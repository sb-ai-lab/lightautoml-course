{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ozP5cZS0jG2"
   },
   "source": [
    "# Uplift modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYXp8j5h0jG4"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPHg_0Cf0jG5",
    "outputId": "1349853d-12ab-407c-8f39-7660957181b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting lightautoml\n",
      "  Downloading LightAutoML-0.3.7.3-py3-none-any.whl (319 kB)\n",
      "\u001b[K     |████████████████████████████████| 319 kB 4.2 MB/s \n",
      "\u001b[?25hCollecting poetry-core<2.0.0,>=1.0.0\n",
      "  Downloading poetry_core-1.4.0-py3-none-any.whl (546 kB)\n",
      "\u001b[K     |████████████████████████████████| 546 kB 40.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from lightautoml) (6.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lightautoml) (4.64.1)\n",
      "Collecting autowoe>=1.2\n",
      "  Downloading AutoWoE-1.3.2-py3-none-any.whl (215 kB)\n",
      "\u001b[K     |████████████████████████████████| 215 kB 47.4 MB/s \n",
      "\u001b[?25hCollecting catboost>=0.26.1\n",
      "  Downloading catboost-1.1.1-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 76.6 MB 83.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from lightautoml) (2.11.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.0.2)\n",
      "Collecting json2html\n",
      "  Downloading json2html-1.3.0.tar.gz (7.0 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from lightautoml) (2.6.3)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.11.2)\n",
      "Collecting torch<1.9\n",
      "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 804.1 MB 2.7 kB/s \n",
      "\u001b[?25hCollecting lightgbm<=3.2.1,>=2.3\n",
      "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 46.9 MB/s \n",
      "\u001b[?25hCollecting optuna\n",
      "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
      "\u001b[K     |████████████████████████████████| 348 kB 45.1 MB/s \n",
      "\u001b[?25hCollecting importlib-metadata<2.0,>=1.0\n",
      "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.3.5)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.13.1+cu113)\n",
      "Requirement already satisfied: holidays in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.17)\n",
      "Collecting cmaes\n",
      "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (2022.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (1.21.6)\n",
      "Collecting sphinx-rtd-theme\n",
      "  Downloading sphinx_rtd_theme-1.1.1-py2.py3-none-any.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 52.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (3.2.2)\n",
      "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (1.8.6)\n",
      "Collecting StrEnum<0.5.0,>=0.4.7\n",
      "  Downloading StrEnum-0.4.8-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (1.7.3)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (3.6.4)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26.1->lightautoml) (0.10.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26.1->lightautoml) (1.15.0)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26.1->lightautoml) (5.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<2.0,>=1.0->lightautoml) (3.10.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.38.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->lightautoml) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->lightautoml) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9->lightautoml) (4.1.1)\n",
      "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays->lightautoml) (2.2.4)\n",
      "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays->lightautoml) (0.3.1)\n",
      "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays->lightautoml) (2.4.0)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays->lightautoml) (0.5.11)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->lightautoml) (2.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.0.9)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 9.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->lightautoml) (21.3)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "\u001b[K     |████████████████████████████████| 209 kB 56.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna->lightautoml) (1.4.44)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna->lightautoml) (5.10.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna->lightautoml) (2.0.1)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 71.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->lightautoml) (3.5.0)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 67.2 MB/s \n",
      "\u001b[?25hCollecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->lightautoml) (22.1.0)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->lightautoml) (0.2.5)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.26.1->lightautoml) (8.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (57.4.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (0.7.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (1.4.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (9.0.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (1.11.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.11.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (0.7.12)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.6.1)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.4.1)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.2.4)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.23.0)\n",
      "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (0.17.1)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.2.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->autowoe>=1.2->lightautoml) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->autowoe>=1.2->lightautoml) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->autowoe>=1.2->lightautoml) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx->autowoe>=1.2->lightautoml) (2022.9.24)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->autowoe>=1.2->lightautoml) (1.1.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->lightautoml) (7.1.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.3 MB 1.3 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1 MB 1.2 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1 MB 80.4 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 1.2 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 1.4 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.3 MB 88.7 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.3 MB 1.4 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.1 MB 1.3 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.1 MB 1.3 MB/s \n",
      "\u001b[?25h  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.4 MB 30.6 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: json2html, pyperclip\n",
      "  Building wheel for json2html (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7609 sha256=3f509028f4963fa3f8ff6b75b91416a16a585b143a646ed65ec68f4f8ff0d2e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/99/37/e1839a5ad733e0d6abb7e0419fd913e8926ddf96408239ce01\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=99e5c05bd1ee87d1c71dd949ab3ba3a0b708b5786dae4957450c53dc8f69df80\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built json2html pyperclip\n",
      "Installing collected packages: pyperclip, pbr, importlib-metadata, stevedore, Mako, cmd2, autopage, torch, StrEnum, sphinx-rtd-theme, lightgbm, colorlog, cmaes, cliff, alembic, torchvision, poetry-core, optuna, json2html, catboost, autowoe, lightautoml\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.13.0\n",
      "    Uninstalling importlib-metadata-4.13.0:\n",
      "      Successfully uninstalled importlib-metadata-4.13.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu113\n",
      "    Uninstalling torch-1.12.1+cu113:\n",
      "      Successfully uninstalled torch-1.12.1+cu113\n",
      "  Attempting uninstall: lightgbm\n",
      "    Found existing installation: lightgbm 2.2.3\n",
      "    Uninstalling lightgbm-2.2.3:\n",
      "      Successfully uninstalled lightgbm-2.2.3\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.1+cu113\n",
      "    Uninstalling torchvision-0.13.1+cu113:\n",
      "      Successfully uninstalled torchvision-0.13.1+cu113\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.1 which is incompatible.\n",
      "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.1 which is incompatible.\n",
      "nbformat 5.7.0 requires importlib-metadata>=3.6; python_version < \"3.8\", but you have importlib-metadata 1.7.0 which is incompatible.\n",
      "markdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\n",
      "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\u001b[0m\n",
      "Successfully installed Mako-1.2.4 StrEnum-0.4.8 alembic-1.8.1 autopage-0.5.1 autowoe-1.3.2 catboost-1.1.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 importlib-metadata-1.7.0 json2html-1.3.0 lightautoml-0.3.7.3 lightgbm-3.2.1 optuna-3.0.3 pbr-5.11.0 poetry-core-1.4.0 pyperclip-1.8.2 sphinx-rtd-theme-1.1.1 stevedore-3.5.2 torch-1.8.1 torchvision-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9pCjMmd0jG5"
   },
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31LcU5VW0jG5"
   },
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "from lightautoml.addons.uplift.base import AutoUplift, BaseLearnerWrapper, MetaLearnerWrapper\n",
    "from lightautoml.addons.uplift import metalearners\n",
    "from lightautoml.addons.uplift.metrics import (_available_uplift_modes,\n",
    "                                               TUpliftMetric,\n",
    "                                               calculate_graphic_uplift_curve,\n",
    "                                               calculate_min_max_uplift_auc,\n",
    "                                               calculate_uplift_at_top,\n",
    "                                               calculate_uplift_auc,\n",
    "                                               perfect_uplift_curve)\n",
    "from lightautoml.addons.uplift.utils import create_linear_automl\n",
    "from lightautoml.report.report_deco import ReportDecoUplift\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghYukmC20jG6"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xil_z_DT0jG6"
   },
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8nghKwH0jG6"
   },
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 300 # Time in seconds for automl run\n",
    "TARGET_NAME = 'TARGET' # Target column name\n",
    "TREATMENT_NAME = 'CODE_GENDER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJPRwe1E0jG7"
   },
   "source": [
    "### Fix torch number of threads and numpy seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5Lqlbk30jG7"
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qzy2Cz3S0jG7"
   },
   "source": [
    "## Example data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7AI6S570jG7"
   },
   "source": [
    "Load a dataset from the repository if doesn't clone repository by git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GB1o4vQ0jG7"
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = 'data/'\n",
    "DATASET_NAME = 'sampled_app_train.csv'\n",
    "DATASET_FULLNAME = os.path.join(DATASET_DIR, DATASET_NAME)\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/sb-ai-lab/LightAutoML/master/examples/data/sampled_app_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlcZnpJc0jG7",
    "outputId": "a9fd194a-293d-407b-e1c6-41d6181479ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64.2 ms, sys: 20.8 ms, total: 85 ms\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DATASET_FULLNAME):\n",
    "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "    dataset = requests.get(DATASET_URL).text\n",
    "    with open(DATASET_FULLNAME, 'w') as output:\n",
    "        output.write(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "fBgZv5t90jG7",
    "outputId": "10f0ddfa-c744-423a-ee33-62eff63de3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 ms, sys: 35.2 ms, total: 168 ms\n",
      "Wall time: 175 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c07275dd-4eb9-45bb-8e83-14cc9fdbf365\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313802</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>327024.0</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319656</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>19737.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207678</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381593</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>142200.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258153</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>1483231.5</td>\n",
       "      <td>46570.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c07275dd-4eb9-45bb-8e83-14cc9fdbf365')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c07275dd-4eb9-45bb-8e83-14cc9fdbf365 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c07275dd-4eb9-45bb-8e83-14cc9fdbf365');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      313802       0         Cash loans           M            N   \n",
       "1      319656       0         Cash loans           F            N   \n",
       "2      207678       0    Revolving loans           F            Y   \n",
       "3      381593       0         Cash loans           F            N   \n",
       "4      258153       0         Cash loans           F            Y   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          270000.0    327024.0      15372.0   \n",
       "1               N             0          108000.0    675000.0      19737.0   \n",
       "2               Y             2          112500.0    270000.0      13500.0   \n",
       "3               N             1           67500.0    142200.0       9630.0   \n",
       "4               Y             0          337500.0   1483231.5      46570.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        0.0                       0.0   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        2.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         1.0  \n",
       "3                        0.0                         4.0  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_FULLNAME)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSLX9GCp0jG8"
   },
   "source": [
    "## (Optional) Some user feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yvz_1Mnc0jG8",
    "outputId": "595c85f7-6c37-46d5-dc2a-55f1c061c3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 125 ms, sys: 5.72 ms, total: 130 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "data['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\n",
    "data['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n",
    "                    ).astype(str)\n",
    "data['report_dt'] = np.datetime64('2018-01-01')\n",
    "data['constant'] = 1\n",
    "data['allnan'] = np.nan\n",
    "data.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)\n",
    "data['CODE_GENDER'] = (data['CODE_GENDER'] == 'M').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ljEd-0lQg-eF",
    "outputId": "b0726bdd-57ff-4fe1-d5f7-8eb9dd0e0b9d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[TARGET_NAME])\n",
    "plt.title('Target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "yQhNyyeRhHgn",
    "outputId": "418e6a1f-2e9f-4a2a-c37d-ae694c9e22ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[TREATMENT_NAME])\n",
    "plt.title('Treatment vs. control group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBynz2clhWRx",
    "outputId": "7463bbe7-a684-4893-97e5-1dc101b07398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control group mean conversion:, 0.0706\n",
      "Target group mean conversion:, 0.0978\n"
     ]
    }
   ],
   "source": [
    "print(f'Control group mean conversion:, {data[data[TREATMENT_NAME] == 0][TARGET_NAME].mean():.4f}')\n",
    "print(f'Target group mean conversion:, {data[data[TREATMENT_NAME] == 1][TARGET_NAME].mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Bmdce570jG8"
   },
   "source": [
    "## Data splitting for train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqzT1M030jG8"
   },
   "outputs": [],
   "source": [
    "stratify_value = data[TARGET_NAME] + 10 * data[TREATMENT_NAME]\n",
    "train, test = train_test_split(data, test_size=3000, stratify=stratify_value, random_state=42)\n",
    "test_target, test_treatment = test[TARGET_NAME].values.ravel(), test[TREATMENT_NAME].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tps17yE70jG8"
   },
   "source": [
    "## Setup columns roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMQeZzL20jG8"
   },
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'target': TARGET_NAME,\n",
    "    'treatment': TREATMENT_NAME,\n",
    "    DatetimeRole(base_date=True, seasonality=(), base_feats=False): 'report_dt'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "es6D41C-0jG8"
   },
   "source": [
    "## AutoUplift (use predefined uplift methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr1oXKS70jG8"
   },
   "source": [
    "### Fit autouplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnfglOF40jG8",
    "outputId": "6bb3b0a6-faa8-4847-b679-78fae0ddb90e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:02] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['REG_REGION_NOT_LIVE_REGION', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_18']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:04] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.51 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.51 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:04] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 197}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7209763539282991\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7272311212814645\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7339435545385202\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7479023646071701\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7482074752097636\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7486651411136537\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7480549199084667\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7418764302059496\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7218154080854309\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7300533943554538\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7413424866514111\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7723874904652938\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7780320366132722\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7733790999237223\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7661327231121282\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5785350567959263\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.581590285938112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5829220524872699\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6108108108108108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6330591461026244\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6710536623580102\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6835879357618488\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6906384645515079\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6898550724637682\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6882882882882884\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.680924402663533\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.690951821386604\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7021543282412848\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.72777124951038\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.736701919310615\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7476694085389738\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7474343909126517\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7405405405405405\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6122992557775168\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6225616921269096\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6329808068938504\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6607128867998434\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6698785742264003\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6720720720720721\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.67340383862123\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6688601645123384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6645515080297688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:07] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.71418739827947\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.71418739827947\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:07] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:07] Time left 9999999994.65 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999994.65 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:07] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:07] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['WEEKDAY_APPR_PROCESS_START']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:09] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.48 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.48 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:10] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49, 13,\n",
      "        8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6398575913882036\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6604059206100023\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6863085893698139\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7453184570531508\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7563355012334605\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7580174927113702\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7541769455034761\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7477853778874186\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6621159452792106\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6795245570755776\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6992318905584212\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7487945727741646\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7599237497196681\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7689504373177841\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7696512671002467\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7647174254317112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7617459071540704\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6221686476788517\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6349517829109665\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6449596322045302\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6703296703296703\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6790760260148015\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6886353442475891\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6879625476564252\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6787396277192195\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6100505334081977\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6240314430095453\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6390510948905109\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6793093767546323\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.692279618192027\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7015160022459292\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.70393037619315\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7085064570466031\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7075519371139809\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6998877035373385\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6921392476137002\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7190342504211117\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7367770915216171\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7705221785513756\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7776810780460416\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7785794497473331\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7731611454239192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7596574957888826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7315916434790413\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7315916434790413\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:17] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:17] Time left 9999999990.82 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999990.82 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:17] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:17] Uplift candidate #0 [__TLearner__Default__] is fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #0 [__TLearner__Default__] is fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:17] \u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['FLAG_CONT_MOBILE', 'REG_REGION_NOT_LIVE_REGION', 'OBS_60_CNT_SOCIAL_CIRCLE', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_19']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:19] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.00 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:20] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 184}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.761746690237396\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7713084234653931\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7765657825281379\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7955475411926836\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8079611437235847\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8355445653290632\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8454393118669646\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8606020455519695\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8635176833610254\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8653740554290026\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8653775981237888\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8626001254113955\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.8625894973270368\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7707734765526746\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.781468872112261\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7877181857151461\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8134523206422198\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8263689858327635\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8506789574557784\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.85703455190225\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8662986987682051\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8676520081765395\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8685341391783075\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8685341391783075\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.867577611586029\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7710168986506619\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7813781410065409\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7880432469246159\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8139268434569162\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8281544857333388\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8542651002426255\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8619305041217951\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8732707615034265\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8754380737524652\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8779494601228734\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8779530072787638\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.877701159210545\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.877701159210545\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7778167964925724\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7865853658536586\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7918883639098171\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8143986151903404\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8263596248527931\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8501113806949588\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8570673533960471\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8642077782034365\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8641474765532996\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.861057903772755\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7713432369925795\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7777777777777779\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7819208558577733\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.801462137658026\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8128059421955476\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8362171710722343\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8448793257566084\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8581527830985115\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8609692248754948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8632500461130266\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8632464989571361\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8619695228365896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:40] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8668794076003595\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8668794076003595\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:40] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:40] Time left 9999999976.79 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999976.79 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:40] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:40] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['WEEKDAY_APPR_PROCESS_START']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:42] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.05 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.05 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:43] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49, 13,\n",
      "        8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6407546535097555\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6616954474097331\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6872617178739628\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7441410630186139\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7561112357030724\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7585220901547433\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7539807131643866\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7480376766091051\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6619197129401211\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.679608656649473\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6993720565149136\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7489067055393587\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7599237497196681\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7687822381699934\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7694270015698587\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7644931599013232\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7619701726844583\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6228414442700156\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6346714509979816\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6444270015698587\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6701334379905809\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6787115945279211\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6886633774388877\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6876261493608432\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6780668311280555\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6101347557551937\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6241156653565413\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6391914654688378\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.679449747332959\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6921953958450309\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7014037057832678\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7035934868051656\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7086468276249298\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7075098259404828\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7002807411566536\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6921392476137002\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7186131386861314\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7364963503649634\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7706625491297023\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7777653003930376\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7783548568220101\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7730769230769231\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7598259404828748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:50] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7320639978457948\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7320639978457948\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:50] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:50] Time left 9999999990.33 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999990.33 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:50] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:50] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['REG_REGION_NOT_LIVE_REGION', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_18']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:51] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.75 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.75 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:52] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 197}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7209763539282991\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7272311212814645\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7339435545385202\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7479023646071701\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7482074752097636\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7486651411136537\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7480549199084667\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7418764302059496\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7218154080854309\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7300533943554538\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7413424866514111\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7723874904652938\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7780320366132722\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7733790999237223\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7661327231121282\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5785350567959263\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.581590285938112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5829220524872699\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6108108108108108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6330591461026244\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6710536623580102\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6835879357618488\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6906384645515079\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6898550724637682\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6882882882882884\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.680924402663533\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.690951821386604\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7021543282412848\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.72777124951038\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.736701919310615\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7476694085389738\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7474343909126517\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7405405405405405\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6122992557775168\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6225616921269096\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6329808068938504\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6607128867998434\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6698785742264003\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6720720720720721\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.67340383862123\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6688601645123384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6645515080297688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:55] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.71418739827947\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.71418739827947\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:55] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:55] Time left 9999999994.80 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999994.80 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:55] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:56] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:57] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.47 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.47 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:58] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], 'embed_sizes': array([ 6,  3,  3,  9,  3,  5, 49, 13,  8, 36, 13,  8], dtype=int32), 'data_size': 192}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07081095750818306\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07039760722921498\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07033066405882725\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07054568330916872\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07068329468437813\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.0621013248877264\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06158544202385532\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.061530808741062135\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06193080168563449\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06226205525720081\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.0604765616328819\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.060041121713478425\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0600103952942151\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06060262446354861\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.061123351064827754\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.06700801382519844\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06626984482191203\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.06605272713994856\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06597613650838188\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06611834970333261\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.0669861345457484\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.05501763322581018\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.05475741536427313\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.05481344287080399\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.05548243371430368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:00] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.06252225227320929\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.06252225227320929\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:00] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:00] Time left 9999999996.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999996.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:00] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:00] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['SK_ID_CURR', 'FLAG_CONT_MOBILE', 'REGION_RATING_CLIENT', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_21']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:01] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.61 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.61 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:02] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207], 'embed_sizes': array([16,  6, 10,  3,  3, 11,  4, 13, 11, 35,  3,  5, 47, 13,  8, 24, 13,\n",
      "        8, 11, 11], dtype=int32), 'data_size': 208}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07485135897496556\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07499940506023503\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07516316685265033\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07742257558254759\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07685617613258125\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07670254246636704\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07692345328495553\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07732504901345565\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.09059030106735845\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08984830365781762\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08957875233317708\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08984131803232731\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.0905836471028469\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.08100058122759639\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.0806812580198333\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08077347911237165\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08134492807070458\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.09275041068953889\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.0923790746707523\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.09247565928990671\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.0942018038361301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:03] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.08283121063342454\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.08283121063342454\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:03] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:03] Time left 9999999996.81 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999996.81 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:03] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:03] Uplift candidate #1 [__XLearner__Default__] is fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #1 [__XLearner__Default__] is fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:04] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:04] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:04] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:04] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:04] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:04] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:04] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:09] Layer \u001b[1m1\u001b[0m train process start. Time left 13.90 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 13.90 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:09] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 190}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7234935163996948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7311975591151791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7366132723112128\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7450800915331808\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.745537757437071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7456140350877192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.743020594965675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7386727688787186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:10] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:10] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:10] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:10] Time left 12.77 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 12.77 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.719527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736156\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.741266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:11] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.737147\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.73341\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.749428\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.726926\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.72746\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.722502\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.739512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:12] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:12] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5727689\tbest: 0.5727689 (0)\ttotal: 2.98ms\tremaining: 1.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7062548\tbest: 0.7141876 (47)\ttotal: 234ms\tremaining: 925ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7240275\tbest: 0.7278413 (194)\ttotal: 446ms\tremaining: 664ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7278413425\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5815408\tbest: 0.5815408 (0)\ttotal: 2.54ms\tremaining: 1.26s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7398932\tbest: 0.7468345 (88)\ttotal: 227ms\tremaining: 899ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7468344775\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4952996\tbest: 0.4952996 (0)\ttotal: 2.42ms\tremaining: 1.21s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6314924\tbest: 0.6426165 (72)\ttotal: 215ms\tremaining: 851ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6426165296\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6287113\tbest: 0.6287113 (0)\ttotal: 2.29ms\tremaining: 1.14s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7001958\tbest: 0.7001958 (100)\ttotal: 234ms\tremaining: 923ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7081864\tbest: 0.7126518 (177)\ttotal: 449ms\tremaining: 668ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7126517822\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 177\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 178 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:15] Time limit exceeded after calculating fold 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6888888888888889\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6888888888888889\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:15] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:15] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-07752575-11e1-4ebf-82fc-6c84ddc2ab1f\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5331426\tbest: 0.5331426 (0)\ttotal: 1.83ms\tremaining: 915ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7044241\tbest: 0.7244851 (58)\ttotal: 167ms\tremaining: 659ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7244851259\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7244851258581235 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7244851258581235.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7244851258581235 in 0:00:00.392963\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.38ms\tremaining: 688ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7245614\tbest: 0.7290618 (50)\ttotal: 121ms\tremaining: 479ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7488940\tbest: 0.7490465 (197)\ttotal: 247ms\tremaining: 367ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7537757\tbest: 0.7571320 (273)\ttotal: 367ms\tremaining: 242ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7571319603\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7571319603356217 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.7571319603356217.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7571319603356217 in 0:00:00.615775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:16] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 0.7571 auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.37ms\tremaining: 4.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7250953\tbest: 0.7370709 (13)\ttotal: 124ms\tremaining: 3.55s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7370709382\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5556064\tbest: 0.5556064 (0)\ttotal: 1.42ms\tremaining: 4.25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650648\tbest: 0.7718535 (86)\ttotal: 125ms\tremaining: 3.6s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7718535469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 86\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 87 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5537799\tbest: 0.5537799 (0)\ttotal: 1.45ms\tremaining: 4.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6231884\tbest: 0.6231884 (100)\ttotal: 131ms\tremaining: 3.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6173130\tbest: 0.6308656 (110)\ttotal: 251ms\tremaining: 3.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6308656483\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6509597\tbest: 0.6509597 (0)\ttotal: 1.47ms\tremaining: 4.42s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7686643\tbest: 0.7754798 (95)\ttotal: 123ms\tremaining: 3.52s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7754798277\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5874657\tbest: 0.5874657 (0)\ttotal: 1.56ms\tremaining: 4.67s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6279671\tbest: 0.6520956 (66)\ttotal: 121ms\tremaining: 3.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6520955738\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 66\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 67 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:17] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:17] Time left 5.16 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 5.16 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:17] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:17] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:17] Blending: optimization starts with equal weights and score \u001b[1m0.695140664961637\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.695140664961637\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7017437805161589\u001b[0m, weights = \u001b[1m[0.48107234 0.51892763 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7017437805161589\u001b[0m, weights = \u001b[1m[0.48107234 0.51892763 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] \u001b[1mAutoml preset training completed in 13.27 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 13.27 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:18] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:19] Layer \u001b[1m1\u001b[0m train process start. Time left 16.58 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.58 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:20] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203], 'embed_sizes': array([ 8, 19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49,\n",
      "       13,  8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 204}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6490524781341108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6751794124243103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6962884054720789\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7440569634447185\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7555505718771025\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.755690737833595\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7507288629737608\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.743748598340435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:21] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:21] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:21] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:21] Time left 14.62 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 14.62 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.716865\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.718435\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.711987\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[128]\tvalid's auc: 0.726901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:24] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751626\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.748991\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.745935\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[148]\tvalid's auc: 0.752635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:26] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:26] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5284257\tbest: 0.5284257 (0)\ttotal: 4.53ms\tremaining: 2.26s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6480713\tbest: 0.6538181 (91)\ttotal: 395ms\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6696008\tbest: 0.6750953 (140)\ttotal: 798ms\tremaining: 1.19s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6842902\tbest: 0.6928403 (264)\ttotal: 1.18s\tremaining: 783ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6928403229\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 264\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 265 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5169741\tbest: 0.5169741 (0)\ttotal: 4.36ms\tremaining: 2.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7313019\tbest: 0.7313019 (100)\ttotal: 395ms\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7190514\tbest: 0.7316663 (121)\ttotal: 797ms\tremaining: 1.19s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7316662929\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 121\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 122 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7063663377438889\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7063663377438889\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Time left 7.31 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 7.31 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Blending: optimization starts with equal weights and score \u001b[1m0.7444704530163715\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7444704530163715\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7632036331015922\u001b[0m, weights = \u001b[1m[0.59691685 0.40308318 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7632036331015922\u001b[0m, weights = \u001b[1m[0.59691685 0.40308318 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] \u001b[1mAutoml preset training completed in 11.09 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 11.09 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:29] Uplift candidate #2 [__TLearner__TabularAutoML__] is fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #2 [__TLearner__TabularAutoML__] is fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:30] \u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['FLAG_CONT_MOBILE', 'REG_REGION_NOT_LIVE_REGION', 'OBS_60_CNT_SOCIAL_CIRCLE', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_19']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:32] Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.02 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.02 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:32] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 184}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.761978736745893\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7711667156739446\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7766118375603587\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7955794254457597\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8078938325226466\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8356331326987185\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8455455927105512\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8605666186041073\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8635885372567497\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8654484520195131\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.864938303970298\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8649453893598704\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7704723474958463\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.781387390132178\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7877164143677531\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8131015938583843\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8264469251180603\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8507002136244957\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8570947777136158\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8662880706838465\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8677405755461949\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8686120784636041\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8685908222948867\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8668159322069926\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7710168986506619\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.781335575135856\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7878907192213284\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8138275230919849\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8281048255508732\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8543573262957761\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8619269569659047\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8732991387505498\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.875427432284794\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8779920259935583\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8779920259935583\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8776337632486272\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7778026078690107\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7866208374125627\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7918670809744747\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8142567289547241\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8263028703585464\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8501113806949588\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8571418436697456\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8642751741653542\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8641297407738476\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8611465826700151\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7713006711218944\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7778841924544899\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7818499127399652\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8015791938024093\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8127456405454107\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8362100767604534\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8448509485094851\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.858120858695498\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8610011492785085\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8632784233601499\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8632997062954924\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8618276366009733\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.8618276366009733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8669115995334863\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8669115995334863\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] Time left 9999999981.70 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 9999999981.70 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:48] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:49] Layer \u001b[1m1\u001b[0m train process start. Time left 16.62 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.62 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:50] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203], 'embed_sizes': array([ 8, 19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49,\n",
      "       13,  8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 204}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6490524781341108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6751794124243103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6962884054720789\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7440569634447185\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7555505718771025\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.755690737833595\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7507288629737608\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.743748598340435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:51] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:51] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:51] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:51] Time left 14.80 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 14.80 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.716865\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.718435\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.711987\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[128]\tvalid's auc: 0.726901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:54] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751626\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.748991\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.745935\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[148]\tvalid's auc: 0.752635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:56] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:56] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5284257\tbest: 0.5284257 (0)\ttotal: 4.28ms\tremaining: 2.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6480713\tbest: 0.6538181 (91)\ttotal: 407ms\tremaining: 1.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6696008\tbest: 0.6750953 (140)\ttotal: 783ms\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6842902\tbest: 0.6928403 (264)\ttotal: 1.2s\tremaining: 793ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6928403229\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 264\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 265 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5169741\tbest: 0.5169741 (0)\ttotal: 4.02ms\tremaining: 2.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7313019\tbest: 0.7313019 (100)\ttotal: 386ms\tremaining: 1.52s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7190514\tbest: 0.7316663 (121)\ttotal: 801ms\tremaining: 1.19s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7316662929\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 121\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 122 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7063663377438889\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7063663377438889\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Time left 7.42 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 7.42 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Blending: optimization starts with equal weights and score \u001b[1m0.7444704530163715\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7444704530163715\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7632036331015922\u001b[0m, weights = \u001b[1m[0.59691685 0.40308318 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7632036331015922\u001b[0m, weights = \u001b[1m[0.59691685 0.40308318 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] \u001b[1mAutoml preset training completed in 10.99 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 10.99 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:00] Layer \u001b[1m1\u001b[0m train process start. Time left 16.87 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.87 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:01] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 190}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7234935163996948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7311975591151791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7366132723112128\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7450800915331808\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.745537757437071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7456140350877192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.743020594965675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7386727688787186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:01] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:01] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:01] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:01] Time left 15.71 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 15.71 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.719527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736156\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.741266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:03] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.737147\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.73341\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.749428\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.726926\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.72746\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.722502\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.739512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:04] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:04] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:04] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-f26c6b9d-5337-436b-9f4a-0c869ec4a0f0\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.685278\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.693898\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.705187\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.711137\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.711899\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.714874\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.713654\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[592]\tvalid's auc: 0.716247\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7162471395881007 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.7162471395881007.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.7162471395881007 in 0:00:03.517082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:07] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve 0.7162 auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5727689\tbest: 0.5727689 (0)\ttotal: 2.79ms\tremaining: 1.39s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7062548\tbest: 0.7141876 (47)\ttotal: 227ms\tremaining: 897ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7240275\tbest: 0.7278413 (194)\ttotal: 447ms\tremaining: 665ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7278413425\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5815408\tbest: 0.5815408 (0)\ttotal: 2.29ms\tremaining: 1.14s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7398932\tbest: 0.7468345 (88)\ttotal: 222ms\tremaining: 876ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7468344775\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4952996\tbest: 0.4952996 (0)\ttotal: 2.3ms\tremaining: 1.15s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6314924\tbest: 0.6426165 (72)\ttotal: 229ms\tremaining: 905ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6426165296\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:09] Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:09] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:09] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-3687cd65-e79c-4162-bbd2-b1a3918fef50\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5331426\tbest: 0.5331426 (0)\ttotal: 1.79ms\tremaining: 893ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7044241\tbest: 0.7244851 (58)\ttotal: 177ms\tremaining: 699ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7244851259\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7244851258581235 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7244851258581235.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7244851258581235 in 0:00:00.428617\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.41ms\tremaining: 703ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7245614\tbest: 0.7290618 (50)\ttotal: 137ms\tremaining: 542ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7488940\tbest: 0.7490465 (197)\ttotal: 264ms\tremaining: 392ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7537757\tbest: 0.7571320 (273)\ttotal: 388ms\tremaining: 257ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7571319603\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7571319603356217 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.7571319603356217.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7571319603356217 in 0:00:00.613741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:10] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 0.7571 auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.39ms\tremaining: 4.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7250953\tbest: 0.7370709 (13)\ttotal: 128ms\tremaining: 3.69s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7370709382\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5556064\tbest: 0.5556064 (0)\ttotal: 1.41ms\tremaining: 4.22s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650648\tbest: 0.7718535 (86)\ttotal: 123ms\tremaining: 3.53s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7718535469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 86\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 87 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5537799\tbest: 0.5537799 (0)\ttotal: 2.13ms\tremaining: 6.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6231884\tbest: 0.6231884 (100)\ttotal: 132ms\tremaining: 3.79s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6173130\tbest: 0.6308656 (110)\ttotal: 267ms\tremaining: 3.72s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6308656483\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6509597\tbest: 0.6509597 (0)\ttotal: 1.64ms\tremaining: 4.93s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7686643\tbest: 0.7754798 (95)\ttotal: 129ms\tremaining: 3.69s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7754798277\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5874657\tbest: 0.5874657 (0)\ttotal: 1.47ms\tremaining: 4.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6279671\tbest: 0.6520956 (66)\ttotal: 126ms\tremaining: 3.62s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6520955738\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 66\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 67 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Time left 5.14 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 5.14 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] \u001b[1mAutoml preset training completed in 13.33 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 13.33 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:12] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:13] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:13] Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:13] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:13] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:13] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:13] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:13] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:14] Layer \u001b[1m1\u001b[0m train process start. Time left 16.63 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.63 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:15] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], 'embed_sizes': array([ 6,  5,  3,  3,  9,  7,  3,  5, 49, 13,  8, 36, 13,  8],\n",
      "      dtype=int32), 'data_size': 186}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07093726938398473\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.0704291346516548\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07031142141410163\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07037027532245685\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07057521661797152\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.06212071301845505\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06166575830034786\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.06164247941905598\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06216234322604961\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06256765384868207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:16] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:16] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0659769504165788\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0659769504165788\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:16] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:16] Time left 15.38 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 15.38 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0701653\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0703635\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0706011\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[111]\tvalid's l2: 0.0701198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:18] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0700265\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0699663\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0702125\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[162]\tvalid's l2: 0.0698633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:20] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.0698632892768944\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.0698632892768944\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:20] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2458766\ttest: 0.2672492\tbest: 0.2672492 (0)\ttotal: 2.78ms\tremaining: 5.55s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2224887\ttest: 0.2672056\tbest: 0.2667037 (20)\ttotal: 269ms\tremaining: 5.06s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2014391\ttest: 0.2686460\tbest: 0.2667037 (20)\ttotal: 532ms\tremaining: 4.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1782851\ttest: 0.2697492\tbest: 0.2667037 (20)\ttotal: 803ms\tremaining: 4.53s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2667037312\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 20\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 21 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2505670\ttest: 0.2500807\tbest: 0.2500807 (0)\ttotal: 2.72ms\tremaining: 5.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2290464\ttest: 0.2464674\tbest: 0.2462925 (76)\ttotal: 252ms\tremaining: 4.74s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2086461\ttest: 0.2465990\tbest: 0.2460105 (109)\ttotal: 514ms\tremaining: 4.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1862601\ttest: 0.2472577\tbest: 0.2460105 (109)\ttotal: 769ms\tremaining: 4.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1669461\ttest: 0.2485226\tbest: 0.2460105 (109)\ttotal: 1.04s\tremaining: 4.16s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2460104782\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 109\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 110 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:22] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.0658260178572445\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.0658260178572445\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:22] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:22] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-5091d262-d804-4f48-8dcc-d156e7530f9d\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2459449\ttest: 0.2669882\tbest: 0.2669882 (0)\ttotal: 1.97ms\tremaining: 3.94s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2275001\ttest: 0.2639859\tbest: 0.2637316 (56)\ttotal: 197ms\tremaining: 3.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2125453\ttest: 0.2633641\tbest: 0.2631804 (191)\ttotal: 389ms\tremaining: 3.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1963823\ttest: 0.2646464\tbest: 0.2631804 (191)\ttotal: 587ms\tremaining: 3.31s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1822437\ttest: 0.2653673\tbest: 0.2631804 (191)\ttotal: 784ms\tremaining: 3.13s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2631803824\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 191\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 192 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.06926391402910047 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.06926391402910047.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.06926391402910047 in 0:00:01.221461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:24] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}\u001b[0m\n",
      " achieve -0.0693 mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.0024430162614261413, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2461236\ttest: 0.2670701\tbest: 0.2670701 (0)\ttotal: 2.06ms\tremaining: 6.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2333416\ttest: 0.2640407\tbest: 0.2640344 (99)\ttotal: 189ms\tremaining: 5.42s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2248658\ttest: 0.2636474\tbest: 0.2635485 (190)\ttotal: 398ms\tremaining: 5.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2151160\ttest: 0.2627348\tbest: 0.2626105 (275)\ttotal: 604ms\tremaining: 5.42s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2626104802\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 275\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 276 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2507162\ttest: 0.2499679\tbest: 0.2499679 (0)\ttotal: 2.13ms\tremaining: 6.38s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2383735\ttest: 0.2468338\tbest: 0.2466842 (73)\ttotal: 202ms\tremaining: 5.81s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2298061\ttest: 0.2459577\tbest: 0.2459577 (200)\ttotal: 391ms\tremaining: 5.44s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2210035\ttest: 0.2452926\tbest: 0.2452596 (292)\ttotal: 602ms\tremaining: 5.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2103936\ttest: 0.2454534\tbest: 0.2451068 (308)\ttotal: 792ms\tremaining: 5.13s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2451068453\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 308\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 309 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2519872\ttest: 0.2442943\tbest: 0.2442943 (0)\ttotal: 2.1ms\tremaining: 6.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2384762\ttest: 0.2431292\tbest: 0.2428909 (44)\ttotal: 193ms\tremaining: 5.53s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2428908884\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 44\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 45 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2489931\ttest: 0.2564218\tbest: 0.2564218 (0)\ttotal: 2.08ms\tremaining: 6.23s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2360685\ttest: 0.2550071\tbest: 0.2549925 (91)\ttotal: 202ms\tremaining: 5.78s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2281250\ttest: 0.2541582\tbest: 0.2541086 (197)\ttotal: 404ms\tremaining: 5.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2189342\ttest: 0.2538045\tbest: 0.2537417 (299)\ttotal: 589ms\tremaining: 5.28s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2086248\ttest: 0.2535272\tbest: 0.2533319 (326)\ttotal: 776ms\tremaining: 5.03s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2533319468\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 326\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 327 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2544000\ttest: 0.2342332\tbest: 0.2342332 (0)\ttotal: 1.88ms\tremaining: 5.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2421512\ttest: 0.2323043\tbest: 0.2322915 (99)\ttotal: 202ms\tremaining: 5.79s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2336028\ttest: 0.2326681\tbest: 0.2321042 (124)\ttotal: 394ms\tremaining: 5.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2321042008\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 124\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 125 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.06121859903579186\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.06121859903579186\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:27] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:27] Time left 3.58 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 3.58 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:27] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:27] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:27] Blending: optimization starts with equal weights and score \u001b[1m-0.06141709163244357\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.06141709163244357\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:27] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] \u001b[1mAutoml preset training completed in 14.72 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 14.72 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:28] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:29] Layer \u001b[1m1\u001b[0m train process start. Time left 16.91 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.91 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:30] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([16,  6, 10,  3,  3, 11,  5,  4, 13, 11, 35,  3,  4, 47, 13,  8, 24,\n",
      "       13,  8, 11], dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07449485797186384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07423297648580518\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0742281102128536\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07548342725769143\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07662500792022853\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07697611915152407\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07627645175899474\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07609266747410862\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07657355182780512\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07721748413374047\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.09041277683662372\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.0896927942793363\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08947769537405861\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08984032062614984\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.0906021671414983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:31] Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:31] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.07992451000609486\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.07992451000609486\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:31] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:31] Time left 15.40 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 15.40 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767461\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0784016\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[3]\tvalid's l2: 0.0744974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:32] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767052\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0793602\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.0745394\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0772268\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0787542\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[41]\tvalid's l2: 0.0768315\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0891813\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0883896\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0882638\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's l2: 0.0885805\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[278]\tvalid's l2: 0.088093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:34] Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.07981406994276753\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.07981406994276753\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:34] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:34] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2742f454-4fec-43a0-b45f-e811f2e62b31\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0777606\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.081215\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[5]\tvalid's l2: 0.0744279\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.07442791311914856 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: -0.07442791311914856.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.07442791311914856 in 0:00:00.632500\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0761122\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0785505\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[5]\tvalid's l2: 0.0744357\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.07443573690859956 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 0 with value: -0.07442791311914856.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -0.07443573690859956 in 0:00:00.415011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:35] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve -0.0744 mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2931105\ttest: 0.2730306\tbest: 0.2730306 (0)\ttotal: 884us\tremaining: 1.77s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2539640\ttest: 0.2789047\tbest: 0.2730306 (0)\ttotal: 86.3ms\tremaining: 1.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2209009\ttest: 0.2840797\tbest: 0.2730306 (0)\ttotal: 168ms\tremaining: 1.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1905947\ttest: 0.2888705\tbest: 0.2730306 (0)\ttotal: 259ms\tremaining: 1.46s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730305773\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2918162\ttest: 0.2783974\tbest: 0.2783974 (0)\ttotal: 891us\tremaining: 1.78s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2541574\ttest: 0.2771797\tbest: 0.2761792 (42)\ttotal: 87.2ms\tremaining: 1.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2214694\ttest: 0.2806531\tbest: 0.2761792 (42)\ttotal: 193ms\tremaining: 1.72s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1907055\ttest: 0.2856095\tbest: 0.2761792 (42)\ttotal: 278ms\tremaining: 1.57s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2761791533\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2858305\ttest: 0.3014090\tbest: 0.3014090 (0)\ttotal: 921us\tremaining: 1.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2524039\ttest: 0.2927180\tbest: 0.2923455 (89)\ttotal: 86.9ms\tremaining: 1.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2186045\ttest: 0.2916859\tbest: 0.2908069 (148)\ttotal: 167ms\tremaining: 1.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1887229\ttest: 0.2944040\tbest: 0.2908069 (148)\ttotal: 251ms\tremaining: 1.42s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1652364\ttest: 0.2963591\tbest: 0.2908069 (148)\ttotal: 334ms\tremaining: 1.33s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2908068672\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 148\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 149 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2898185\ttest: 0.2854178\tbest: 0.2854178 (0)\ttotal: 989us\tremaining: 1.98s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2569051\ttest: 0.2821814\tbest: 0.2813736 (83)\ttotal: 79.6ms\tremaining: 1.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2260265\ttest: 0.2835825\tbest: 0.2813736 (83)\ttotal: 163ms\tremaining: 1.46s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1946849\ttest: 0.2851189\tbest: 0.2813736 (83)\ttotal: 259ms\tremaining: 1.46s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2813735614\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 83\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 84 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2842533\ttest: 0.3080572\tbest: 0.3080572 (0)\ttotal: 969us\tremaining: 1.94s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2494624\ttest: 0.3061037\tbest: 0.3055388 (76)\ttotal: 91.9ms\tremaining: 1.73s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2168374\ttest: 0.3099174\tbest: 0.3055388 (76)\ttotal: 174ms\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1874059\ttest: 0.3135705\tbest: 0.3055388 (76)\ttotal: 260ms\tremaining: 1.47s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.305538818\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.08157640428059512\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.08157640428059512\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:37] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:37] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-e2b300fb-0598-4c82-a9ea-5f55c3444f2d\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2930198\ttest: 0.2730346\tbest: 0.2730346 (0)\ttotal: 736us\tremaining: 1.47s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2626308\ttest: 0.2786636\tbest: 0.2730346 (0)\ttotal: 64.3ms\tremaining: 1.21s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2405736\ttest: 0.2827328\tbest: 0.2730346 (0)\ttotal: 127ms\tremaining: 1.14s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2190736\ttest: 0.2884436\tbest: 0.2730346 (0)\ttotal: 201ms\tremaining: 1.13s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730345851\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.07454788496599066 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.07454788496599066.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.07454788496599066 in 0:00:00.340929\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934392\ttest: 0.2730211\tbest: 0.2730211 (0)\ttotal: 609us\tremaining: 1.22s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2762059\ttest: 0.2753635\tbest: 0.2727228 (1)\ttotal: 62.3ms\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2624159\ttest: 0.2795560\tbest: 0.2727228 (1)\ttotal: 110ms\tremaining: 988ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2485725\ttest: 0.2823829\tbest: 0.2727228 (1)\ttotal: 167ms\tremaining: 943ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2727227973\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.0743777244717666 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: -0.0743777244717666.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.0743777244717666 in 0:00:00.283278\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2932603\ttest: 0.2729836\tbest: 0.2729836 (0)\ttotal: 555us\tremaining: 1.11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2739754\ttest: 0.2788363\tbest: 0.2729836 (0)\ttotal: 54.8ms\tremaining: 1.03s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2581291\ttest: 0.2842183\tbest: 0.2729836 (0)\ttotal: 105ms\tremaining: 944ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2441654\ttest: 0.2879016\tbest: 0.2729836 (0)\ttotal: 155ms\tremaining: 874ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.272983633\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.07452006419389333 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: -0.0743777244717666.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.07452006419389333 in 0:00:00.280656\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934392\ttest: 0.2730211\tbest: 0.2730211 (0)\ttotal: 583us\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2762017\ttest: 0.2753644\tbest: 0.2727228 (1)\ttotal: 48.6ms\tremaining: 915ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2624074\ttest: 0.2795581\tbest: 0.2727228 (1)\ttotal: 102ms\tremaining: 914ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2485611\ttest: 0.2823859\tbest: 0.2727228 (1)\ttotal: 153ms\tremaining: 864ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2727227842\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.07437771729254725 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 3 with value: -0.07437771729254725.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.07437771729254725 in 0:00:00.283178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:38] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}\u001b[0m\n",
      " achieve -0.0744 mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 7.71800699380605e-05, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 6, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934784\ttest: 0.2729962\tbest: 0.2729962 (0)\ttotal: 810us\tremaining: 2.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2818313\ttest: 0.2741072\tbest: 0.2728140 (1)\ttotal: 68.5ms\tremaining: 1.97s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2728139867\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2922093\ttest: 0.2783588\tbest: 0.2783588 (0)\ttotal: 545us\tremaining: 1.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2810740\ttest: 0.2773695\tbest: 0.2769819 (47)\ttotal: 69.3ms\tremaining: 1.99s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2769818792\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 47\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 48 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861366\ttest: 0.3015423\tbest: 0.3015423 (0)\ttotal: 570us\tremaining: 1.71s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2772232\ttest: 0.2969872\tbest: 0.2969685 (98)\ttotal: 46.9ms\tremaining: 1.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2709412\ttest: 0.2946235\tbest: 0.2946235 (200)\ttotal: 96.6ms\tremaining: 1.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2630969\ttest: 0.2944796\tbest: 0.2941172 (232)\ttotal: 149ms\tremaining: 1.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2542882\ttest: 0.2939718\tbest: 0.2939312 (398)\ttotal: 207ms\tremaining: 1.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2460489\ttest: 0.2939368\tbest: 0.2937800 (437)\ttotal: 256ms\tremaining: 1.27s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2388600\ttest: 0.2943532\tbest: 0.2936933 (523)\ttotal: 308ms\tremaining: 1.23s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2936933275\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 523\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 524 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2903441\ttest: 0.2855145\tbest: 0.2855145 (0)\ttotal: 554us\tremaining: 1.66s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2795555\ttest: 0.2831808\tbest: 0.2830044 (88)\ttotal: 47.6ms\tremaining: 1.36s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2727980\ttest: 0.2829466\tbest: 0.2826695 (152)\ttotal: 91.6ms\tremaining: 1.27s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2826694542\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 152\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 153 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2845696\ttest: 0.3080152\tbest: 0.3080152 (0)\ttotal: 557us\tremaining: 1.67s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2734864\ttest: 0.3051470\tbest: 0.3051380 (97)\ttotal: 49.8ms\tremaining: 1.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2667230\ttest: 0.3047675\tbest: 0.3046527 (189)\ttotal: 114ms\tremaining: 1.59s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3046527142\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.08201675266808113\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.08201675266808113\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Time left 6.81 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 6.81 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Blending: optimization starts with equal weights and score \u001b[1m-0.08180051954118665\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.08180051954118665\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.08157509841201353\u001b[0m, weights = \u001b[1m[0.         0.         0.94842803 0.05157195]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.08157509841201353\u001b[0m, weights = \u001b[1m[0.         0.         0.94842803 0.05157195]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.08157509841201353\u001b[0m, weights = \u001b[1m[0.         0.         0.94842803 0.05157195]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.08157509841201353\u001b[0m, weights = \u001b[1m[0.         0.         0.94842803 0.05157195]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] \u001b[1mAutoml preset training completed in 11.49 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 11.49 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.94843 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.05157 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.94843 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.05157 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:39] Uplift candidate #3 [__XLearner__Propensity_Linear__Other_TabularAutoML__] is fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #3 [__XLearner__Propensity_Linear__Other_TabularAutoML__] is fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] \u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:43] Layer \u001b[1m1\u001b[0m train process start. Time left 16.26 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.26 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:44] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 182}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7638864778882705\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7718079434302496\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7763886477888269\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7967237158617074\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.808588200700745\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8356827304257257\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8457652397872966\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8617038236304828\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8647859680944908\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8673402510353525\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8673402510353525\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8654767935778029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:47] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:47] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8673402510353525\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8673402510353525\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:47] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:47] Time left 12.49 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 12.49 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.853589\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.862699\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.868265\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.871723\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.873575\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.874578\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.874061\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.873476\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[634]\tvalid's auc: 0.87473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:53] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.874911\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.880654\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.883229\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.885128\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.886145\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.886042\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.886024\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.88561\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[644]\tvalid's auc: 0.886379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8863786928164779\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8863786928164779\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Time left -3.46 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left -3.46 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Blending: optimization starts with equal weights and score \u001b[1m0.8851777192839505\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.8851777192839505\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8880791863138615\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8880791863138615\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8880791863138615\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8880791863138615\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] \u001b[1mAutoml preset training completed in 21.78 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 21.78 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.23607 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.76393 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.23607 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.76393 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:03] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:05] Layer \u001b[1m1\u001b[0m train process start. Time left 16.40 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.40 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:05] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203], 'embed_sizes': array([ 8, 19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49,\n",
      "       13,  8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 204}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6490524781341108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6751794124243103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6962884054720789\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7440569634447185\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7555505718771025\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.755690737833595\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7507288629737608\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.743748598340435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:07] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:07] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:07] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:07] Time left 14.59 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 14.59 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.716865\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.718435\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.711987\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[128]\tvalid's auc: 0.726901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:09] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751626\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.748991\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.745935\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[148]\tvalid's auc: 0.752635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:11] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:11] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5284257\tbest: 0.5284257 (0)\ttotal: 4.97ms\tremaining: 2.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6480713\tbest: 0.6538181 (91)\ttotal: 398ms\tremaining: 1.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6696008\tbest: 0.6750953 (140)\ttotal: 787ms\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6842902\tbest: 0.6928403 (264)\ttotal: 1.2s\tremaining: 790ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6928403229\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 264\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 265 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5169741\tbest: 0.5169741 (0)\ttotal: 4.46ms\tremaining: 2.22s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7313019\tbest: 0.7313019 (100)\ttotal: 410ms\tremaining: 1.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7190514\tbest: 0.7316663 (121)\ttotal: 795ms\tremaining: 1.18s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7316662929\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 121\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 122 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7063663377438889\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7063663377438889\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Time left 7.26 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 7.26 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Blending: optimization starts with equal weights and score \u001b[1m0.7444704530163715\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7444704530163715\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7632036331015922\u001b[0m, weights = \u001b[1m[0.59691685 0.40308318 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7632036331015922\u001b[0m, weights = \u001b[1m[0.59691685 0.40308318 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.748486207669881\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] \u001b[1mAutoml preset training completed in 11.15 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 11.15 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:14] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:15] Layer \u001b[1m1\u001b[0m train process start. Time left 16.85 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.85 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:16] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 190}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7234935163996948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7311975591151791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7366132723112128\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7450800915331808\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.745537757437071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7456140350877192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.743020594965675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7386727688787186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:17] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:17] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:17] Time left 15.68 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 15.68 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.719527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736156\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.741266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:18] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.737147\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.73341\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.749428\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.726926\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.72746\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.722502\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.739512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:19] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:19] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-d09005f2-4026-477a-8e9f-63521fec3732\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.685278\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.693898\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.705187\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.711137\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.711899\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.714874\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.713654\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[592]\tvalid's auc: 0.716247\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7162471395881007 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.7162471395881007.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.7162471395881007 in 0:00:03.523253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:23] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve 0.7162 auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5727689\tbest: 0.5727689 (0)\ttotal: 2.63ms\tremaining: 1.31s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7062548\tbest: 0.7141876 (47)\ttotal: 224ms\tremaining: 885ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7240275\tbest: 0.7278413 (194)\ttotal: 447ms\tremaining: 665ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7278413425\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5815408\tbest: 0.5815408 (0)\ttotal: 2.58ms\tremaining: 1.29s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7398932\tbest: 0.7468345 (88)\ttotal: 226ms\tremaining: 892ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7468344775\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4952996\tbest: 0.4952996 (0)\ttotal: 2.24ms\tremaining: 1.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6314924\tbest: 0.6426165 (72)\ttotal: 218ms\tremaining: 863ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6426165296\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:25] Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:25] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:25] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-deba6e41-7954-4ac7-b4da-c3ba55529202\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5331426\tbest: 0.5331426 (0)\ttotal: 1.91ms\tremaining: 952ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7044241\tbest: 0.7244851 (58)\ttotal: 169ms\tremaining: 667ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7244851259\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7244851258581235 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7244851258581235.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7244851258581235 in 0:00:00.481593\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.4ms\tremaining: 698ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7245614\tbest: 0.7290618 (50)\ttotal: 131ms\tremaining: 516ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7488940\tbest: 0.7490465 (197)\ttotal: 263ms\tremaining: 392ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7537757\tbest: 0.7571320 (273)\ttotal: 401ms\tremaining: 265ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7571319603\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7571319603356217 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.7571319603356217.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7571319603356217 in 0:00:00.644062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:26] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 0.7571 auc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.55ms\tremaining: 4.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7250953\tbest: 0.7370709 (13)\ttotal: 145ms\tremaining: 4.17s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7370709382\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5556064\tbest: 0.5556064 (0)\ttotal: 1.48ms\tremaining: 4.42s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650648\tbest: 0.7718535 (86)\ttotal: 133ms\tremaining: 3.81s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7718535469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 86\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 87 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5537799\tbest: 0.5537799 (0)\ttotal: 1.42ms\tremaining: 4.26s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6231884\tbest: 0.6231884 (100)\ttotal: 130ms\tremaining: 3.73s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6173130\tbest: 0.6308656 (110)\ttotal: 273ms\tremaining: 3.8s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6308656483\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6509597\tbest: 0.6509597 (0)\ttotal: 1.54ms\tremaining: 4.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7686643\tbest: 0.7754798 (95)\ttotal: 126ms\tremaining: 3.63s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7754798277\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5874657\tbest: 0.5874657 (0)\ttotal: 1.42ms\tremaining: 4.27s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6279671\tbest: 0.6520956 (66)\ttotal: 129ms\tremaining: 3.71s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6520955738\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 66\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 67 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:27] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:27] Time left 4.89 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 4.89 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:27] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:27] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:27] Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] \u001b[1mAutoml preset training completed in 13.59 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 13.59 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:28] \u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:30] Layer \u001b[1m1\u001b[0m train process start. Time left 16.59 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.59 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:31] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], 'embed_sizes': array([ 6,  5,  3,  3,  9,  7,  3,  5, 49, 13,  8, 36, 13,  8],\n",
      "      dtype=int32), 'data_size': 186}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07093726938398473\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.0704291346516548\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07031142141410163\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07037027532245685\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07057521661797152\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.06212071301845505\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06166575830034786\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.06164247941905598\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06216234322604961\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06256765384868207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:31] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:31] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0659769504165788\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0659769504165788\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:31] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:31] Time left 15.13 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 15.13 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0701653\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0703635\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0706011\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[111]\tvalid's l2: 0.0701198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:33] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0700265\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0699663\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0702125\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[162]\tvalid's l2: 0.0698633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:36] Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.0698632892768944\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.0698632892768944\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:36] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2458766\ttest: 0.2672492\tbest: 0.2672492 (0)\ttotal: 3.12ms\tremaining: 6.24s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2224887\ttest: 0.2672056\tbest: 0.2667037 (20)\ttotal: 267ms\tremaining: 5.03s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2014391\ttest: 0.2686460\tbest: 0.2667037 (20)\ttotal: 529ms\tremaining: 4.74s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1782851\ttest: 0.2697492\tbest: 0.2667037 (20)\ttotal: 792ms\tremaining: 4.47s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2667037312\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 20\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 21 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2505670\ttest: 0.2500807\tbest: 0.2500807 (0)\ttotal: 2.75ms\tremaining: 5.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2290464\ttest: 0.2464674\tbest: 0.2462925 (76)\ttotal: 264ms\tremaining: 4.97s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2086461\ttest: 0.2465990\tbest: 0.2460105 (109)\ttotal: 518ms\tremaining: 4.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1862601\ttest: 0.2472577\tbest: 0.2460105 (109)\ttotal: 769ms\tremaining: 4.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1669461\ttest: 0.2485226\tbest: 0.2460105 (109)\ttotal: 1.02s\tremaining: 4.06s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2460104782\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 109\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 110 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:38] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.0658260178572445\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.0658260178572445\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:38] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:38] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-39fea1bf-97cc-47ce-951e-389a90cb7ce0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2459449\ttest: 0.2669882\tbest: 0.2669882 (0)\ttotal: 2.01ms\tremaining: 4.03s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2275001\ttest: 0.2639859\tbest: 0.2637316 (56)\ttotal: 192ms\tremaining: 3.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2125453\ttest: 0.2633641\tbest: 0.2631804 (191)\ttotal: 387ms\tremaining: 3.46s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1963823\ttest: 0.2646464\tbest: 0.2631804 (191)\ttotal: 578ms\tremaining: 3.26s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1822437\ttest: 0.2653673\tbest: 0.2631804 (191)\ttotal: 771ms\tremaining: 3.07s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2631803824\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 191\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 192 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.06926391402910047 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.06926391402910047.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.06926391402910047 in 0:00:01.237168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:39] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}\u001b[0m\n",
      " achieve -0.0693 mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.0024430162614261413, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2461236\ttest: 0.2670701\tbest: 0.2670701 (0)\ttotal: 2.02ms\tremaining: 6.07s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2333416\ttest: 0.2640407\tbest: 0.2640344 (99)\ttotal: 207ms\tremaining: 5.93s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2248658\ttest: 0.2636474\tbest: 0.2635485 (190)\ttotal: 396ms\tremaining: 5.51s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2151160\ttest: 0.2627348\tbest: 0.2626105 (275)\ttotal: 584ms\tremaining: 5.23s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2626104802\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 275\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 276 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2507162\ttest: 0.2499679\tbest: 0.2499679 (0)\ttotal: 2.56ms\tremaining: 7.67s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2383735\ttest: 0.2468338\tbest: 0.2466842 (73)\ttotal: 191ms\tremaining: 5.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2298061\ttest: 0.2459577\tbest: 0.2459577 (200)\ttotal: 398ms\tremaining: 5.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2210035\ttest: 0.2452926\tbest: 0.2452596 (292)\ttotal: 593ms\tremaining: 5.32s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2103936\ttest: 0.2454534\tbest: 0.2451068 (308)\ttotal: 802ms\tremaining: 5.2s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2451068453\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 308\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 309 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2519872\ttest: 0.2442943\tbest: 0.2442943 (0)\ttotal: 2.05ms\tremaining: 6.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2384762\ttest: 0.2431292\tbest: 0.2428909 (44)\ttotal: 197ms\tremaining: 5.64s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2428908884\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 44\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 45 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2489931\ttest: 0.2564218\tbest: 0.2564218 (0)\ttotal: 1.95ms\tremaining: 5.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2360685\ttest: 0.2550071\tbest: 0.2549925 (91)\ttotal: 197ms\tremaining: 5.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2281250\ttest: 0.2541582\tbest: 0.2541086 (197)\ttotal: 397ms\tremaining: 5.53s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2189342\ttest: 0.2538045\tbest: 0.2537417 (299)\ttotal: 582ms\tremaining: 5.22s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2086248\ttest: 0.2535272\tbest: 0.2533319 (326)\ttotal: 776ms\tremaining: 5.03s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2533319468\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 326\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 327 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2544000\ttest: 0.2342332\tbest: 0.2342332 (0)\ttotal: 1.93ms\tremaining: 5.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2421512\ttest: 0.2323043\tbest: 0.2322915 (99)\ttotal: 195ms\tremaining: 5.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2336028\ttest: 0.2326681\tbest: 0.2321042 (124)\ttotal: 390ms\tremaining: 5.43s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2321042008\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 124\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 125 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.06121859903579186\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.06121859903579186\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Time left 3.30 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 3.30 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Blending: optimization starts with equal weights and score \u001b[1m-0.06141709163244357\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.06141709163244357\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06121859903579186\u001b[0m, weights = \u001b[1m[0. 0. 0. 1.]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] \u001b[1mAutoml preset training completed in 14.98 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 14.98 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:43] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:44] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:44] Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:44] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:44] - time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- time: 18.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:44] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:44] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:44] \u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:45] Layer \u001b[1m1\u001b[0m train process start. Time left 16.88 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 16.88 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([16,  6, 10,  3,  3, 11,  5,  4, 13, 11, 35,  3,  4, 47, 13,  8, 24,\n",
      "       13,  8, 11], dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07449485797186384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07423297648580518\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0742281102128536\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07548342725769143\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07662500792022853\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07697611915152407\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07627645175899474\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07609266747410862\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07657355182780512\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07721748413374047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:46] Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:46] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0751603888434811\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0751603888434811\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:46] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:46] Time left 15.63 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 15.63 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767461\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0784016\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[3]\tvalid's l2: 0.0744974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:47] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767052\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0793602\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.0745394\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0772268\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0787542\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[41]\tvalid's l2: 0.0768315\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0891813\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0883896\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0882638\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's l2: 0.0885805\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[278]\tvalid's l2: 0.088093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:49] Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.07981406994276753\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.07981406994276753\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:49] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:49] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-fc9f572c-bdbe-4e85-95c0-8a6682acaa9a\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0777606\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.081215\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[5]\tvalid's l2: 0.0744279\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.07442791311914856 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: -0.07442791311914856.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.07442791311914856 in 0:00:00.669813\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0761122\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0785505\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[5]\tvalid's l2: 0.0744357\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.07443573690859956 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 0 with value: -0.07442791311914856.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -0.07443573690859956 in 0:00:00.455836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:50] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve -0.0744 mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2931105\ttest: 0.2730306\tbest: 0.2730306 (0)\ttotal: 1.5ms\tremaining: 3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2539640\ttest: 0.2789047\tbest: 0.2730306 (0)\ttotal: 93.1ms\tremaining: 1.75s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2209009\ttest: 0.2840797\tbest: 0.2730306 (0)\ttotal: 183ms\tremaining: 1.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1905947\ttest: 0.2888705\tbest: 0.2730306 (0)\ttotal: 281ms\tremaining: 1.58s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730305773\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2918162\ttest: 0.2783974\tbest: 0.2783974 (0)\ttotal: 990us\tremaining: 1.98s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2541574\ttest: 0.2771797\tbest: 0.2761792 (42)\ttotal: 114ms\tremaining: 2.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2214694\ttest: 0.2806531\tbest: 0.2761792 (42)\ttotal: 200ms\tremaining: 1.79s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1907055\ttest: 0.2856095\tbest: 0.2761792 (42)\ttotal: 305ms\tremaining: 1.72s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2761791533\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2858305\ttest: 0.3014090\tbest: 0.3014090 (0)\ttotal: 905us\tremaining: 1.81s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2524039\ttest: 0.2927180\tbest: 0.2923455 (89)\ttotal: 84ms\tremaining: 1.58s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2186045\ttest: 0.2916859\tbest: 0.2908069 (148)\ttotal: 176ms\tremaining: 1.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1887229\ttest: 0.2944040\tbest: 0.2908069 (148)\ttotal: 265ms\tremaining: 1.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1652364\ttest: 0.2963591\tbest: 0.2908069 (148)\ttotal: 349ms\tremaining: 1.39s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2908068672\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 148\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 149 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2898185\ttest: 0.2854178\tbest: 0.2854178 (0)\ttotal: 920us\tremaining: 1.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2569051\ttest: 0.2821814\tbest: 0.2813736 (83)\ttotal: 92.1ms\tremaining: 1.73s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2260265\ttest: 0.2835825\tbest: 0.2813736 (83)\ttotal: 212ms\tremaining: 1.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1946849\ttest: 0.2851189\tbest: 0.2813736 (83)\ttotal: 439ms\tremaining: 2.48s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2813735614\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 83\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 84 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2842533\ttest: 0.3080572\tbest: 0.3080572 (0)\ttotal: 8.57ms\tremaining: 17.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2494624\ttest: 0.3061037\tbest: 0.3055388 (76)\ttotal: 192ms\tremaining: 3.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2168374\ttest: 0.3099174\tbest: 0.3055388 (76)\ttotal: 464ms\tremaining: 4.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1874059\ttest: 0.3135705\tbest: 0.3055388 (76)\ttotal: 728ms\tremaining: 4.11s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.305538818\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.08157640428059512\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.08157640428059512\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:54] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:54] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-7787fe28-b007-4e0d-ab51-b395a16444ec\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2930198\ttest: 0.2730346\tbest: 0.2730346 (0)\ttotal: 1.06ms\tremaining: 2.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2626308\ttest: 0.2786636\tbest: 0.2730346 (0)\ttotal: 114ms\tremaining: 2.14s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2405736\ttest: 0.2827328\tbest: 0.2730346 (0)\ttotal: 283ms\tremaining: 2.53s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2190736\ttest: 0.2884436\tbest: 0.2730346 (0)\ttotal: 436ms\tremaining: 2.46s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730345851\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.07454788496599066 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.07454788496599066.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.07454788496599066 in 0:00:00.603172\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934392\ttest: 0.2730211\tbest: 0.2730211 (0)\ttotal: 1.72ms\tremaining: 3.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2762059\ttest: 0.2753635\tbest: 0.2727228 (1)\ttotal: 158ms\tremaining: 2.97s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2624159\ttest: 0.2795560\tbest: 0.2727228 (1)\ttotal: 296ms\tremaining: 2.65s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2485725\ttest: 0.2823829\tbest: 0.2727228 (1)\ttotal: 441ms\tremaining: 2.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2727227973\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.0743777244717666 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: -0.0743777244717666.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.0743777244717666 in 0:00:00.640789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:55] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve -0.0744 mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934784\ttest: 0.2729962\tbest: 0.2729962 (0)\ttotal: 802us\tremaining: 2.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2818340\ttest: 0.2741072\tbest: 0.2728140 (1)\ttotal: 147ms\tremaining: 4.23s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2728139952\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2922093\ttest: 0.2783588\tbest: 0.2783588 (0)\ttotal: 727us\tremaining: 2.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2810769\ttest: 0.2773695\tbest: 0.2769822 (47)\ttotal: 171ms\tremaining: 4.91s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.276982158\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 47\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 48 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861366\ttest: 0.3015423\tbest: 0.3015423 (0)\ttotal: 888us\tremaining: 2.67s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2772255\ttest: 0.2969880\tbest: 0.2969693 (98)\ttotal: 121ms\tremaining: 3.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2709455\ttest: 0.2946255\tbest: 0.2946255 (200)\ttotal: 250ms\tremaining: 3.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2631038\ttest: 0.2944812\tbest: 0.2941193 (232)\ttotal: 404ms\tremaining: 3.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2542972\ttest: 0.2939738\tbest: 0.2939332 (398)\ttotal: 513ms\tremaining: 3.33s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2460596\ttest: 0.2939382\tbest: 0.2937820 (437)\ttotal: 673ms\tremaining: 3.36s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2388632\ttest: 0.2942461\tbest: 0.2936949 (523)\ttotal: 855ms\tremaining: 3.41s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2936949357\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 523\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 524 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2903441\ttest: 0.2855145\tbest: 0.2855145 (0)\ttotal: 808us\tremaining: 2.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2795591\ttest: 0.2831798\tbest: 0.2830037 (88)\ttotal: 161ms\tremaining: 4.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2728036\ttest: 0.2829451\tbest: 0.2826681 (152)\ttotal: 319ms\tremaining: 4.44s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2826680991\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 152\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 153 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2845696\ttest: 0.3080152\tbest: 0.3080152 (0)\ttotal: 2.09ms\tremaining: 6.25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2734893\ttest: 0.3051467\tbest: 0.3051377 (97)\ttotal: 169ms\tremaining: 4.85s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2667275\ttest: 0.3047669\tbest: 0.3046522 (189)\ttotal: 324ms\tremaining: 4.51s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3046522413\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.08201676262610579\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.08201676262610579\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Time left 4.26 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time left 4.26 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Blending: optimization starts with equal weights and score \u001b[1m-0.0816802138062263\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.0816802138062263\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.08140335128118426\u001b[0m, weights = \u001b[1m[0.5450377 0.        0.4549623 0.       ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.08140335128118426\u001b[0m, weights = \u001b[1m[0.5450377 0.        0.4549623 0.       ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.08140164609517518\u001b[0m, weights = \u001b[1m[0.60477763 0.         0.39522237 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.08140164609517518\u001b[0m, weights = \u001b[1m[0.60477763 0.         0.39522237 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.08140164609517518\u001b[0m, weights = \u001b[1m[0.60477763 0.         0.39522237 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.08140164609517518\u001b[0m, weights = \u001b[1m[0.60477763 0.         0.39522237 0.        ]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] \u001b[1mAutoml preset training completed in 14.11 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 14.11 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.60478 * (2 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.39522 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.60478 * (2 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.39522 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] Uplift candidate #4 [__XLearner__TabularAutoML__] is fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #4 [__XLearner__TabularAutoML__] is fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:54:00] Time of training exceeds 'timeout': 237.88137936592102 > 200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lightautoml.addons.uplift.base:Time of training exceeds 'timeout': 237.88137936592102 > 200.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:54:00] There is fitted 5/5 candidates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lightautoml.addons.uplift.base:There is fitted 5/5 candidates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 10s, sys: 12 s, total: 5min 22s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "autouplift = AutoUplift(task,\n",
    "                        metric='adj_qini',\n",
    "                        has_report=True,\n",
    "                        test_size=0.2,\n",
    "                        timeout=200,\n",
    ")\n",
    "\n",
    "autouplift.fit(train, roles, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQUiEz3O0jG8"
   },
   "source": [
    "### Show rating of uplift methods (meta-learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cQTsREtB0jG8",
    "outputId": "0cc0ded9-6f34-4ceb-aa66-1403fe60cb9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ced14510-d001-4304-8ee2-457518bdf768\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetaLearner</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Metrics</th>\n",
       "      <th>WorkTime</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__XLearner__TabularAutoML__</td>\n",
       "      <td>{'timeout': None, 'outcome_learners': [BaseLea...</td>\n",
       "      <td>0.160781</td>\n",
       "      <td>76.808822</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__XLearner__Propensity_Linear__Other_TabularAu...</td>\n",
       "      <td>{'timeout': None, 'outcome_learners': [BaseLea...</td>\n",
       "      <td>0.128359</td>\n",
       "      <td>69.951428</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__TLearner__TabularAutoML__</td>\n",
       "      <td>{'timeout': None, 'treatment_learner': BaseLea...</td>\n",
       "      <td>0.064424</td>\n",
       "      <td>24.448092</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__XLearner__Default__</td>\n",
       "      <td>{'base_task': &lt;lightautoml.tasks.base.Task obj...</td>\n",
       "      <td>0.056549</td>\n",
       "      <td>46.010798</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__TLearner__Default__</td>\n",
       "      <td>{'base_task': &lt;lightautoml.tasks.base.Task obj...</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>14.582936</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ced14510-d001-4304-8ee2-457518bdf768')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ced14510-d001-4304-8ee2-457518bdf768 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ced14510-d001-4304-8ee2-457518bdf768');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                         MetaLearner  \\\n",
       "0                        __XLearner__TabularAutoML__   \n",
       "1  __XLearner__Propensity_Linear__Other_TabularAu...   \n",
       "2                        __TLearner__TabularAutoML__   \n",
       "3                              __XLearner__Default__   \n",
       "4                              __TLearner__Default__   \n",
       "\n",
       "                                          Parameters   Metrics   WorkTime  \\\n",
       "0  {'timeout': None, 'outcome_learners': [BaseLea...  0.160781  76.808822   \n",
       "1  {'timeout': None, 'outcome_learners': [BaseLea...  0.128359  69.951428   \n",
       "2  {'timeout': None, 'treatment_learner': BaseLea...  0.064424  24.448092   \n",
       "3  {'base_task': <lightautoml.tasks.base.Task obj...  0.056549  46.010798   \n",
       "4  {'base_task': <lightautoml.tasks.base.Task obj...  0.025919  14.582936   \n",
       "\n",
       "   Rank  \n",
       "0   1.0  \n",
       "1   2.0  \n",
       "2   3.0  \n",
       "3   4.0  \n",
       "4   5.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_table = autouplift.get_metalearners_rating()\n",
    "rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0uA0zrc0jG8"
   },
   "source": [
    "###  Get best metalearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDP_lQm-0jG8",
    "outputId": "0d42e276-fa60-49a5-e6c4-78ec4e5adc62",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 100.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (7000, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 97.84 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181], 'embed_sizes': array([35, 20,  6,  3,  9,  9,  7,  3,  6, 49, 13,  8, 38, 13,  8],\n",
      "      dtype=int32), 'data_size': 182}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7632613746721245\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.771351618729522\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7762096225233484\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7992425961390103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8110733442852086\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8343717949881557\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8423724121656577\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.855262799626063\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.857720164459652\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8592994127737592\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8592994127737592\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8582987683678377\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7814136541446193\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7906021111101026\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7974364443314969\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8218762196062771\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8328106989535211\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8523153232467167\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8586209713284746\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8672886847765908\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8683551311955999\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8678604815799744\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8678604815799744\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.863421681990216\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 91.14 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847253\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.856556\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.860906\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.864448\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.865911\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.866674\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.866864\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.86701\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.867028\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.867611\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.868353\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.868487\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.868115\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1172]\tvalid's auc: 0.868634\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.856113\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.865426\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.871123\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.873808\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.875371\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.876723\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.877191\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.877184\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.87737\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.877699\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.877953\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.878321\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.878191\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's auc: 0.878137\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1500]\tvalid's auc: 0.878064\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1600]\tvalid's auc: 0.878346\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1430]\tvalid's auc: 0.878464\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8784636818268453\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 5000, 'learning_rate': 0.035, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7755357\tbest: 0.7755357 (0)\ttotal: 6.43ms\tremaining: 32.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8580968\tbest: 0.8580968 (100)\ttotal: 547ms\tremaining: 26.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8638057\tbest: 0.8641415 (193)\ttotal: 1.08s\tremaining: 25.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8670527\tbest: 0.8671140 (299)\ttotal: 1.6s\tremaining: 25.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8713548\tbest: 0.8716861 (391)\ttotal: 2.13s\tremaining: 24.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8743749\tbest: 0.8749376 (483)\ttotal: 2.66s\tremaining: 23.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8770478\tbest: 0.8770773 (572)\ttotal: 3.21s\tremaining: 23.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8778624\tbest: 0.8780666 (649)\ttotal: 3.75s\tremaining: 23s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8790083\tbest: 0.8794280 (794)\ttotal: 4.27s\tremaining: 22.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.8799317\tbest: 0.8799317 (900)\ttotal: 4.82s\tremaining: 21.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:1000:\ttest: 0.8796186\tbest: 0.8800634 (949)\ttotal: 5.35s\tremaining: 21.4s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8800633515\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 949\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 950 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8124427\tbest: 0.8124427 (0)\ttotal: 5.88ms\tremaining: 29.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8679603\tbest: 0.8679603 (100)\ttotal: 548ms\tremaining: 26.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8737101\tbest: 0.8737554 (192)\ttotal: 1.08s\tremaining: 25.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8754731\tbest: 0.8759541 (288)\ttotal: 1.61s\tremaining: 25.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8764556\tbest: 0.8764556 (400)\ttotal: 2.15s\tremaining: 24.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8772724\tbest: 0.8774267 (488)\ttotal: 2.68s\tremaining: 24.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8776945\tbest: 0.8783162 (548)\ttotal: 3.22s\tremaining: 23.6s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8783161946\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 548\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 549 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8263326\tbest: 0.8263326 (0)\ttotal: 5.76ms\tremaining: 28.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8820760\tbest: 0.8822779 (99)\ttotal: 535ms\tremaining: 26s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8877508\tbest: 0.8877508 (200)\ttotal: 1.08s\tremaining: 25.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8895343\tbest: 0.8900153 (294)\ttotal: 1.65s\tremaining: 25.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8917443\tbest: 0.8923025 (374)\ttotal: 2.18s\tremaining: 25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8925703\tbest: 0.8928153 (433)\ttotal: 2.72s\tremaining: 24.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8920734\tbest: 0.8931330 (510)\ttotal: 3.24s\tremaining: 23.8s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8931329927\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 510\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 511 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.88286510536894\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-87ee3aa0-f77d-4ae6-8777-c0fabd28084d\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7725610\tbest: 0.7725610 (0)\ttotal: 4.47ms\tremaining: 2.23s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8409338\tbest: 0.8409338 (100)\ttotal: 430ms\tremaining: 1.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8539694\tbest: 0.8539876 (198)\ttotal: 869ms\tremaining: 1.29s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8598735\tbest: 0.8599189 (283)\ttotal: 1.28s\tremaining: 850ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8629730\tbest: 0.8629730 (400)\ttotal: 1.7s\tremaining: 419ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.8681986\tbest: 0.8682553 (498)\ttotal: 2.13s\tremaining: 0us\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8682552937\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 498\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 499 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.8682552936585012 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.8682552936585012.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.8682552936585012 in 0:00:02.417996\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}\u001b[0m\n",
      " achieve 0.8683 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.0024430162614261413, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7725610\tbest: 0.7725610 (0)\ttotal: 4.35ms\tremaining: 13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8485238\tbest: 0.8485238 (100)\ttotal: 428ms\tremaining: 12.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8607085\tbest: 0.8608401 (198)\ttotal: 860ms\tremaining: 12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8657435\tbest: 0.8657435 (300)\ttotal: 1.28s\tremaining: 11.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8717791\tbest: 0.8718517 (398)\ttotal: 1.7s\tremaining: 11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8738575\tbest: 0.8738575 (500)\ttotal: 2.11s\tremaining: 10.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8756024\tbest: 0.8756773 (599)\ttotal: 2.54s\tremaining: 10.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8778896\tbest: 0.8780825 (684)\ttotal: 2.96s\tremaining: 9.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8783548\tbest: 0.8783797 (797)\ttotal: 3.37s\tremaining: 9.25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.8787541\tbest: 0.8788517 (857)\ttotal: 3.79s\tremaining: 8.84s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8788516868\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 857\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 858 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7935178\tbest: 0.7935178 (0)\ttotal: 4.24ms\tremaining: 12.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8633791\tbest: 0.8633791 (98)\ttotal: 431ms\tremaining: 12.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8707308\tbest: 0.8707308 (200)\ttotal: 842ms\tremaining: 11.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8744611\tbest: 0.8745746 (297)\ttotal: 1.25s\tremaining: 11.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8752961\tbest: 0.8756229 (398)\ttotal: 1.72s\tremaining: 11.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8762604\tbest: 0.8766780 (472)\ttotal: 2.13s\tremaining: 10.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8764397\tbest: 0.8768368 (555)\ttotal: 2.56s\tremaining: 10.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8770523\tbest: 0.8772248 (697)\ttotal: 2.97s\tremaining: 9.75s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8772247888\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 697\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 698 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8108578\tbest: 0.8108578 (0)\ttotal: 4.45ms\tremaining: 13.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8760721\tbest: 0.8761130 (99)\ttotal: 435ms\tremaining: 12.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8859855\tbest: 0.8860037 (199)\ttotal: 845ms\tremaining: 11.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8916785\tbest: 0.8917080 (299)\ttotal: 1.27s\tremaining: 11.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8950980\tbest: 0.8951456 (399)\ttotal: 1.68s\tremaining: 10.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8973080\tbest: 0.8973080 (500)\ttotal: 2.1s\tremaining: 10.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8988487\tbest: 0.8991255 (589)\ttotal: 2.52s\tremaining: 10s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8990733\tbest: 0.8994250 (670)\ttotal: 2.95s\tremaining: 9.67s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.9009339\tbest: 0.9009339 (800)\ttotal: 3.36s\tremaining: 9.23s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:900:\ttest: 0.9014830\tbest: 0.9015352 (892)\ttotal: 3.77s\tremaining: 8.79s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.901535229\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 892\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 893 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8054870\tbest: 0.8054870 (0)\ttotal: 4.35ms\tremaining: 13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8721512\tbest: 0.8721512 (100)\ttotal: 424ms\tremaining: 12.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8790967\tbest: 0.8790967 (200)\ttotal: 856ms\tremaining: 11.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8826047\tbest: 0.8826047 (300)\ttotal: 1.27s\tremaining: 11.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8863735\tbest: 0.8864008 (399)\ttotal: 1.7s\tremaining: 11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8882909\tbest: 0.8884883 (495)\ttotal: 2.11s\tremaining: 10.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8890192\tbest: 0.8890692 (594)\ttotal: 2.52s\tremaining: 10.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8888944\tbest: 0.8894980 (616)\ttotal: 2.94s\tremaining: 9.65s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8894979987\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 616\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 617 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7895765\tbest: 0.7895765 (0)\ttotal: 4.28ms\tremaining: 12.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8569578\tbest: 0.8570031 (96)\ttotal: 418ms\tremaining: 12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8671820\tbest: 0.8673885 (198)\ttotal: 843ms\tremaining: 11.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.8733629\tbest: 0.8733629 (300)\ttotal: 1.29s\tremaining: 11.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.8760449\tbest: 0.8760449 (400)\ttotal: 1.72s\tremaining: 11.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.8784070\tbest: 0.8785613 (497)\ttotal: 2.14s\tremaining: 10.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.8794303\tbest: 0.8798773 (561)\ttotal: 2.57s\tremaining: 10.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.8807327\tbest: 0.8807599 (696)\ttotal: 2.98s\tremaining: 9.77s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:800:\ttest: 0.8807463\tbest: 0.8808734 (719)\ttotal: 3.38s\tremaining: 9.29s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8808733969\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 719\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 720 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8851491663565652\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 18.60 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.8857321268118244\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8861710035487705\u001b[0m, weights = \u001b[1m[0.16684383 0.08687391 0.21573344 0.5305488 ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8861873406002959\u001b[0m, weights = \u001b[1m[0.12729853 0.09082355 0.26456693 0.517311  ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8861873406002959\u001b[0m, weights = \u001b[1m[0.12729853 0.09082355 0.26456693 0.517311  ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 81.76 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.12730 * (2 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.09082 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.26457 * (3 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.51731 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 100.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (4610, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 98.15 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], 'embed_sizes': array([30, 18,  6,  5,  3, 19, 17, 17,  9,  4,  3, 49, 13,  8, 37, 13,  8,\n",
      "       11, 11,  7,  7,  8,  7, 11, 11], dtype=int32), 'data_size': 192}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6278879813302218\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6539269365407054\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6710618436406067\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7150884121712594\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7298267659994614\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7528588098016337\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7579750471232385\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7638273045507584\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7615653891033121\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7536666367471502\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6575352302306795\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6785746342339108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6940490081680282\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7221793375819047\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7249977560362625\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7099362714298537\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6979804326362086\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6331209047661791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6616461717978638\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6831523202585048\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7349519791760165\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7519791760165156\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7687819764832601\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.769607755138677\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7595009424647698\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7512970110403016\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7540296602140244\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 93.07 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751566\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.753954\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.755605\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.754385\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.753128\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[306]\tvalid's auc: 0.757365\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.776645\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.775191\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.770757\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[190]\tvalid's auc: 0.77862\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.703833\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.703922\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.694031\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[149]\tvalid's auc: 0.706669\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.77187\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.783018\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.793591\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.797936\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.803501\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.809461\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.81025\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.809855\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.808886\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.807306\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[806]\tvalid's auc: 0.810807\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7642122689963997\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2be29827-61f2-42d8-a59e-7c90a34a735b\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756359\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.758711\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.760901\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.763019\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.764474\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.764043\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[418]\tvalid's auc: 0.76582\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7658199443496994 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.7658199443496994.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.7658199443496994 in 0:00:12.429612\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve 0.7658 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5267211\tbest: 0.5267211 (0)\ttotal: 5.14ms\tremaining: 2.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6979625\tbest: 0.7114622 (81)\ttotal: 450ms\tremaining: 1.78s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7184992\tbest: 0.7184992 (200)\ttotal: 913ms\tremaining: 1.36s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7207971\tbest: 0.7225563 (274)\ttotal: 1.35s\tremaining: 894ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7082129\tbest: 0.7231667 (325)\ttotal: 1.8s\tremaining: 445ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7231666816\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 325\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 326 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5962212\tbest: 0.5962212 (0)\ttotal: 4.57ms\tremaining: 2.28s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6615385\tbest: 0.6615385 (100)\ttotal: 440ms\tremaining: 1.74s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6802800\tbest: 0.6831164 (161)\ttotal: 913ms\tremaining: 1.36s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6761332\tbest: 0.6845526 (212)\ttotal: 1.34s\tremaining: 888ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6845525536\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 212\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 213 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5565210\tbest: 0.5565210 (0)\ttotal: 4.71ms\tremaining: 2.35s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6874787\tbest: 0.6874787 (100)\ttotal: 461ms\tremaining: 1.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7129701\tbest: 0.7141011 (198)\ttotal: 889ms\tremaining: 1.32s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7064716\tbest: 0.7168836 (217)\ttotal: 1.35s\tremaining: 892ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7168835832\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 217\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 218 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5123059\tbest: 0.5123059 (0)\ttotal: 4.38ms\tremaining: 2.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6568710\tbest: 0.6568710 (100)\ttotal: 444ms\tremaining: 1.75s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6664931\tbest: 0.6690961 (193)\ttotal: 900ms\tremaining: 1.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6660802\tbest: 0.6710349 (298)\ttotal: 1.37s\tremaining: 906ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6710349161\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 298\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 299 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6071717\tbest: 0.6071717 (0)\ttotal: 4.64ms\tremaining: 2.31s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7393232\tbest: 0.7508123 (70)\ttotal: 440ms\tremaining: 1.74s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7508123149\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 70\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 71 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.682532627232744\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 11.17 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-ce39ceb0-cbc3-4400-89ab-bd87f0f4df1e\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5222601\tbest: 0.5222601 (0)\ttotal: 3.8ms\tremaining: 1.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7312270\tbest: 0.7312270 (100)\ttotal: 346ms\tremaining: 1.37s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7293062\tbest: 0.7334889 (140)\ttotal: 676ms\tremaining: 1.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7335248\tbest: 0.7372408 (252)\ttotal: 1.02s\tremaining: 675ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7320169\tbest: 0.7380846 (341)\ttotal: 1.35s\tremaining: 334ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7380845526\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 341\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 342 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7380845525536308 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7380845525536308.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7380845525536308 in 0:00:01.721507\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5347366\tbest: 0.5347366 (0)\ttotal: 2.87ms\tremaining: 1.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7281573\tbest: 0.7281573 (100)\ttotal: 262ms\tremaining: 1.04s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7306525\tbest: 0.7360201 (154)\ttotal: 514ms\tremaining: 765ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7360201059\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 154\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 155 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7360201059150886 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.7380845525536308.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7360201059150886 in 0:00:00.887528\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5171529\tbest: 0.5171529 (0)\ttotal: 2.8ms\tremaining: 1.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7379768\tbest: 0.7388744 (97)\ttotal: 276ms\tremaining: 1.09s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7575981\tbest: 0.7608473 (179)\ttotal: 535ms\tremaining: 796ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7561799\tbest: 0.7623014 (273)\ttotal: 794ms\tremaining: 525ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7623014092\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: 0.7623014092092272 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 2 with value: 0.7623014092092272.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.7623014092092272 in 0:00:01.202470\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5347366\tbest: 0.5347366 (0)\ttotal: 2.8ms\tremaining: 1.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6976753\tbest: 0.6981061 (98)\ttotal: 259ms\tremaining: 1.02s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7085540\tbest: 0.7124495 (127)\ttotal: 510ms\tremaining: 759ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7124495108\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 127\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 128 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: 0.7124495108159052 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 2 with value: 0.7623014092092272.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored 0.7124495108159052 in 0:00:00.986529\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5259492\tbest: 0.5259492 (0)\ttotal: 7.46ms\tremaining: 3.72s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6591509\tbest: 0.6591509 (100)\ttotal: 601ms\tremaining: 2.37s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6967418\tbest: 0.6975675 (188)\ttotal: 1.21s\tremaining: 1.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6979984\tbest: 0.7062203 (272)\ttotal: 1.78s\tremaining: 1.18s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7062202675\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 272\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 273 iterations.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: 0.7062202674804775 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 2 with value: 0.7623014092092272.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored 0.7062202674804775 in 0:00:02.478241\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5259492\tbest: 0.5259492 (0)\ttotal: 6.04ms\tremaining: 3.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6750561\tbest: 0.6878377 (82)\ttotal: 610ms\tremaining: 2.41s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6881070\tbest: 0.6936182 (159)\ttotal: 1.2s\tremaining: 1.78s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6771744\tbest: 0.6991473 (242)\ttotal: 1.83s\tremaining: 1.21s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6991472938\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 242\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 243 iterations.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: 0.6991472937797327 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 2 with value: 0.7623014092092272.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.6991472937797327 in 0:00:02.318729\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5159232\tbest: 0.5159232 (0)\ttotal: 6.43ms\tremaining: 3.21s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7602729\tbest: 0.7602729 (100)\ttotal: 615ms\tremaining: 2.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7598779\tbest: 0.7625348 (115)\ttotal: 1.2s\tremaining: 1.79s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7625347814\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 115\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 116 iterations.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: 0.762534781437932 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 6 with value: 0.762534781437932.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored 0.762534781437932 in 0:00:01.527606\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}\u001b[0m\n",
      " achieve 0.7625 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 3.4671276804481113, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 6, 'min_data_in_leaf': 20, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5159232\tbest: 0.5159232 (0)\ttotal: 5.97ms\tremaining: 17.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7598600\tbest: 0.7598600 (100)\ttotal: 601ms\tremaining: 17.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7685845\tbest: 0.7691769 (197)\ttotal: 1.21s\tremaining: 16.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7643479\tbest: 0.7702540 (210)\ttotal: 1.81s\tremaining: 16.2s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7702540167\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 210\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 211 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5346109\tbest: 0.5346109 (0)\ttotal: 6.51ms\tremaining: 19.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6799928\tbest: 0.6835652 (44)\ttotal: 606ms\tremaining: 17.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6826856\tbest: 0.6924513 (138)\ttotal: 1.2s\tremaining: 16.7s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.692451306\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 138\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 139 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5560542\tbest: 0.5560542 (0)\ttotal: 6.27ms\tremaining: 18.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7276008\tbest: 0.7281932 (95)\ttotal: 619ms\tremaining: 17.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7352123\tbest: 0.7352302 (199)\ttotal: 1.21s\tremaining: 16.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7493582\tbest: 0.7493582 (300)\ttotal: 1.8s\tremaining: 16.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7547976\tbest: 0.7547976 (400)\ttotal: 2.4s\tremaining: 15.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\ttest: 0.7620680\tbest: 0.7620680 (500)\ttotal: 3s\tremaining: 14.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\ttest: 0.7622476\tbest: 0.7630374 (521)\ttotal: 3.59s\tremaining: 14.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\ttest: 0.7582443\tbest: 0.7631810 (602)\ttotal: 4.19s\tremaining: 13.7s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.763181043\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 602\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 603 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5231487\tbest: 0.5231487 (0)\ttotal: 6.16ms\tremaining: 18.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6850552\tbest: 0.6863836 (93)\ttotal: 629ms\tremaining: 18.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6825240\tbest: 0.6874787 (167)\ttotal: 1.23s\tremaining: 17.1s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6874786823\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 167\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 168 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5839332\tbest: 0.5839332 (0)\ttotal: 6.28ms\tremaining: 18.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7520689\tbest: 0.7541513 (46)\ttotal: 597ms\tremaining: 17.1s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7541513329\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 46\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 47 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6995048918409479\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 37.29 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7150618436406067\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7702480327917901\u001b[0m, weights = \u001b[1m[0.30501038 0.6949896  0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7702480327917901\u001b[0m, weights = \u001b[1m[0.30501038 0.6949896  0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 62.90 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.30501 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.69499 * (3 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 100.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (2390, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 98.68 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], 'embed_sizes': array([ 8, 18,  4, 11, 11,  4,  7,  3,  3,  6,  6,  5,  5, 13, 10, 47, 13,\n",
      "        8, 26, 13,  8, 11], dtype=int32), 'data_size': 192}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7417975040257649\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7500503220611917\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7560889694041868\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.772493961352657\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7786332528180354\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7810990338164252\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7767713365539453\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7556863929146538\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6413585427259713\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6541936120847114\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6677198005627684\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6991657204916818\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7088413881621168\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7120995211531815\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7046946734462162\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6734462161228217\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6608579750209804\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6765562521597472\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6848990472429284\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7021770252258479\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7084464629510787\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7125438120155995\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7076072468776224\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6948709088216419\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6497507034605321\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6602162215530434\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6648565927827417\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6635730858468678\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6616478254430568\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6580934985437132\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6723108061410871\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6867996248210495\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7345115268795971\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7507034605321616\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7622550229550279\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7599842029915586\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7542577874315053\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.723074544503116\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 95.16 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.757448\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.773651\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.782105\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.782659\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.785578\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.787993\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.788446\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[546]\tvalid's auc: 0.789553\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.772645\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.778281\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.785427\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.786383\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.789201\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.788547\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[492]\tvalid's auc: 0.790006\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.703263\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.697932\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.685343\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[116]\tvalid's auc: 0.705781\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.721578\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.720195\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.729526\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.673792\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.670682\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.665301\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[110]\tvalid's auc: 0.678926\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.773856\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.785704\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.779533\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[144]\tvalid's auc: 0.789209\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7172510029652888\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-389dccfe-0ecb-4159-a757-7587ba87cbcb\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.754177\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.767462\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.775815\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.783112\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.784571\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.785376\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[455]\tvalid's auc: 0.786031\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7860305958132046 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.7860305958132046.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.7860305958132046 in 0:00:06.402081\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve 0.7860 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 244, 'feature_fraction': 0.6872700594236812, 'bagging_fraction': 0.8659969709057025, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'min_sum_hessian_in_leaf': 0.24810409748678125}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.77652\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.775211\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[162]\tvalid's auc: 0.782005\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.67779\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.684159\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[169]\tvalid's auc: 0.688898\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.732191\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.725724\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[155]\tvalid's auc: 0.739497\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.658093\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.672089\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.71832\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[24]\tvalid's auc: 0.728538\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6587479980337123\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5879378\tbest: 0.5879378 (0)\ttotal: 4.05ms\tremaining: 2.02s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7592593\tbest: 0.7592593 (100)\ttotal: 362ms\tremaining: 1.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7611212\tbest: 0.7616747 (193)\ttotal: 726ms\tremaining: 1.08s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7504026\tbest: 0.7679147 (213)\ttotal: 1.1s\tremaining: 729ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7679146538\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 213\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 214 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4985931\tbest: 0.4985931 (0)\ttotal: 3.9ms\tremaining: 1.94s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6700894\tbest: 0.6718171 (84)\ttotal: 397ms\tremaining: 1.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6778398\tbest: 0.6829244 (178)\ttotal: 768ms\tremaining: 1.14s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6762601\tbest: 0.6875154 (221)\ttotal: 1.12s\tremaining: 743ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6875154268\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 221\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 222 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5633855\tbest: 0.5633855 (0)\ttotal: 3.96ms\tremaining: 1.98s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6484178\tbest: 0.6580935 (88)\ttotal: 379ms\tremaining: 1.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6636225\tbest: 0.6636225 (200)\ttotal: 735ms\tremaining: 1.09s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6653996\tbest: 0.6707805 (244)\ttotal: 1.1s\tremaining: 727ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6707804709\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 244\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 245 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6195883\tbest: 0.6195883 (0)\ttotal: 4.09ms\tremaining: 2.04s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6477267\tbest: 0.6541936 (94)\ttotal: 368ms\tremaining: 1.45s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6794195\tbest: 0.6802587 (189)\ttotal: 727ms\tremaining: 1.08s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6885521\tbest: 0.6885521 (300)\ttotal: 1.11s\tremaining: 732ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.6857383\tbest: 0.6917609 (351)\ttotal: 1.47s\tremaining: 363ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.6865775\tbest: 0.6980797 (433)\ttotal: 1.83s\tremaining: 0us\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6980796762\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 433\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 434 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5435158\tbest: 0.5435158 (0)\ttotal: 3.73ms\tremaining: 1.86s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7608234\tbest: 0.7608234 (100)\ttotal: 353ms\tremaining: 1.39s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7725724\tbest: 0.7768179 (194)\ttotal: 714ms\tremaining: 1.06s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7768178901\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.711183657612229\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 14.57 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-eea2f3a6-d4b9-4e6c-a9e0-36e2ea23c08f\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5775966\tbest: 0.5775966 (0)\ttotal: 3.12ms\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7393317\tbest: 0.7455717 (79)\ttotal: 275ms\tremaining: 1.09s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7455716586\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 79\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 80 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7455716586151369 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7455716586151369.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7455716586151369 in 0:00:00.697254\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5912842\tbest: 0.5912842 (0)\ttotal: 2.21ms\tremaining: 1.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7239835\tbest: 0.7305757 (75)\ttotal: 213ms\tremaining: 842ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7511574\tbest: 0.7559380 (138)\ttotal: 418ms\tremaining: 622ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7559380032\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 138\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 139 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.755938003220612 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.755938003220612.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.755938003220612 in 0:00:00.883301\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5870572\tbest: 0.5870572 (0)\ttotal: 2.11ms\tremaining: 1.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7322363\tbest: 0.7650966 (57)\ttotal: 213ms\tremaining: 841ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7650966184\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 57\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 58 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: 0.7650966183574879 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 2 with value: 0.7650966183574879.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.7650966183574879 in 0:00:00.542346\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5912842\tbest: 0.5912842 (0)\ttotal: 2.34ms\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7400866\tbest: 0.7528684 (71)\ttotal: 213ms\tremaining: 840ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7503019\tbest: 0.7549819 (171)\ttotal: 417ms\tremaining: 620ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7561393\tbest: 0.7599134 (282)\ttotal: 630ms\tremaining: 417ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7498490\tbest: 0.7616244 (325)\ttotal: 826ms\tremaining: 204ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7616243961\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 325\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 326 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: 0.7616243961352657 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 2 with value: 0.7650966183574879.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored 0.7616243961352657 in 0:00:01.117136\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5832327\tbest: 0.5832327 (0)\ttotal: 5.59ms\tremaining: 2.79s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7020934\tbest: 0.7380988 (6)\ttotal: 522ms\tremaining: 2.06s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7380988325\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 6\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 7 iterations.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: 0.7380988325281803 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 2 with value: 0.7650966183574879.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored 0.7380988325281803 in 0:00:00.777727\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5832327\tbest: 0.5832327 (0)\ttotal: 8.12ms\tremaining: 4.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7238829\tbest: 0.7377466 (6)\ttotal: 514ms\tremaining: 2.03s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7377465781\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 6\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 7 iterations.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: 0.737746578099839 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 2 with value: 0.7650966183574879.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.737746578099839 in 0:00:00.775281\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6075886\tbest: 0.6075886 (0)\ttotal: 5.23ms\tremaining: 2.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7580515\tbest: 0.7618760 (96)\ttotal: 519ms\tremaining: 2.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7548309\tbest: 0.7630334 (173)\ttotal: 1.03s\tremaining: 1.54s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7630334138\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 173\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 174 iterations.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: 0.7630334138486312 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 2 with value: 0.7650966183574879.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored 0.7630334138486312 in 0:00:01.624564\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5987319\tbest: 0.5987319 (0)\ttotal: 8.75ms\tremaining: 4.37s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7059682\tbest: 0.7333937 (56)\ttotal: 770ms\tremaining: 3.04s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7333937198\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 56\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 57 iterations.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: 0.7333937198067633 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9}. Best is trial 2 with value: 0.7650966183574879.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored 0.7333937198067633 in 0:00:01.416696\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5870572\tbest: 0.5870572 (0)\ttotal: 2.5ms\tremaining: 1.25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7849738\tbest: 0.7872383 (90)\ttotal: 208ms\tremaining: 820ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7872383253\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 90\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 91 iterations.\n",
      "INFO:optuna.study.study:Trial 8 finished with value: 0.7872383252818035 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6}. Best is trial 8 with value: 0.7872383252818035.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored 0.7872383252818035 in 0:00:00.610127\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5832327\tbest: 0.5832327 (0)\ttotal: 5.5ms\tremaining: 2.74s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7115036\tbest: 0.7375453 (6)\ttotal: 523ms\tremaining: 2.07s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7375452899\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 6\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 7 iterations.\n",
      "INFO:optuna.study.study:Trial 9 finished with value: 0.7375452898550725 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4}. Best is trial 8 with value: 0.7872383252818035.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored 0.7375452898550725 in 0:00:00.766237\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5943035\tbest: 0.5943035 (0)\ttotal: 2.9ms\tremaining: 1.44s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7509561\tbest: 0.7526671 (92)\ttotal: 280ms\tremaining: 1.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7687701\tbest: 0.7694746 (193)\ttotal: 544ms\tremaining: 809ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7722424\tbest: 0.7731481 (249)\ttotal: 823ms\tremaining: 544ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7731481481\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 249\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 250 iterations.\n",
      "INFO:optuna.study.study:Trial 10 finished with value: 0.7731481481481481 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.319049072944658, 'min_data_in_leaf': 14}. Best is trial 8 with value: 0.7872383252818035.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.319049072944658, 'min_data_in_leaf': 14} scored 0.7731481481481481 in 0:00:01.187049\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6177536\tbest: 0.6177536 (0)\ttotal: 2.94ms\tremaining: 1.47s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7534722\tbest: 0.7555354 (92)\ttotal: 265ms\tremaining: 1.04s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7710346\tbest: 0.7716888 (193)\ttotal: 549ms\tremaining: 817ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7728965\tbest: 0.7738527 (273)\ttotal: 819ms\tremaining: 541ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7749597\tbest: 0.7754630 (357)\ttotal: 1.08s\tremaining: 267ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.7817532\tbest: 0.7818035 (497)\ttotal: 1.35s\tremaining: 0us\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7818035427\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 497\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 498 iterations.\n",
      "INFO:optuna.study.study:Trial 11 finished with value: 0.7818035426731079 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 7.6545382002097115, 'min_data_in_leaf': 15}. Best is trial 8 with value: 0.7872383252818035.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 7.6545382002097115, 'min_data_in_leaf': 15} scored 0.7818035426731079 in 0:00:01.603124\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5775966\tbest: 0.5775966 (0)\ttotal: 2.93ms\tremaining: 1.46s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7572967\tbest: 0.7576993 (94)\ttotal: 284ms\tremaining: 1.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7676127\tbest: 0.7706320 (170)\ttotal: 591ms\tremaining: 880ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7683676\tbest: 0.7769726 (237)\ttotal: 869ms\tremaining: 575ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7769726248\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 237\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 238 iterations.\n",
      "INFO:optuna.study.study:Trial 12 finished with value: 0.7769726247987118 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.21068312935605357, 'min_data_in_leaf': 15}. Best is trial 8 with value: 0.7872383252818035.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.21068312935605357, 'min_data_in_leaf': 15} scored 0.7769726247987118 in 0:00:01.200335\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5775966\tbest: 0.5775966 (0)\ttotal: 2.9ms\tremaining: 1.45s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7477355\tbest: 0.7480374 (99)\ttotal: 274ms\tremaining: 1.08s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7618760\tbest: 0.7618760 (200)\ttotal: 534ms\tremaining: 795ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7643921\tbest: 0.7684179 (216)\ttotal: 816ms\tremaining: 539ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7684178744\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 216\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 217 iterations.\n",
      "INFO:optuna.study.study:Trial 13 finished with value: 0.7684178743961353 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16505863700695894, 'min_data_in_leaf': 19}. Best is trial 8 with value: 0.7872383252818035.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16505863700695894, 'min_data_in_leaf': 19} scored 0.7684178743961353 in 0:00:01.099445\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5720109\tbest: 0.5720109 (0)\ttotal: 3.93ms\tremaining: 1.96s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7494968\tbest: 0.7567935 (88)\ttotal: 369ms\tremaining: 1.46s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7657005\tbest: 0.7716888 (151)\ttotal: 735ms\tremaining: 1.09s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7716888084\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 151\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 152 iterations.\n",
      "INFO:optuna.study.study:Trial 14 finished with value: 0.7716888083735909 and parameters: {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.252450628010636, 'min_data_in_leaf': 12}. Best is trial 8 with value: 0.7872383252818035.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.252450628010636, 'min_data_in_leaf': 12} scored 0.7716888083735909 in 0:00:01.155489\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6}\u001b[0m\n",
      " achieve 0.7872 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 1.527156759251193, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 6, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5870572\tbest: 0.5870572 (0)\ttotal: 2.73ms\tremaining: 8.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7701791\tbest: 0.7701791 (100)\ttotal: 204ms\tremaining: 5.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7739533\tbest: 0.7770229 (158)\ttotal: 402ms\tremaining: 5.6s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7770229469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 158\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 159 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5158957\tbest: 0.5158957 (0)\ttotal: 2.27ms\tremaining: 6.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7248852\tbest: 0.7248852 (100)\ttotal: 206ms\tremaining: 5.92s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7350545\tbest: 0.7373747 (189)\ttotal: 414ms\tremaining: 5.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7460631\tbest: 0.7470998 (287)\ttotal: 613ms\tremaining: 5.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7397937\tbest: 0.7477909 (308)\ttotal: 818ms\tremaining: 5.3s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7477908871\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 308\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 309 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5209310\tbest: 0.5209310 (0)\ttotal: 2.2ms\tremaining: 6.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7274522\tbest: 0.7274522 (100)\ttotal: 205ms\tremaining: 5.87s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7362887\tbest: 0.7398924 (131)\ttotal: 405ms\tremaining: 5.64s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7398923829\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 131\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 132 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5116997\tbest: 0.5116997 (0)\ttotal: 2.21ms\tremaining: 6.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6685097\tbest: 0.6943773 (36)\ttotal: 206ms\tremaining: 5.92s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6943772523\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 36\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 37 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5214494\tbest: 0.5214494 (0)\ttotal: 2.3ms\tremaining: 6.91s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7629461\tbest: 0.7693637 (92)\ttotal: 208ms\tremaining: 5.97s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7695611\tbest: 0.7705978 (198)\ttotal: 403ms\tremaining: 5.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7731648\tbest: 0.7737079 (295)\ttotal: 598ms\tremaining: 5.37s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7716839\tbest: 0.7756825 (365)\ttotal: 800ms\tremaining: 5.19s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7756824801\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 365\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 366 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7067377067377068\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 42.42 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7420595277738135\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7472527472527472\u001b[0m, weights = \u001b[1m[0.2173829  0.35904282 0.         0.22490674 0.19866747]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7475778190063905\u001b[0m, weights = \u001b[1m[0.20110959 0.31837508 0.         0.25807232 0.22244307]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7476392654964085\u001b[0m, weights = \u001b[1m[0.17634653 0.33215043 0.         0.26650628 0.22499682]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7476392654964085\u001b[0m, weights = \u001b[1m[0.17634653 0.33215043 0.         0.26650628 0.22499682]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 57.93 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.17635 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.33215 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.26651 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.22500 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/usr/local/lib/python3.7/dist-packages/lightautoml/report/report_deco.py:1722: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treatment_train_data[self._target] = treatment_train_data[self._target] - outcome_pred\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 100.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (2390, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 98.70 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207], 'embed_sizes': array([ 8, 18,  6,  6,  4,  5,  5,  3,  3,  5,  5,  8, 13,  8,  4,  7, 19,\n",
      "        6, 47, 13,  8, 26, 13,  8,  6,  6,  3, 11], dtype=int32), 'data_size': 208}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.09001241698671086\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08950712831356085\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08936160867056006\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08973073083641728\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.09035487477039217\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.08824574554108074\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08805122739298889\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08823473939804999\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08931695061240383\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.08670661625814498\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08628475418680612\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0861470136083271\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08645849221523931\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.08707684280880708\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.06548613899905051\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06559392672690666\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.06591012714974404\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.08680334720944906\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08605648591591313\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08594884916686336\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08661683397133207\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.08705443056367115\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.08299896756755798\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 96.49 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0888476\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0889054\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0893076\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[165]\tvalid's l2: 0.0886841\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0891125\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0896304\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0905688\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[102]\tvalid's l2: 0.0890734\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0873122\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0876526\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0884186\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[119]\tvalid's l2: 0.0871372\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0868527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0874853\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[45]\tvalid's l2: 0.0865676\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0661038\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0665734\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[19]\tvalid's l2: 0.065736\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.085518\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0852642\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0852366\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's l2: 0.0853464\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[289]\tvalid's l2: 0.0850685\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.08271654767760031\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2eb68903-414e-46c2-88d9-75149eb7223b\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0895129\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0897866\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0904127\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[112]\tvalid's l2: 0.0893473\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.089347311566469 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: -0.089347311566469.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.089347311566469 in 0:00:02.664453\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve -0.0893 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 244, 'feature_fraction': 0.6872700594236812, 'bagging_fraction': 0.8659969709057025, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'min_sum_hessian_in_leaf': 0.24810409748678125}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0961052\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[6]\tvalid's l2: 0.0901292\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0920351\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[13]\tvalid's l2: 0.0878494\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0900638\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.0873079\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0698968\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[21]\tvalid's l2: 0.0639196\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0878335\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[26]\tvalid's l2: 0.084999\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-0.08284102698843851\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861249\ttest: 0.3007718\tbest: 0.3007718 (0)\ttotal: 2.4ms\tremaining: 4.79s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2558570\ttest: 0.2972882\tbest: 0.2970503 (93)\ttotal: 223ms\tremaining: 4.19s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2272162\ttest: 0.2966998\tbest: 0.2964884 (195)\ttotal: 444ms\tremaining: 3.98s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1975556\ttest: 0.2982649\tbest: 0.2961284 (235)\ttotal: 666ms\tremaining: 3.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1729305\ttest: 0.2998494\tbest: 0.2961284 (235)\ttotal: 887ms\tremaining: 3.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1515371\ttest: 0.3013442\tbest: 0.2961284 (235)\ttotal: 1.1s\tremaining: 3.29s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2961283961\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 235\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 236 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2867793\ttest: 0.2975856\tbest: 0.2975856 (0)\ttotal: 2.22ms\tremaining: 4.44s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2568042\ttest: 0.2970716\tbest: 0.2962504 (18)\ttotal: 212ms\tremaining: 3.98s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2260801\ttest: 0.2989464\tbest: 0.2962504 (18)\ttotal: 433ms\tremaining: 3.87s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1951755\ttest: 0.3004740\tbest: 0.2962504 (18)\ttotal: 649ms\tremaining: 3.67s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2962504248\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 18\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 19 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2879905\ttest: 0.2949112\tbest: 0.2949112 (0)\ttotal: 2.17ms\tremaining: 4.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2578751\ttest: 0.2954212\tbest: 0.2928283 (47)\ttotal: 219ms\tremaining: 4.11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2267061\ttest: 0.2961645\tbest: 0.2928283 (47)\ttotal: 432ms\tremaining: 3.87s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1975140\ttest: 0.2973657\tbest: 0.2928283 (47)\ttotal: 660ms\tremaining: 3.73s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2928282704\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 47\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 48 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2965736\ttest: 0.2565836\tbest: 0.2565836 (0)\ttotal: 2.24ms\tremaining: 4.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2640151\ttest: 0.2564932\tbest: 0.2554498 (26)\ttotal: 213ms\tremaining: 4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2349046\ttest: 0.2598131\tbest: 0.2554498 (26)\ttotal: 430ms\tremaining: 3.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2041046\ttest: 0.2605768\tbest: 0.2554498 (26)\ttotal: 658ms\tremaining: 3.71s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.255449764\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 26\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 27 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2870374\ttest: 0.2958436\tbest: 0.2958436 (0)\ttotal: 2.24ms\tremaining: 4.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2554148\ttest: 0.2930107\tbest: 0.2926399 (95)\ttotal: 211ms\tremaining: 3.96s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2258424\ttest: 0.2919993\tbest: 0.2916477 (197)\ttotal: 429ms\tremaining: 3.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1944528\ttest: 0.2913242\tbest: 0.2910255 (285)\ttotal: 682ms\tremaining: 3.85s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1707437\ttest: 0.2918785\tbest: 0.2910255 (285)\ttotal: 908ms\tremaining: 3.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1501269\ttest: 0.2934652\tbest: 0.2910255 (285)\ttotal: 1.13s\tremaining: 3.38s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2910255054\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 285\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 286 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.08223103297395239\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 33.94 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-b6ea0690-0df7-4f30-b39b-81cfedc9b0c3\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2862826\ttest: 0.3007422\tbest: 0.3007422 (0)\ttotal: 1.79ms\tremaining: 3.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2648200\ttest: 0.3000359\tbest: 0.2996403 (50)\ttotal: 160ms\tremaining: 3.02s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2438331\ttest: 0.2994528\tbest: 0.2994466 (104)\ttotal: 331ms\tremaining: 2.96s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2214286\ttest: 0.2992554\tbest: 0.2988120 (282)\ttotal: 490ms\tremaining: 2.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2027129\ttest: 0.2994049\tbest: 0.2988120 (282)\ttotal: 645ms\tremaining: 2.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1871171\ttest: 0.2993338\tbest: 0.2988120 (282)\ttotal: 807ms\tremaining: 2.41s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2988120237\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 282\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 283 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.08928862552105704 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.08928862552105704.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.08928862552105704 in 0:00:01.162491\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2863710\ttest: 0.3008463\tbest: 0.3008463 (0)\ttotal: 1.29ms\tremaining: 2.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2731868\ttest: 0.2978095\tbest: 0.2970940 (77)\ttotal: 136ms\tremaining: 2.55s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2608272\ttest: 0.2977481\tbest: 0.2970940 (77)\ttotal: 260ms\tremaining: 2.33s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2473216\ttest: 0.2990857\tbest: 0.2970940 (77)\ttotal: 370ms\tremaining: 2.09s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2970940414\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.08826486944910611 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: -0.08826486944910611.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.08826486944910611 in 0:00:00.674288\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2864202\ttest: 0.3008215\tbest: 0.3008215 (0)\ttotal: 1.21ms\tremaining: 2.42s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2725547\ttest: 0.2994575\tbest: 0.2987544 (76)\ttotal: 114ms\tremaining: 2.15s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2597149\ttest: 0.2986380\tbest: 0.2986380 (200)\ttotal: 231ms\tremaining: 2.06s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2457689\ttest: 0.2978184\tbest: 0.2973214 (278)\ttotal: 342ms\tremaining: 1.93s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2329972\ttest: 0.2975103\tbest: 0.2973214 (278)\ttotal: 464ms\tremaining: 1.85s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2221836\ttest: 0.2977221\tbest: 0.2971453 (417)\ttotal: 575ms\tremaining: 1.72s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2130450\ttest: 0.2987678\tbest: 0.2971453 (417)\ttotal: 692ms\tremaining: 1.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:700:\tlearn: 0.2040496\ttest: 0.2983694\tbest: 0.2971453 (417)\ttotal: 803ms\tremaining: 1.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.297145305\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 417\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 418 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.08829533223612622 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: -0.08826486944910611.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.08829533223612622 in 0:00:01.052928\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2863709\ttest: 0.3008464\tbest: 0.3008464 (0)\ttotal: 1.2ms\tremaining: 2.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2731826\ttest: 0.2978090\tbest: 0.2970932 (77)\ttotal: 117ms\tremaining: 2.21s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2608196\ttest: 0.2977477\tbest: 0.2970932 (77)\ttotal: 232ms\tremaining: 2.07s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2473105\ttest: 0.2990873\tbest: 0.2970932 (77)\ttotal: 356ms\tremaining: 2.01s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2970932312\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.08826438796302706 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.08826438796302706 in 0:00:00.665226\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2860244\ttest: 0.3008168\tbest: 0.3008168 (0)\ttotal: 3.95ms\tremaining: 7.91s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2419984\ttest: 0.3000643\tbest: 0.2986824 (12)\ttotal: 313ms\tremaining: 5.89s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1989151\ttest: 0.3019506\tbest: 0.2986824 (12)\ttotal: 628ms\tremaining: 5.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1592149\ttest: 0.3047966\tbest: 0.2986824 (12)\ttotal: 948ms\tremaining: 5.35s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2986823794\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.08921116368377828 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -0.08921116368377828 in 0:00:01.222805\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2860249\ttest: 0.3008170\tbest: 0.3008170 (0)\ttotal: 3.57ms\tremaining: 7.15s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2420199\ttest: 0.3000639\tbest: 0.2986840 (12)\ttotal: 317ms\tremaining: 5.95s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1989504\ttest: 0.3019501\tbest: 0.2986840 (12)\ttotal: 625ms\tremaining: 5.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1592597\ttest: 0.3047953\tbest: 0.2986840 (12)\ttotal: 954ms\tremaining: 5.38s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2986840459\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.08921215920389378 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -0.08921215920389378 in 0:00:01.214539\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2860840\ttest: 0.3006081\tbest: 0.3006081 (0)\ttotal: 3.51ms\tremaining: 7.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2516621\ttest: 0.2994271\tbest: 0.2986008 (64)\ttotal: 323ms\tremaining: 6.06s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2181351\ttest: 0.3011333\tbest: 0.2986008 (64)\ttotal: 638ms\tremaining: 5.71s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1862080\ttest: 0.3023800\tbest: 0.2986008 (64)\ttotal: 951ms\tremaining: 5.37s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2986008466\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 64\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 65 iterations.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.0891624655372276 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -0.0891624655372276 in 0:00:01.367148\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2857102\ttest: 0.3006108\tbest: 0.3006108 (0)\ttotal: 5.35ms\tremaining: 10.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2140621\ttest: 0.2993594\tbest: 0.2988644 (84)\ttotal: 488ms\tremaining: 9.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1587029\ttest: 0.3008111\tbest: 0.2988644 (84)\ttotal: 977ms\tremaining: 8.74s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1114709\ttest: 0.3014368\tbest: 0.2988644 (84)\ttotal: 1.47s\tremaining: 8.32s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2988644395\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 84\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 85 iterations.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.08931995315027998 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -0.08931995315027998 in 0:00:02.141693\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2864332\ttest: 0.3008286\tbest: 0.3008286 (0)\ttotal: 1.15ms\tremaining: 2.29s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2736143\ttest: 0.2988507\tbest: 0.2983213 (79)\ttotal: 119ms\tremaining: 2.24s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2622176\ttest: 0.2983845\tbest: 0.2980877 (177)\ttotal: 230ms\tremaining: 2.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2494632\ttest: 0.2982439\tbest: 0.2979204 (283)\ttotal: 344ms\tremaining: 1.94s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2384690\ttest: 0.2983965\tbest: 0.2979204 (283)\ttotal: 458ms\tremaining: 1.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2285676\ttest: 0.2987245\tbest: 0.2979204 (283)\ttotal: 571ms\tremaining: 1.71s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2979204293\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 283\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 284 iterations.\n",
      "INFO:optuna.study.study:Trial 8 finished with value: -0.08875658218313336 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -0.08875658218313336 in 0:00:01.080833\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2860246\ttest: 0.3008169\tbest: 0.3008169 (0)\ttotal: 3.2ms\tremaining: 6.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2420066\ttest: 0.3000641\tbest: 0.2986830 (12)\ttotal: 317ms\tremaining: 5.95s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1989286\ttest: 0.3019504\tbest: 0.2986830 (12)\ttotal: 627ms\tremaining: 5.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1592320\ttest: 0.3047961\tbest: 0.2986830 (12)\ttotal: 950ms\tremaining: 5.36s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2986830169\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
      "INFO:optuna.study.study:Trial 9 finished with value: -0.08921154447188565 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored -0.08921154447188565 in 0:00:01.198528\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2862401\ttest: 0.3007530\tbest: 0.3007530 (0)\ttotal: 1.61ms\tremaining: 3.23s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2656305\ttest: 0.2993108\tbest: 0.2988649 (57)\ttotal: 153ms\tremaining: 2.88s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2450707\ttest: 0.2985242\tbest: 0.2980137 (186)\ttotal: 313ms\tremaining: 2.8s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2240043\ttest: 0.2993346\tbest: 0.2980137 (186)\ttotal: 472ms\tremaining: 2.66s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2054731\ttest: 0.3012053\tbest: 0.2980137 (186)\ttotal: 648ms\tremaining: 2.58s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2980136865\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 186\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 187 iterations.\n",
      "INFO:optuna.study.study:Trial 10 finished with value: -0.08881215722982978 and parameters: {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1692997958212103e-08, 'min_data_in_leaf': 14}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1692997958212103e-08, 'min_data_in_leaf': 14} scored -0.08881215722982978 in 0:00:01.019008\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2862401\ttest: 0.3007530\tbest: 0.3007530 (0)\ttotal: 1.59ms\tremaining: 3.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2656306\ttest: 0.2993108\tbest: 0.2988649 (57)\ttotal: 155ms\tremaining: 2.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2450708\ttest: 0.2985242\tbest: 0.2980137 (186)\ttotal: 305ms\tremaining: 2.73s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2240044\ttest: 0.2993345\tbest: 0.2980137 (186)\ttotal: 464ms\tremaining: 2.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2054732\ttest: 0.3012053\tbest: 0.2980137 (186)\ttotal: 632ms\tremaining: 2.52s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2980136785\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 186\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 187 iterations.\n",
      "INFO:optuna.study.study:Trial 11 finished with value: -0.08881215252014207 and parameters: {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5624722374695985e-05, 'min_data_in_leaf': 15}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.5624722374695985e-05, 'min_data_in_leaf': 15} scored -0.08881215252014207 in 0:00:01.006200\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2863743\ttest: 0.3008437\tbest: 0.3008437 (0)\ttotal: 1.19ms\tremaining: 2.39s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2732063\ttest: 0.2980513\tbest: 0.2971575 (77)\ttotal: 113ms\tremaining: 2.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2607571\ttest: 0.2980348\tbest: 0.2971575 (77)\ttotal: 227ms\tremaining: 2.03s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2474265\ttest: 0.2996273\tbest: 0.2971575 (77)\ttotal: 342ms\tremaining: 1.93s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2971574929\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n",
      "INFO:optuna.study.study:Trial 12 finished with value: -0.088302575599228 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.06686028679500336, 'min_data_in_leaf': 15}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.06686028679500336, 'min_data_in_leaf': 15} scored -0.088302575599228 in 0:00:00.651356\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2862401\ttest: 0.3007530\tbest: 0.3007530 (0)\ttotal: 1.58ms\tremaining: 3.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2656306\ttest: 0.2993108\tbest: 0.2988649 (57)\ttotal: 157ms\tremaining: 2.95s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2450708\ttest: 0.2985242\tbest: 0.2980137 (186)\ttotal: 315ms\tremaining: 2.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2240044\ttest: 0.2993346\tbest: 0.2980137 (186)\ttotal: 479ms\tremaining: 2.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2054732\ttest: 0.3012053\tbest: 0.2980137 (186)\ttotal: 633ms\tremaining: 2.52s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2980136803\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 186\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 187 iterations.\n",
      "INFO:optuna.study.study:Trial 13 finished with value: -0.08881215373177584 and parameters: {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.2096060313323957e-05, 'min_data_in_leaf': 19}. Best is trial 3 with value: -0.08826438796302706.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.2096060313323957e-05, 'min_data_in_leaf': 19} scored -0.08881215373177584 in 0:00:01.006756\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861438\ttest: 0.3007797\tbest: 0.3007797 (0)\ttotal: 2.14ms\tremaining: 4.29s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2569684\ttest: 0.2959658\tbest: 0.2958567 (93)\ttotal: 215ms\tremaining: 4.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2279015\ttest: 0.2972638\tbest: 0.2953909 (109)\ttotal: 433ms\tremaining: 3.87s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1972307\ttest: 0.2982939\tbest: 0.2953909 (109)\ttotal: 654ms\tremaining: 3.69s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1734615\ttest: 0.3007531\tbest: 0.2953909 (109)\ttotal: 870ms\tremaining: 3.47s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2953909298\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 109\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 110 iterations.\n",
      "INFO:optuna.study.study:Trial 14 finished with value: -0.0872558012767399 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.125932335717553, 'min_data_in_leaf': 12}. Best is trial 14 with value: -0.0872558012767399.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.125932335717553, 'min_data_in_leaf': 12} scored -0.0872558012767399 in 0:00:01.153035\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861532\ttest: 0.3007836\tbest: 0.3007836 (0)\ttotal: 2.33ms\tremaining: 4.67s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2571178\ttest: 0.2959421\tbest: 0.2958326 (93)\ttotal: 222ms\tremaining: 4.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2285900\ttest: 0.2958292\tbest: 0.2953731 (109)\ttotal: 432ms\tremaining: 3.86s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1992575\ttest: 0.2970107\tbest: 0.2951953 (235)\ttotal: 646ms\tremaining: 3.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1753604\ttest: 0.2992098\tbest: 0.2951953 (235)\ttotal: 872ms\tremaining: 3.48s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1539163\ttest: 0.3002529\tbest: 0.2951953 (235)\ttotal: 1.1s\tremaining: 3.28s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2951952796\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 235\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 236 iterations.\n",
      "INFO:optuna.study.study:Trial 15 finished with value: -0.0871402529974173 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1910706059935141, 'min_data_in_leaf': 8}. Best is trial 15 with value: -0.0871402529974173.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.1910706059935141, 'min_data_in_leaf': 8} scored -0.0871402529974173 in 0:00:01.418326\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861542\ttest: 0.3007840\tbest: 0.3007840 (0)\ttotal: 2.16ms\tremaining: 4.31s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2571521\ttest: 0.2959458\tbest: 0.2958365 (93)\ttotal: 217ms\tremaining: 4.07s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2285866\ttest: 0.2958844\tbest: 0.2953767 (109)\ttotal: 446ms\tremaining: 3.99s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1993103\ttest: 0.2963261\tbest: 0.2952586 (235)\ttotal: 669ms\tremaining: 3.78s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1752223\ttest: 0.2974010\tbest: 0.2952586 (235)\ttotal: 886ms\tremaining: 3.53s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1547648\ttest: 0.2988577\tbest: 0.2952586 (235)\ttotal: 1.1s\tremaining: 3.29s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2952586404\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 235\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 236 iterations.\n",
      "INFO:optuna.study.study:Trial 16 finished with value: -0.08717766463085361 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.19808696428203346, 'min_data_in_leaf': 12}. Best is trial 15 with value: -0.0871402529974173.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.19808696428203346, 'min_data_in_leaf': 12} scored -0.08717766463085361 in 0:00:01.409448\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2862379\ttest: 0.3010263\tbest: 0.3010263 (0)\ttotal: 2.48ms\tremaining: 4.96s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2678964\ttest: 0.2992094\tbest: 0.2990084 (57)\ttotal: 219ms\tremaining: 4.11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2503722\ttest: 0.2987517\tbest: 0.2986937 (154)\ttotal: 463ms\tremaining: 4.15s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2301921\ttest: 0.2999395\tbest: 0.2984280 (223)\ttotal: 684ms\tremaining: 3.86s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2132696\ttest: 0.3009612\tbest: 0.2984280 (223)\ttotal: 899ms\tremaining: 3.59s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1974599\ttest: 0.3004662\tbest: 0.2984280 (223)\ttotal: 1.13s\tremaining: 3.37s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2984280201\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 223\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 224 iterations.\n",
      "INFO:optuna.study.study:Trial 17 finished with value: -0.08905928308365792 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 9.86874546485385, 'min_data_in_leaf': 8}. Best is trial 15 with value: -0.0871402529974173.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 9.86874546485385, 'min_data_in_leaf': 8} scored -0.08905928308365792 in 0:00:01.433326\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861788\ttest: 0.3007936\tbest: 0.3007936 (0)\ttotal: 2.24ms\tremaining: 4.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2577560\ttest: 0.2964672\tbest: 0.2963431 (93)\ttotal: 215ms\tremaining: 4.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2296856\ttest: 0.2970055\tbest: 0.2960140 (109)\ttotal: 434ms\tremaining: 3.88s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2010109\ttest: 0.2967942\tbest: 0.2960140 (109)\ttotal: 668ms\tremaining: 3.77s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1769571\ttest: 0.2990083\tbest: 0.2960140 (109)\ttotal: 890ms\tremaining: 3.55s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2960140017\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 109\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 110 iterations.\n",
      "INFO:optuna.study.study:Trial 18 finished with value: -0.08762428908331538 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.3942946781689508, 'min_data_in_leaf': 11}. Best is trial 15 with value: -0.0871402529974173.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.3942946781689508, 'min_data_in_leaf': 11} scored -0.08762428908331538 in 0:00:01.126029\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2855732\ttest: 0.3009969\tbest: 0.3009969 (0)\ttotal: 4.88ms\tremaining: 9.75s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2226785\ttest: 0.3015528\tbest: 0.3004058 (20)\ttotal: 488ms\tremaining: 9.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1685268\ttest: 0.3042525\tbest: 0.3004058 (20)\ttotal: 967ms\tremaining: 8.66s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1208296\ttest: 0.3060359\tbest: 0.3004058 (20)\ttotal: 1.45s\tremaining: 8.18s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3004058079\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 20\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 21 iterations.\n",
      "INFO:optuna.study.study:Trial 19 finished with value: -0.09024364933336537 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.03823528764110746, 'min_data_in_leaf': 13}. Best is trial 15 with value: -0.0871402529974173.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.03823528764110746, 'min_data_in_leaf': 13} scored -0.09024364933336537 in 0:00:01.774808\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861875\ttest: 0.3007968\tbest: 0.3007968 (0)\ttotal: 2.12ms\tremaining: 4.23s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2584344\ttest: 0.2970738\tbest: 0.2969422 (93)\ttotal: 219ms\tremaining: 4.11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2306750\ttest: 0.2965801\tbest: 0.2965284 (195)\ttotal: 432ms\tremaining: 3.87s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2019621\ttest: 0.2985861\tbest: 0.2962558 (234)\ttotal: 645ms\tremaining: 3.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1775315\ttest: 0.2998803\tbest: 0.2962558 (234)\ttotal: 888ms\tremaining: 3.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1572849\ttest: 0.3016978\tbest: 0.2962558 (234)\ttotal: 1.1s\tremaining: 3.29s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2962557706\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 234\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 235 iterations.\n",
      "INFO:optuna.study.study:Trial 20 finished with value: -0.08776748161578002 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.4740410642277949, 'min_data_in_leaf': 17}. Best is trial 15 with value: -0.0871402529974173.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.4740410642277949, 'min_data_in_leaf': 17} scored -0.08776748161578002 in 0:00:01.402056\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861429\ttest: 0.3007794\tbest: 0.3007794 (0)\ttotal: 3.57ms\tremaining: 7.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2569381\ttest: 0.2959633\tbest: 0.2958540 (93)\ttotal: 216ms\tremaining: 4.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2278487\ttest: 0.2972695\tbest: 0.2953885 (109)\ttotal: 442ms\tremaining: 3.95s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1970771\ttest: 0.2980378\tbest: 0.2953885 (109)\ttotal: 664ms\tremaining: 3.75s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1728519\ttest: 0.2999544\tbest: 0.2953885 (109)\ttotal: 876ms\tremaining: 3.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2953884564\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 109\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 110 iterations.\n",
      "INFO:optuna.study.study:Trial 21 finished with value: -0.0872543401062858 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.12012982541970953, 'min_data_in_leaf': 12}. Best is trial 15 with value: -0.0871402529974173.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.12012982541970953, 'min_data_in_leaf': 12} scored -0.0872543401062858 in 0:00:01.119104\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861253\ttest: 0.3007719\tbest: 0.3007719 (0)\ttotal: 2.15ms\tremaining: 4.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2559790\ttest: 0.2973749\tbest: 0.2971206 (93)\ttotal: 237ms\tremaining: 4.46s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2266363\ttest: 0.2961166\tbest: 0.2961166 (200)\ttotal: 468ms\tremaining: 4.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1958081\ttest: 0.2960653\tbest: 0.2949074 (262)\ttotal: 688ms\tremaining: 3.88s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1706033\ttest: 0.2972822\tbest: 0.2949074 (262)\ttotal: 902ms\tremaining: 3.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1499784\ttest: 0.2982436\tbest: 0.2949074 (262)\ttotal: 1.11s\tremaining: 3.33s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2949074047\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 262\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 263 iterations.\n",
      "INFO:optuna.study.study:Trial 22 finished with value: -0.0869703772795315 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.011825778179145006, 'min_data_in_leaf': 8}. Best is trial 22 with value: -0.0869703772795315.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.011825778179145006, 'min_data_in_leaf': 8} scored -0.0869703772795315 in 0:00:01.495952\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2860290\ttest: 0.3008188\tbest: 0.3008188 (0)\ttotal: 3.28ms\tremaining: 6.55s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2422234\ttest: 0.3000610\tbest: 0.2986998 (12)\ttotal: 307ms\tremaining: 5.77s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1985359\ttest: 0.3028116\tbest: 0.2986998 (12)\ttotal: 609ms\tremaining: 5.45s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1597299\ttest: 0.3042055\tbest: 0.2986998 (12)\ttotal: 944ms\tremaining: 5.33s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2986997826\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
      "INFO:optuna.study.study:Trial 23 finished with value: -0.08922156005624521 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.022565721363852407, 'min_data_in_leaf': 7}. Best is trial 22 with value: -0.0869703772795315.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.022565721363852407, 'min_data_in_leaf': 7} scored -0.08922156005624521 in 0:00:01.214249\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2862412\ttest: 0.3007526\tbest: 0.3007526 (0)\ttotal: 1.56ms\tremaining: 3.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2657275\ttest: 0.2994328\tbest: 0.2988654 (57)\ttotal: 158ms\tremaining: 2.97s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2453829\ttest: 0.2981889\tbest: 0.2978935 (172)\ttotal: 314ms\tremaining: 2.81s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2246499\ttest: 0.2990914\tbest: 0.2976558 (215)\ttotal: 475ms\tremaining: 2.68s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2063462\ttest: 0.3010019\tbest: 0.2976558 (215)\ttotal: 644ms\tremaining: 2.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1912050\ttest: 0.3032839\tbest: 0.2976558 (215)\ttotal: 799ms\tremaining: 2.39s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2976557695\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 215\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 216 iterations.\n",
      "INFO:optuna.study.study:Trial 24 finished with value: -0.08859895701674067 and parameters: {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.008946403841950902, 'min_data_in_leaf': 9}. Best is trial 22 with value: -0.0869703772795315.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.008946403841950902, 'min_data_in_leaf': 9} scored -0.08859895701674067 in 0:00:01.059193\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2862346\ttest: 0.3008130\tbest: 0.3008130 (0)\ttotal: 2.29ms\tremaining: 4.58s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2599396\ttest: 0.2977574\tbest: 0.2976816 (97)\ttotal: 213ms\tremaining: 4.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2338817\ttest: 0.2976012\tbest: 0.2968126 (120)\ttotal: 440ms\tremaining: 3.94s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2062433\ttest: 0.2984808\tbest: 0.2967799 (244)\ttotal: 691ms\tremaining: 3.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1827219\ttest: 0.3000491\tbest: 0.2967799 (244)\ttotal: 902ms\tremaining: 3.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1632669\ttest: 0.3010449\tbest: 0.2967799 (244)\ttotal: 1.13s\tremaining: 3.38s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2967798741\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 244\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 245 iterations.\n",
      "INFO:optuna.study.study:Trial 25 finished with value: -0.08807829347878124 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.022640873679234, 'min_data_in_leaf': 10}. Best is trial 22 with value: -0.0869703772795315.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.022640873679234, 'min_data_in_leaf': 10} scored -0.08807829347878124 in 0:00:01.638903\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861763\ttest: 0.3007412\tbest: 0.3007412 (0)\ttotal: 2.32ms\tremaining: 4.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2548300\ttest: 0.3002115\tbest: 0.2997242 (30)\ttotal: 220ms\tremaining: 4.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2241795\ttest: 0.3010467\tbest: 0.2997242 (30)\ttotal: 438ms\tremaining: 3.92s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1920568\ttest: 0.2996170\tbest: 0.2991235 (290)\ttotal: 654ms\tremaining: 3.69s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1661603\ttest: 0.2997239\tbest: 0.2991235 (290)\ttotal: 884ms\tremaining: 3.52s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1464638\ttest: 0.3009875\tbest: 0.2991235 (290)\ttotal: 1.1s\tremaining: 3.29s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2991234849\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 290\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 291 iterations.\n",
      "INFO:optuna.study.study:Trial 26 finished with value: -0.08947485918816149 and parameters: {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00033655836338300634, 'min_data_in_leaf': 7}. Best is trial 22 with value: -0.0869703772795315.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00033655836338300634, 'min_data_in_leaf': 7} scored -0.08947485918816149 in 0:00:01.561129\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2860881\ttest: 0.3008436\tbest: 0.3008436 (0)\ttotal: 2.97ms\tremaining: 5.94s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2457389\ttest: 0.2995521\tbest: 0.2986015 (12)\ttotal: 339ms\tremaining: 6.38s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2060836\ttest: 0.3008944\tbest: 0.2986015 (12)\ttotal: 651ms\tremaining: 5.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1690022\ttest: 0.3026257\tbest: 0.2986015 (12)\ttotal: 953ms\tremaining: 5.38s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2986015458\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
      "INFO:optuna.study.study:Trial 27 finished with value: -0.08916288308299934 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.39302005224430625, 'min_data_in_leaf': 2}. Best is trial 22 with value: -0.0869703772795315.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.39302005224430625, 'min_data_in_leaf': 2} scored -0.08916288308299934 in 0:00:01.211965\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.011825778179145006, 'min_data_in_leaf': 8}\u001b[0m\n",
      " achieve -0.0870 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.011825778179145006, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 8, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2863347\ttest: 0.3008210\tbest: 0.3008210 (0)\ttotal: 2.14ms\tremaining: 6.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2665017\ttest: 0.2980414\tbest: 0.2979373 (97)\ttotal: 231ms\tremaining: 6.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2499866\ttest: 0.2982797\tbest: 0.2978055 (119)\ttotal: 441ms\tremaining: 6.14s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2978055264\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 119\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 120 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2870458\ttest: 0.2976939\tbest: 0.2976939 (0)\ttotal: 5.71ms\tremaining: 17.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2671011\ttest: 0.2963884\tbest: 0.2962909 (92)\ttotal: 219ms\tremaining: 6.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2506972\ttest: 0.2966921\tbest: 0.2958164 (118)\ttotal: 439ms\tremaining: 6.12s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2958164276\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 118\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 119 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2880752\ttest: 0.2949005\tbest: 0.2949005 (0)\ttotal: 2.21ms\tremaining: 6.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2677515\ttest: 0.2933530\tbest: 0.2921594 (65)\ttotal: 215ms\tremaining: 6.17s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2921594078\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 65\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 66 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2968519\ttest: 0.2566290\tbest: 0.2566290 (0)\ttotal: 2.9ms\tremaining: 8.69s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2750718\ttest: 0.2562236\tbest: 0.2554449 (68)\ttotal: 217ms\tremaining: 6.24s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2554448839\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 68\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 69 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2873962\ttest: 0.2958550\tbest: 0.2958550 (0)\ttotal: 2.29ms\tremaining: 6.88s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2672422\ttest: 0.2934726\tbest: 0.2933474 (95)\ttotal: 213ms\tremaining: 6.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2512107\ttest: 0.2934666\tbest: 0.2931808 (109)\ttotal: 425ms\tremaining: 5.92s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2335203\ttest: 0.2924132\tbest: 0.2920054 (253)\ttotal: 640ms\tremaining: 5.73s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2920053976\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 253\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 254 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.08241437034976273\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 36.92 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.08215635741532198\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.08197920016848913\u001b[0m, weights = \u001b[1m[0.         0.         0.2687157  0.73128426 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.08196292030233254\u001b[0m, weights = \u001b[1m[0.06196766 0.         0.32044372 0.61758864 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.08196285799813853\u001b[0m, weights = \u001b[1m[0.06094043 0.         0.32109466 0.6179649  0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-0.08196280162881074\u001b[0m, weights = \u001b[1m[0.05998272 0.         0.32173464 0.6182826  0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-0.08196275082338503\u001b[0m, weights = \u001b[1m[0.05909066 0.         0.32233956 0.6185698  0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 63.27 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.05909 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.32234 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.61857 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/usr/local/lib/python3.7/dist-packages/lightautoml/report/report_deco.py:1730: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_train_data[self._target] = control_train_data[self._target] - outcome_pred\n",
      "/usr/local/lib/python3.7/dist-packages/lightautoml/report/report_deco.py:1731: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  control_train_data[self._target] *= -1\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 100.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (4610, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 98.28 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188], 'embed_sizes': array([ 6,  5,  3,  3,  6,  9,  4,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 189}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07044585553197316\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06971360151854843\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0695364670355813\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06980084787888935\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07027915363776314\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.05733176508143964\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.057082134738520855\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.057123545220954856\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.057727297103537405\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.053860222836548864\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.05359079883786041\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.053617817403784955\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.054097237501394696\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.05425448162335408\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.05414598098030248\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.05432903036588641\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.055185050864533194\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07497734398542831\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07422836520406835\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07400965130488527\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07394188297283974\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07416459696755695\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.07506775739746656\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.06165945291302096\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 95.63 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0700443\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0701012\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0703924\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[184]\tvalid's l2: 0.0699933\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0700435\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0702188\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0703763\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[115]\tvalid's l2: 0.069929\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0560044\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0558958\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0560547\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's l2: 0.0558598\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0536208\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.053709\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[83]\tvalid's l2: 0.0535605\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0542169\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0546292\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[77]\tvalid's l2: 0.0541653\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0736875\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0731805\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0731343\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's l2: 0.0730046\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's l2: 0.0730283\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's l2: 0.0731322\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[425]\tvalid's l2: 0.0729691\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.06129677262065126\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2826325a-af30-4ba9-8ab1-093a6b0f4075\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0703387\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.070418\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[96]\tvalid's l2: 0.0702572\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.07025724781110038 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: -0.07025724781110038.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.07025724781110038 in 0:00:05.597143\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}\u001b[0m\n",
      " achieve -0.0703 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 244, 'feature_fraction': 0.6872700594236812, 'bagging_fraction': 0.8659969709057025, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'min_sum_hessian_in_leaf': 0.24810409748678125}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0731616\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[11]\tvalid's l2: 0.0704471\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0586437\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[15]\tvalid's l2: 0.0559912\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0564052\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's l2: 0.0538719\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0573386\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[12]\tvalid's l2: 0.0539718\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0747336\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[46]\tvalid's l2: 0.0734031\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-0.06153700740221503\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2453763\ttest: 0.2661891\tbest: 0.2661891 (0)\ttotal: 2.91ms\tremaining: 5.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2257060\ttest: 0.2656938\tbest: 0.2652007 (24)\ttotal: 285ms\tremaining: 5.35s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2085280\ttest: 0.2669850\tbest: 0.2652007 (24)\ttotal: 571ms\tremaining: 5.11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1914439\ttest: 0.2687829\tbest: 0.2652007 (24)\ttotal: 848ms\tremaining: 4.79s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2652006509\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 24\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 25 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2522612\ttest: 0.2399296\tbest: 0.2399296 (0)\ttotal: 2.88ms\tremaining: 5.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2327774\ttest: 0.2393188\tbest: 0.2388211 (42)\ttotal: 280ms\tremaining: 5.27s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2157286\ttest: 0.2389015\tbest: 0.2386247 (186)\ttotal: 565ms\tremaining: 5.06s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1959603\ttest: 0.2394746\tbest: 0.2385159 (211)\ttotal: 848ms\tremaining: 4.78s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1809194\ttest: 0.2405709\tbest: 0.2385159 (211)\ttotal: 1.12s\tremaining: 4.47s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1665543\ttest: 0.2422606\tbest: 0.2385159 (211)\ttotal: 1.41s\tremaining: 4.22s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2385159401\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 211\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 212 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2538545\ttest: 0.2327846\tbest: 0.2327846 (0)\ttotal: 3.1ms\tremaining: 6.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2326032\ttest: 0.2311341\tbest: 0.2308653 (61)\ttotal: 271ms\tremaining: 5.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2153980\ttest: 0.2313068\tbest: 0.2308653 (61)\ttotal: 546ms\tremaining: 4.88s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1958889\ttest: 0.2312403\tbest: 0.2307442 (228)\ttotal: 826ms\tremaining: 4.66s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1801526\ttest: 0.2322983\tbest: 0.2307442 (228)\ttotal: 1.11s\tremaining: 4.42s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1661969\ttest: 0.2343541\tbest: 0.2307442 (228)\ttotal: 1.38s\tremaining: 4.13s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2307441934\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 228\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 229 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2535342\ttest: 0.2335125\tbest: 0.2335125 (0)\ttotal: 3ms\tremaining: 6.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2329674\ttest: 0.2345797\tbest: 0.2329557 (19)\ttotal: 274ms\tremaining: 5.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2153618\ttest: 0.2358489\tbest: 0.2329557 (19)\ttotal: 573ms\tremaining: 5.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1963340\ttest: 0.2360373\tbest: 0.2329557 (19)\ttotal: 848ms\tremaining: 4.79s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2329557245\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 19\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 20 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2430423\ttest: 0.2748059\tbest: 0.2748059 (0)\ttotal: 2.92ms\tremaining: 5.83s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2237767\ttest: 0.2713596\tbest: 0.2712708 (88)\ttotal: 277ms\tremaining: 5.21s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2069670\ttest: 0.2708445\tbest: 0.2707614 (195)\ttotal: 566ms\tremaining: 5.07s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1887358\ttest: 0.2703236\tbest: 0.2699444 (275)\ttotal: 837ms\tremaining: 4.72s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1732425\ttest: 0.2708554\tbest: 0.2697842 (318)\ttotal: 1.13s\tremaining: 4.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.1599166\ttest: 0.2714076\tbest: 0.2697842 (318)\ttotal: 1.42s\tremaining: 4.24s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.1478455\ttest: 0.2721499\tbest: 0.2697842 (318)\ttotal: 1.69s\tremaining: 3.93s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2697842432\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 318\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 319 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.061503205703717666\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 10.74 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-0ebb0959-cfc9-49f0-9f80-0d83ad8a020b\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2454259\ttest: 0.2661201\tbest: 0.2661201 (0)\ttotal: 2.21ms\tremaining: 4.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2303034\ttest: 0.2631157\tbest: 0.2630986 (59)\ttotal: 207ms\tremaining: 3.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2182228\ttest: 0.2638797\tbest: 0.2630986 (59)\ttotal: 421ms\tremaining: 3.77s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2048588\ttest: 0.2646154\tbest: 0.2630986 (59)\ttotal: 635ms\tremaining: 3.58s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2630986003\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 59\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 60 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.06922087339615099 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.06922087339615099.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.06922087339615099 in 0:00:01.011852\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2456998\ttest: 0.2664004\tbest: 0.2664004 (0)\ttotal: 1.85ms\tremaining: 3.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2366048\ttest: 0.2654888\tbest: 0.2650085 (65)\ttotal: 160ms\tremaining: 3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2290636\ttest: 0.2661470\tbest: 0.2650085 (65)\ttotal: 319ms\tremaining: 2.86s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2215053\ttest: 0.2664126\tbest: 0.2650085 (65)\ttotal: 495ms\tremaining: 2.8s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2650085206\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 65\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 66 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.07022951587798976 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 0 with value: -0.06922087339615099.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.07022951587798976 in 0:00:00.806413\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2455782\ttest: 0.2661724\tbest: 0.2661724 (0)\ttotal: 1.6ms\tremaining: 3.19s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2354113\ttest: 0.2628729\tbest: 0.2627119 (92)\ttotal: 158ms\tremaining: 2.97s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2281820\ttest: 0.2628985\tbest: 0.2625262 (172)\ttotal: 315ms\tremaining: 2.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2201054\ttest: 0.2637226\tbest: 0.2625262 (172)\ttotal: 475ms\tremaining: 2.68s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2126159\ttest: 0.2642167\tbest: 0.2625262 (172)\ttotal: 639ms\tremaining: 2.55s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2625262052\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 172\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 173 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.06892000834481996 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 2 with value: -0.06892000834481996.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.06892000834481996 in 0:00:00.963586\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2456998\ttest: 0.2664004\tbest: 0.2664004 (0)\ttotal: 1.81ms\tremaining: 3.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2366020\ttest: 0.2654898\tbest: 0.2650094 (65)\ttotal: 157ms\tremaining: 2.95s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2290588\ttest: 0.2661488\tbest: 0.2650094 (65)\ttotal: 318ms\tremaining: 2.85s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2214988\ttest: 0.2664148\tbest: 0.2650094 (65)\ttotal: 482ms\tremaining: 2.72s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2650093742\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 65\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 66 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.07022996833402852 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 2 with value: -0.06892000834481996.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.07022996833402852 in 0:00:00.809090\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2452457\ttest: 0.2663922\tbest: 0.2663922 (0)\ttotal: 4.16ms\tremaining: 8.31s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2183362\ttest: 0.2649799\tbest: 0.2639319 (36)\ttotal: 384ms\tremaining: 7.23s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1952543\ttest: 0.2663887\tbest: 0.2639319 (36)\ttotal: 751ms\tremaining: 6.72s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1692177\ttest: 0.2681799\tbest: 0.2639319 (36)\ttotal: 1.15s\tremaining: 6.47s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2639319081\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 36\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 37 iterations.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.06966005201645069 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 2 with value: -0.06892000834481996.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -0.06966005201645069 in 0:00:01.504209\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2452461\ttest: 0.2663921\tbest: 0.2663921 (0)\ttotal: 4.21ms\tremaining: 8.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2183499\ttest: 0.2649786\tbest: 0.2639317 (36)\ttotal: 398ms\tremaining: 7.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1952786\ttest: 0.2663857\tbest: 0.2639317 (36)\ttotal: 768ms\tremaining: 6.87s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1695496\ttest: 0.2681580\tbest: 0.2639317 (36)\ttotal: 1.14s\tremaining: 6.44s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.263931745\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 36\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 37 iterations.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.06965996593562584 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 2 with value: -0.06892000834481996.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -0.06965996593562584 in 0:00:01.478547\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2454091\ttest: 0.2662775\tbest: 0.2662775 (0)\ttotal: 3.94ms\tremaining: 7.89s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2211184\ttest: 0.2636527\tbest: 0.2632839 (55)\ttotal: 387ms\tremaining: 7.28s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2020174\ttest: 0.2649701\tbest: 0.2632839 (55)\ttotal: 755ms\tremaining: 6.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1818063\ttest: 0.2659944\tbest: 0.2632839 (55)\ttotal: 1.14s\tremaining: 6.44s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2632838822\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 55\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 56 iterations.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.06931840256778593 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 2 with value: -0.06892000834481996.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -0.06931840256778593 in 0:00:01.577482\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2449282\ttest: 0.2662685\tbest: 0.2662685 (0)\ttotal: 5.98ms\tremaining: 12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.1991588\ttest: 0.2639567\tbest: 0.2633537 (58)\ttotal: 580ms\tremaining: 10.9s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1654117\ttest: 0.2656834\tbest: 0.2633537 (58)\ttotal: 1.12s\tremaining: 10.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1332411\ttest: 0.2684155\tbest: 0.2633537 (58)\ttotal: 1.69s\tremaining: 9.54s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2633537496\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.06935519734482873 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9}. Best is trial 2 with value: -0.06892000834481996.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -0.06935519734482873 in 0:00:02.381107\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2455923\ttest: 0.2661785\tbest: 0.2661785 (0)\ttotal: 1.56ms\tremaining: 3.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2362972\ttest: 0.2629957\tbest: 0.2628550 (92)\ttotal: 167ms\tremaining: 3.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2294999\ttest: 0.2627447\tbest: 0.2625374 (193)\ttotal: 325ms\tremaining: 2.91s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2221033\ttest: 0.2630452\tbest: 0.2625374 (193)\ttotal: 478ms\tremaining: 2.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2153058\ttest: 0.2639343\tbest: 0.2625374 (193)\ttotal: 633ms\tremaining: 2.52s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2625373816\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 193\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 194 iterations.\n",
      "INFO:optuna.study.study:Trial 8 finished with value: -0.0689258766897434 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6}. Best is trial 2 with value: -0.06892000834481996.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored -0.0689258766897434 in 0:00:01.013991\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}\u001b[0m\n",
      " achieve -0.0689 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 8.148018307012941e-07, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2456910\ttest: 0.2662858\tbest: 0.2662858 (0)\ttotal: 1.6ms\tremaining: 4.79s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2386183\ttest: 0.2633550\tbest: 0.2633550 (100)\ttotal: 161ms\tremaining: 4.63s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2347552\ttest: 0.2629370\tbest: 0.2628272 (193)\ttotal: 326ms\tremaining: 4.54s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2628272136\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 193\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 194 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2523993\ttest: 0.2398818\tbest: 0.2398818 (0)\ttotal: 1.78ms\tremaining: 5.33s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2450097\ttest: 0.2371451\tbest: 0.2370332 (79)\ttotal: 167ms\tremaining: 4.78s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2370332203\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 79\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 80 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2539818\ttest: 0.2328764\tbest: 0.2328764 (0)\ttotal: 1.86ms\tremaining: 5.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2452624\ttest: 0.2315897\tbest: 0.2315468 (84)\ttotal: 160ms\tremaining: 4.6s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2408716\ttest: 0.2318545\tbest: 0.2315188 (116)\ttotal: 328ms\tremaining: 4.56s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2315188106\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 116\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 117 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2538571\ttest: 0.2335968\tbest: 0.2335968 (0)\ttotal: 1.84ms\tremaining: 5.52s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2456544\ttest: 0.2332020\tbest: 0.2329037 (41)\ttotal: 156ms\tremaining: 4.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2329036931\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 41\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 42 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2432956\ttest: 0.2748168\tbest: 0.2748168 (0)\ttotal: 1.72ms\tremaining: 5.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2350397\ttest: 0.2720065\tbest: 0.2720065 (100)\ttotal: 176ms\tremaining: 5.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2304540\ttest: 0.2716389\tbest: 0.2716389 (200)\ttotal: 328ms\tremaining: 4.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2256441\ttest: 0.2717674\tbest: 0.2716010 (217)\ttotal: 486ms\tremaining: 4.36s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.271600958\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 217\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 218 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.06137501225925825\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 41.36 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.061087739324194076\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.061076193457893266\u001b[0m, weights = \u001b[1m[0.11204676 0.26505375 0.16087736 0.30027544 0.16174677]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06107572091969317\u001b[0m, weights = \u001b[1m[0.11250752 0.2937772  0.16167395 0.28212625 0.14991513]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.0610756681787431\u001b[0m, weights = \u001b[1m[0.12076585 0.29226342 0.1600403  0.28056484 0.1463656 ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m-0.06107566761792707\u001b[0m, weights = \u001b[1m[0.12116086 0.29291204 0.1598156  0.28002667 0.14608483]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m-0.06107566753388236\u001b[0m, weights = \u001b[1m[0.12140447 0.29300576 0.15978229 0.28000432 0.14580317]\u001b[0m\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 58.83 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.12140 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.29301 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.15978 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.28000 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.14580 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/lightautoml/report/report_deco.py:1906: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
      "  self._datetime_features_table = pd.DataFrame(datetime_features_df).to_html(index=False, justify=\"left\")\n"
     ]
    }
   ],
   "source": [
    "best_metalearner = autouplift.create_best_metalearner(\n",
    "    update_metalearner_params={'timeout': None},\n",
    "    update_baselearner_params={'timeout': 100}\n",
    ")\n",
    "\n",
    "RDU = ReportDecoUplift()\n",
    "best_metalearner = RDU(best_metalearner)\n",
    "best_metalearner.fit(train, roles)\n",
    "_ = best_metalearner.predict(test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vkTEMbh0jG9"
   },
   "source": [
    "### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7uhLejG0jG9",
    "outputId": "a8e815ba-36bd-4ff8-d220-049772936d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check scores ---\n",
      "OOF scores \"ROC_AUC\":\n",
      "\tTreatment = 0.69805\n",
      "\tControl   = 0.74660\n",
      "Uplift score of test group (default=\"adj_qini\"):\n",
      "\tBaseline      = 0.01340\n",
      "\tAlgo (Normed) = 0.02837 (0.18490)\n",
      "\tPerfect       = 0.09438\n"
     ]
    }
   ],
   "source": [
    "uplift_pred, treatment_pred, control_pred = best_metalearner.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "print('--- Check scores ---')\n",
    "print('OOF scores \"ROC_AUC\":')\n",
    "print('\\tTreatment = {:.5f}'.format(roc_auc_treatment))\n",
    "print('\\tControl   = {:.5f}'.format(roc_auc_control))\n",
    "print('Uplift score of test group (default=\"adj_qini\"):')\n",
    "print('\\tBaseline      = {:.5f}'.format(auc_base))\n",
    "print('\\tAlgo (Normed) = {:.5f} ({:.5f})'.format(uplift_auc_algo, uplift_auc_algo_normed))\n",
    "print('\\tPerfect       = {:.5f}'.format(auc_perfect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHNb9bQisgbF"
   },
   "source": [
    "Отчет ReportDecoUplift сохраняется по следующему пути:\n",
    "\n",
    "`PATH_TO_CURRENT_NOTEBOOK/lama_report/lama_interactive_report.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvK6U7lV0jG9"
   },
   "source": [
    "## AutoUplift with custom metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJDvmz3I0jG9"
   },
   "source": [
    "### Fit autouplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtbuUGBz0jG9",
    "outputId": "0d713e0c-3f61-4275-aeb4-7da403a085f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 125)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999997.22 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202], 'embed_sizes': array([20,  6,  5, 19,  5,  9,  4,  7,  3,  6, 49, 13,  8, 37, 13,  8, 11,\n",
      "       11, 11,  3], dtype=int32), 'data_size': 203}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6637931973975305\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6883357490818339\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7044431608888501\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7297594786342484\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7330507089222855\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7296287012718098\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7259887313506032\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6579681557122463\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6829956734489261\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6951143757015661\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7151778027223487\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7198530934295274\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7245065879096327\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7242232369576825\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7226539086084198\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6692095598251941\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7028193419719047\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7243758105471942\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7608844908946262\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7688292156627687\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7753026951034775\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7730794799420221\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7683061062130145\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5897950377562028\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6125242718446602\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6350377562028048\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.699730312837109\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7175080906148867\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7406796116504853\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7423300970873785\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7316828478964402\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7230960086299891\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6956040992448761\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.718403451995685\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7301294498381877\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7487055016181229\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7512837108953613\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7471736785329018\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7443905070118664\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7417112422510984\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999990.02 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #0 [__SLearner__Default__] is fitted\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['REG_REGION_NOT_LIVE_REGION', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_18']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.71 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 197}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7209763539282991\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7272311212814645\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7339435545385202\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7479023646071701\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7482074752097636\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7486651411136537\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7480549199084667\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7418764302059496\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7218154080854309\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7300533943554538\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7413424866514111\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7723874904652938\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7780320366132722\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7733790999237223\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7661327231121282\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5785350567959263\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.581590285938112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5829220524872699\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6108108108108108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6330591461026244\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6710536623580102\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6835879357618488\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6906384645515079\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6898550724637682\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6882882882882884\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.680924402663533\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.690951821386604\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7021543282412848\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.72777124951038\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.736701919310615\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7476694085389738\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7474343909126517\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7405405405405405\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6122992557775168\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6225616921269096\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6329808068938504\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6607128867998434\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6698785742264003\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6720720720720721\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.67340383862123\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6688601645123384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6645515080297688\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.71418739827947\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999994.86 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['WEEKDAY_APPR_PROCESS_START']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.49 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49, 13,\n",
      "        8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6407546535097556\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6615272482619421\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6872056514913657\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7438326979143305\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7558869701726846\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7588584884503251\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7540648127382821\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7475611123570307\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6622280780444046\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6796366898407715\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6991197577932272\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7488226059654631\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7603442475891455\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7687542049786947\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7695111011437542\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7647174254317112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7612973760932944\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6228134110787171\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6348116169544741\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6445111011437542\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6696568737385064\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6787115945279211\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6886073110562907\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6874299170217538\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6783751962323391\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6100505334081977\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.624396406513195\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6395564289724873\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6798989331836047\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6921392476137002\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.701347557551937\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7035654126895002\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7086187535092644\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7075238629983155\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.699915777653004\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6921392476137002\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7190342504211117\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7365524985962942\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7705783267827063\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7777091521617069\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7782425603593487\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7741437394722067\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7599943851768669\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7315781796966161\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999991.00 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #1 [__TLearner__Default__] is fitted\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['REG_REGION_NOT_LIVE_REGION', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_18']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.72 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 197}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7209763539282991\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7272311212814645\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7339435545385202\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7479023646071701\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7482074752097636\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7486651411136537\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7480549199084667\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7418764302059496\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7218154080854309\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7300533943554538\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7413424866514111\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7723874904652938\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7780320366132722\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7733790999237223\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7661327231121282\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5785350567959263\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.581590285938112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5829220524872699\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6108108108108108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6330591461026244\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6710536623580102\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6835879357618488\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6906384645515079\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6898550724637682\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6882882882882884\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.680924402663533\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.690951821386604\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7021543282412848\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.72777124951038\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.736701919310615\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7476694085389738\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7474343909126517\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7405405405405405\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6122992557775168\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6225616921269096\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6329808068938504\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6607128867998434\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6698785742264003\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6720720720720721\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.67340383862123\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6688601645123384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6645515080297688\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.71418739827947\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999994.67 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/lightautoml/addons/uplift/metalearners.py:566: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dependent_train_data[self._other_group_pred_col] = sg_oof_pred\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 125)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['WEEKDAY_APPR_PROCESS_START']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.48 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212], 'embed_sizes': array([19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49, 13,\n",
      "        8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 213}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6525285938551244\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.680505718771025\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7046983628616281\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7522426553038798\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7608208118412201\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7556066382596995\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.751513792330119\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.673525454137699\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6946905135680647\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7143698138596097\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7585220901547433\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.766063018614039\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7703801300740075\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7702119309262166\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7644370935187262\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6331296254765642\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6450717649697242\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6546310832025118\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6755999102937879\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6823559093967259\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6882428795694102\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6852713612917695\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.678767660910518\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6186973610331274\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6318360471645144\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6469679955081414\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6843065693430658\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6927849522740034\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7025547445255474\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7042953396967995\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7090398652442448\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7075800112296462\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6989051094890512\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7029758562605277\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7257439640651319\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7420269511510389\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7685008422234699\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7737507018528915\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7769511510387422\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7739191465468838\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.759208309938237\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7274846288483977\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999991.47 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #2 [__TDLearner__Default__] is fitted\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['FLAG_CONT_MOBILE', 'REG_REGION_NOT_LIVE_REGION', 'OBS_60_CNT_SOCIAL_CIRCLE', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_19']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.05 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 184}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7617608610165408\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7711950572322342\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7765409836646342\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7955971389196906\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8078725763539294\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8355410226342771\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8456306173854202\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.860524106266673\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8636841900159775\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8654378239351546\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8654378239351544\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8625080153469539\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7707593057735298\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7812846519833777\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7874843678592559\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8132574724289778\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8264823520659225\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8505797620017643\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8570628934605398\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8662313875672671\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8677122339879052\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8684561998930107\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8682436382058376\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8682400955110514\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7711445962627166\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.781168858809007\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7879545680273558\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8139871451070532\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8281615800451197\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.854261553086735\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8619908057719321\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8733133273741116\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8754522623760269\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8780133089289008\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8780168560847913\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8780062146171199\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.877456405454107\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7777032875040791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7864647625533846\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7919096468451595\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8143986151903403\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8265653598944367\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8500759091360548\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8570460704607046\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.864229061138779\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8641332879297379\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8610046964343989\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7713716142397027\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7778345322720243\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7819421387931158\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8013096099547382\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8128556023780134\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8361994352927823\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8449112501596219\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.85813859447495\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8609585834078236\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8632819705160402\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8632819705160402\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8618063536656311\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8668857892611115\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999981.27 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['WEEKDAY_APPR_PROCESS_START']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.50 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49, 13,\n",
      "        8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6405584211706661\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6613870823054496\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6870935187261719\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7443933617403006\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7561673020856694\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7584940569634447\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7542330118860732\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7475611123570306\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6621159452792106\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6795245570755776\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6995963220453016\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7487945727741646\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.759867683337071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7686981385960978\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7697353666741421\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7644651267100248\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7613254092845929\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6221686476788517\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6348396501457726\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6445111011437541\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6697129401211035\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6787956941018165\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6887474770127832\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6871495851087689\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6779546983628616\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6102470522178551\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6239752947782146\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6395002807411565\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6813868613138686\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6920830993823694\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7009825940482874\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7039303761931499\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7089556428972487\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7076080853453116\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7001122964626614\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6921532846715328\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.718585064570466\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7363559797866368\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7705783267827063\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7777091521617069\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7788882650196519\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.773469960696238\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7599382369455362\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7322519298088143\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999990.65 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['REG_REGION_NOT_LIVE_REGION', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_18']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.77 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 197}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7209763539282991\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7272311212814645\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7339435545385202\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7479023646071701\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7482074752097636\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7486651411136537\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7480549199084667\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7418764302059496\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7218154080854309\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7300533943554538\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7413424866514111\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7723874904652938\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7780320366132722\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7733790999237223\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7661327231121282\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5785350567959263\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.581590285938112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5829220524872699\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6108108108108108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6330591461026244\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6710536623580102\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6835879357618488\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6906384645515079\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6898550724637682\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.6882882882882884\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.680924402663533\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.690951821386604\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7021543282412848\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.72777124951038\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.736701919310615\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7476694085389738\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7474343909126517\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7405405405405405\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6122992557775168\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6225616921269096\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6329808068938504\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6607128867998434\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6698785742264003\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6720720720720721\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.67340383862123\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6688601645123384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.6645515080297688\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.71418739827947\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999994.92 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.48 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], 'embed_sizes': array([ 6,  3,  3,  9,  3,  5, 49, 13,  8, 36, 13,  8], dtype=int32), 'data_size': 192}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07081095750818306\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07039760722921498\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07033066405882725\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07054568330916872\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07068329468437813\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.0621013248877264\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06158544202385532\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.061530808741062135\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06193080168563449\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06226205525720081\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.0604765616328819\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.060041121713478425\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0600103952942151\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06060262446354861\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.061123351064827754\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.06700801382519844\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06626984482191203\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.06605272713994856\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06597613650838188\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06611834970333261\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.0669861345457484\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.05501763322581018\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.05475741536427313\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.05481344287080399\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.05548243371430368\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.06252225227320929\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999995.80 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['SK_ID_CURR', 'FLAG_CONT_MOBILE', 'REGION_RATING_CLIENT', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_21']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.74 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207], 'embed_sizes': array([16,  6, 10,  3,  3, 11,  4, 13, 11, 35,  3,  5, 47, 13,  8, 24, 13,\n",
      "        8, 11, 11], dtype=int32), 'data_size': 208}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07479989126261112\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07497147419979765\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07516103538578148\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07741687724248963\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07685373020750225\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07669739118182292\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.0769166773354575\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07731300914734932\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.0905845260626324\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08985535633367622\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.089587966160229\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08984887344183644\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.09057658656474704\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.08097914905460608\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08065662766323597\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08072291146879043\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08133775272558812\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.09278839516546114\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.09239945762240931\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.09247819920118994\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.09422314184398481\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.08282086131199906\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999996.97 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #3 [__XLearner__Default__] is fitted\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['FLAG_CONT_MOBILE', 'REG_REGION_NOT_LIVE_REGION', 'OBS_60_CNT_SOCIAL_CIRCLE', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_19']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.04 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 184}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7619840507880723\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7714076189194072\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7762044276599438\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7956077670040492\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8080922234306748\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8355162237707736\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8455597634896961\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8605630759093211\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8635885372567497\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8654803362725891\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8654909643569477\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.862376935639864\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.8631279869345415\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7707734765526746\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7811783711397912\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7877075576307874\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8131972466176122\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8263689858327635\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8507108417088542\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8570363232496432\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.866217216788122\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8676697216504707\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8685235110939488\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8682152966475479\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.868215296647548\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7710168986506619\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7813338015579109\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7878729834418764\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8138665418067793\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8281615800451197\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8543537791398854\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8619766171483705\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8733168745300018\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.875452262376027\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8779636487464352\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.877953007278764\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8775699144426\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.777797287135175\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7864576682416039\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7919273826246116\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8142815590459569\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8262922288908752\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8500475318889313\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8571382965138551\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8643035514124775\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8641368350856284\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8610898281757687\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7710133514947713\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7778735509868188\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7819598745725677\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8012493083046014\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8129300926517118\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8362916613459329\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8448615899771564\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.858252103463443\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8609905078108373\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8633458193220677\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8633422721661772\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8618134479774117\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8669186902676552\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999980.70 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.09 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'embed_sizes': array([20,  6,  5, 19,  5,  9,  4,  7,  3,  6, 49, 13,  8, 37, 13,  8, 11,\n",
      "       11, 11,  3], dtype=int32), 'data_size': 202}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6637986464542988\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6872350396146427\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7036040061465361\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7279067993330355\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7310236598044878\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7285170936910821\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7247245501803637\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6576575594764545\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6823744809773428\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6967381946185115\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7164746782331978\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7214878104600093\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7284517050098629\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7295742107041271\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7272747087479157\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.726086814372432\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6706372126984819\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.701053847578984\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7227083991761026\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7585196002571954\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7658758268943646\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7731230723961682\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7717172157499537\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7671944986322867\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5897195253505934\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6115749730312837\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6344552319309601\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7004530744336569\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7189212513484358\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7423408845738944\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7437756202804747\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7315641855447681\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7221143473570659\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6947033441208199\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7175512405609492\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7307659115426106\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7496763754045308\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7511974110032362\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.747076591154261\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7439482200647249\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7410092337775046\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999989.05 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 125)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.04 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241], 'embed_sizes': array([21,  6,  4, 16,  6,  5,  5,  8,  7,  4,  4,  4,  9,  7,  3, 20,  6,\n",
      "        5,  6,  3, 18, 49, 13,  8, 37, 13,  8, 11, 11,  7, 11, 11, 11, 11,\n",
      "       11, 11,  7,  6,  6, 11,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "        3,  3,  3,  9,  8,  7, 11,  3, 11, 11, 11,  8,  8,  8, 11,  3,  3,\n",
      "        3, 11], dtype=int32), 'data_size': 242}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.4889782031596436\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.489827152070035\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.4906203850235551\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.6369527999041452\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.6364044161738959\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.6360859199311559\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.6359469329214744\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.636706262324138\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.643554874288673\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.4217866362964855\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.42112727857481275\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.4207086569166312\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.42020011923196565\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.42074495988734134\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.42679227383362206\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.5091311506820765\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.5097029166000338\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.5104433126805392\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.4669994096341256\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.4667972000526321\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.46662352861285544\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.46665799284786363\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.4675418434137349\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.49975480552515544\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999992.07 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #4 [__RLearner__Linear__] is fitted\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 8.53 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 182}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7637022577593872\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7716060098274352\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7765976667812137\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7970744426455426\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8085669445320276\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8360228291252023\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8458042094299449\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.861675482072193\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8648461939058565\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8672871106135593\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8669363838297239\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8669363838297239\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8672871106135593\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 5.06 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.853589\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.862699\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.868265\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.871723\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.873575\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.874578\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.874061\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.873476\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[634]\tvalid's auc: 0.87473\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.874911\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.880654\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.883229\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.885128\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.886145\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.886042\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.886024\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.88561\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[644]\tvalid's auc: 0.886379\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8863786928164779\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left -10.83 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.8851883473683092\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8880508447555717\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8880508447555717\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 24.55 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.23607 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.76393 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 11.57 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], 'embed_sizes': array([20,  6,  5, 19,  5,  9,  4,  7,  3,  6, 49, 13,  8, 37, 13,  8, 11,\n",
      "       11, 11,  3], dtype=int32), 'data_size': 192}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6816987979380769\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.699397334321429\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7102082629496834\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7292690635251038\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7314704824594862\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7280157804684008\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7235039614642707\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7314704824594862\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9.85 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.724899\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.733705\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.740483\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.735612\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[275]\tvalid's auc: 0.740723\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.746172\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.739274\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.733694\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[108]\tvalid's auc: 0.746575\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7465752678211401\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5855011\tbest: 0.5855011 (0)\ttotal: 6.33ms\tremaining: 3.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7264791\tbest: 0.7264791 (100)\ttotal: 489ms\tremaining: 1.93s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7291710\tbest: 0.7311980 (176)\ttotal: 954ms\tremaining: 1.42s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7369086\tbest: 0.7369086 (300)\ttotal: 1.42s\tremaining: 938ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7371375\tbest: 0.7374209 (346)\ttotal: 1.9s\tremaining: 470ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.7362112\tbest: 0.7408647 (470)\ttotal: 2.36s\tremaining: 0us\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7408646563\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 470\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 471 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7408646563279897\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 0.08 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7488965660044246\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7525474340391677\u001b[0m, weights = \u001b[1m[0.08647733 0.68091357 0.2326091 ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7531141359430682\u001b[0m, weights = \u001b[1m[0.         0.7556607  0.24433932]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7531141359430682\u001b[0m, weights = \u001b[1m[0.         0.7556607  0.24433932]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 13.73 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.75566 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.24434 * (1 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (240, 125)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.67 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223], 'embed_sizes': array([ 6,  4,  5,  3,  4,  5,  5,  5,  3,  3,  6,  5,  5,  3, 10,  5,  6,\n",
      "        8,  3, 21, 13,  8, 14, 13,  8, 11,  3,  3,  3, 11, 11,  5, 11, 11,\n",
      "       11, 11,  3,  3,  7,  7, 11, 11, 11, 11], dtype=int32), 'data_size': 224}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.35165001071330765\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.35205415875516166\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.35236888917629\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.9172994196877646\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.9165991150263872\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.9158570538137603\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.912457506435239\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.9114701032827274\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = -0.9255677054558614\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = -0.9433108457628817\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.38870132712208944\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.3883562110219362\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.3881068851286748\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.3882742206556263\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.3896050929312262\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.5288987327384392\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 11.61 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.359804\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.366285\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[3]\tvalid's l2: 0.351746\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.352712\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.353116\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[2]\tvalid's l2: 0.351572\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.909558\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.906878\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.905677\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's l2: 0.904932\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's l2: 0.904562\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's l2: 0.90474\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[481]\tvalid's l2: 0.904259\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.405273\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.415073\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.388925\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.609909\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.608073\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.607115\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's l2: 0.605975\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's l2: 0.604684\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's l2: 0.603996\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's l2: 0.603652\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's l2: 0.603097\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's l2: 0.6028\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's l2: 0.602598\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's l2: 0.602196\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's l2: 0.601915\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's l2: 0.601553\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's l2: 0.601349\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1500]\tvalid's l2: 0.601074\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1600]\tvalid's l2: 0.600585\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1700]\tvalid's l2: 0.600499\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1800]\tvalid's l2: 0.600427\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1900]\tvalid's l2: 0.60007\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2000]\tvalid's l2: 0.599711\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2100]\tvalid's l2: 0.59969\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2200]\tvalid's l2: 0.599561\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2300]\tvalid's l2: 0.59937\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2400]\tvalid's l2: 0.599303\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2500]\tvalid's l2: 0.599163\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2600]\tvalid's l2: 0.599139\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2700]\tvalid's l2: 0.59895\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2800]\tvalid's l2: 0.598949\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[2900]\tvalid's l2: 0.59877\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[3000]\tvalid's l2: 0.598643\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Did not meet early stopping. Best iteration is:\n",
      "[2982]\tvalid's l2: 0.598643\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 3\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.5434901600684189\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-00ec4433-6392-4edc-be23-98fbb9a3164a\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.357838\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.360499\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.351399\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.3513988468439437 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: -0.3513988468439437.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored -0.3513988468439437 in 0:00:00.102190\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.350968\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.351124\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[72]\tvalid's l2: 0.350358\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.3503577358720847 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 1 with value: -0.3503577358720847.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored -0.3503577358720847 in 0:00:00.096469\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.354188\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.357667\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[25]\tvalid's l2: 0.350734\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.35073376473562357 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323}. Best is trial 1 with value: -0.3503577358720847.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored -0.35073376473562357 in 0:00:00.072710\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.355077\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.358396\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.351704\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.351704378163162 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 1 with value: -0.3503577358720847.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored -0.351704378163162 in 0:00:00.080666\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.35468\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.357732\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[6]\tvalid's l2: 0.352003\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.35200305543399624 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08}. Best is trial 1 with value: -0.3503577358720847.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored -0.35200305543399624 in 0:00:00.079012\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.35747\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.35747\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.35747\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.35174475810902134 and parameters: {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936}. Best is trial 1 with value: -0.3503577358720847.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored -0.35174475810902134 in 0:00:00.063715\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.356907\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.359168\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.351399\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.3513988796105541 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 1 with value: -0.3503577358720847.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored -0.3513988796105541 in 0:00:00.073951\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.352509\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.357037\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[72]\tvalid's l2: 0.350185\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.35018466836858103 and parameters: {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 7 with value: -0.35018466836858103.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored -0.35018466836858103 in 0:00:00.112039\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.35747\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.35747\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.35747\n",
      "INFO:optuna.study.study:Trial 8 finished with value: -0.35174475810902134 and parameters: {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483}. Best is trial 7 with value: -0.35018466836858103.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored -0.35174475810902134 in 0:00:00.055375\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.354358\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.356047\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[37]\tvalid's l2: 0.350911\n",
      "INFO:optuna.study.study:Trial 9 finished with value: -0.35091093521613276 and parameters: {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06}. Best is trial 7 with value: -0.35018466836858103.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored -0.35091093521613276 in 0:00:00.082540\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.354312\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.359915\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[15]\tvalid's l2: 0.350216\n",
      "INFO:optuna.study.study:Trial 10 finished with value: -0.3502163236923613 and parameters: {'feature_fraction': 0.5102569642516216, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662247, 'reg_alpha': 0.00314241287338549, 'reg_lambda': 0.016301353379407572}. Best is trial 7 with value: -0.35018466836858103.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102569642516216, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662247, 'reg_alpha': 0.00314241287338549, 'reg_lambda': 0.016301353379407572} scored -0.3502163236923613 in 0:00:00.102380\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}\u001b[0m\n",
      " achieve -0.3502 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8110495\ttest: 0.5930838\tbest: 0.5930838 (0)\ttotal: 1.14ms\tremaining: 2.27s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4236799\ttest: 1.0728380\tbest: 0.5930838 (0)\ttotal: 46.1ms\tremaining: 867ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2781235\ttest: 2.3432432\tbest: 0.5930838 (0)\ttotal: 92.7ms\tremaining: 830ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2000543\ttest: 2.9164895\tbest: 0.5930838 (0)\ttotal: 139ms\tremaining: 784ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5930837514\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.7210492\ttest: 0.9592909\tbest: 0.9592909 (0)\ttotal: 586us\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3126432\ttest: 1.7793036\tbest: 0.9561023 (2)\ttotal: 47.9ms\tremaining: 901ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1882426\ttest: 2.0670553\tbest: 0.9561023 (2)\ttotal: 94ms\tremaining: 842ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1327701\ttest: 2.2141231\tbest: 0.9561023 (2)\ttotal: 144ms\tremaining: 811ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9561022893\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 3 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8146265\ttest: 0.6218904\tbest: 0.6218904 (0)\ttotal: 555us\tremaining: 1.11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4243899\ttest: 0.6623595\tbest: 0.5972783 (45)\ttotal: 46.5ms\tremaining: 875ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2893713\ttest: 0.6757467\tbest: 0.5972783 (45)\ttotal: 92.5ms\tremaining: 827ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2272036\ttest: 0.7275634\tbest: 0.5972783 (45)\ttotal: 157ms\tremaining: 888ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972782786\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 45\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 46 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.7720847\ttest: 0.7549164\tbest: 0.7549164 (0)\ttotal: 531us\tremaining: 1.06s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4373618\ttest: 1.0539814\tbest: 0.7549164 (0)\ttotal: 46.9ms\tremaining: 882ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3082645\ttest: 1.0263480\tbest: 0.7549164 (0)\ttotal: 93.7ms\tremaining: 838ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2381304\ttest: 1.0476827\tbest: 0.7549164 (0)\ttotal: 142ms\tremaining: 804ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7549163811\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.7306314\ttest: 0.9979184\tbest: 0.9979184 (0)\ttotal: 579us\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4061258\ttest: 1.4625784\tbest: 0.9979184 (0)\ttotal: 47.6ms\tremaining: 894ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2849457\ttest: 1.6959088\tbest: 0.9979184 (0)\ttotal: 95.1ms\tremaining: 851ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2116325\ttest: 1.8519946\tbest: 0.9979184 (0)\ttotal: 145ms\tremaining: 820ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9979184125\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.5941414021850596\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.90 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2f96891f-097b-430e-81d7-192d3af6f63a\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8145750\ttest: 0.5925615\tbest: 0.5925615 (0)\ttotal: 927us\tremaining: 1.85s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.4796907\ttest: 1.1302567\tbest: 0.5915724 (1)\ttotal: 40.4ms\tremaining: 760ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.3392616\ttest: 1.2927629\tbest: 0.5915724 (1)\ttotal: 72.2ms\tremaining: 647ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2555639\ttest: 1.7745400\tbest: 0.5915724 (1)\ttotal: 114ms\tremaining: 641ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5915724363\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.3499579303343408 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.3499579303343408.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.3499579303343408 in 0:00:00.206082\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8158614\ttest: 0.5925163\tbest: 0.5925163 (0)\ttotal: 342us\tremaining: 684ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.5772783\ttest: 0.8305122\tbest: 0.5914688 (4)\ttotal: 32.8ms\tremaining: 616ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.4703479\ttest: 1.0408824\tbest: 0.5914688 (4)\ttotal: 61.9ms\tremaining: 554ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3992693\ttest: 1.4736324\tbest: 0.5914688 (4)\ttotal: 87.9ms\tremaining: 496ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5914687595\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.34983527633202083 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: -0.34983527633202083.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.34983527633202083 in 0:00:00.168449\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8158583\ttest: 0.5925163\tbest: 0.5925163 (0)\ttotal: 362us\tremaining: 725ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.5682690\ttest: 0.9416265\tbest: 0.5905553 (1)\ttotal: 29.6ms\tremaining: 557ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.4548129\ttest: 1.4641324\tbest: 0.5905553 (1)\ttotal: 67.6ms\tremaining: 605ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3783963\ttest: 2.2264566\tbest: 0.5905553 (1)\ttotal: 98.3ms\tremaining: 555ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5905553239\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.3487555733474929 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 2 with value: -0.3487555733474929.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.3487555733474929 in 0:00:00.183576\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8158584\ttest: 0.5925163\tbest: 0.5925163 (0)\ttotal: 340us\tremaining: 681ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.5666948\ttest: 0.8621639\tbest: 0.5914689 (4)\ttotal: 28.7ms\tremaining: 539ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.4538177\ttest: 1.0320787\tbest: 0.5914689 (4)\ttotal: 53.9ms\tremaining: 482ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.3849212\ttest: 1.5678034\tbest: 0.5914689 (4)\ttotal: 86.6ms\tremaining: 489ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5914688895\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.3498354300447135 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 2 with value: -0.3487555733474929.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.3498354300447135 in 0:00:00.177605\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8076736\ttest: 0.6448029\tbest: 0.6448029 (0)\ttotal: 848us\tremaining: 1.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2876509\ttest: 1.5295159\tbest: 0.6448029 (0)\ttotal: 66ms\tremaining: 1.24s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1465785\ttest: 2.2287837\tbest: 0.6448029 (0)\ttotal: 134ms\tremaining: 1.2s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.0844120\ttest: 2.6941015\tbest: 0.6448029 (0)\ttotal: 205ms\tremaining: 1.16s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6448028955\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: -0.41577075360665144 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 2 with value: -0.3487555733474929.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored -0.41577075360665144 in 0:00:00.299099\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8081017\ttest: 0.6306553\tbest: 0.6306553 (0)\ttotal: 811us\tremaining: 1.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.3069567\ttest: 1.0811532\tbest: 0.6306553 (0)\ttotal: 67.4ms\tremaining: 1.27s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1705676\ttest: 1.5197783\tbest: 0.6306553 (0)\ttotal: 132ms\tremaining: 1.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.0969329\ttest: 1.7304379\tbest: 0.6306553 (0)\ttotal: 198ms\tremaining: 1.12s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6306553035\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: -0.39772609562338596 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 2 with value: -0.3487555733474929.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored -0.39772609562338596 in 0:00:00.284656\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8169052\ttest: 0.5930517\tbest: 0.5930517 (0)\ttotal: 752us\tremaining: 1.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.6465666\ttest: 0.6013311\tbest: 0.5924387 (2)\ttotal: 62.4ms\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.5973424\ttest: 0.6070990\tbest: 0.5924387 (2)\ttotal: 145ms\tremaining: 1.29s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.5706726\ttest: 0.6087515\tbest: 0.5924387 (2)\ttotal: 207ms\tremaining: 1.17s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5924386845\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 3 iterations.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: -0.35098357772535005 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 2 with value: -0.3487555733474929.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored -0.35098357772535005 in 0:00:00.293056\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8050627\ttest: 0.5932184\tbest: 0.5932184 (0)\ttotal: 1.24ms\tremaining: 2.47s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2638654\ttest: 1.1140021\tbest: 0.5932184 (0)\ttotal: 90ms\tremaining: 1.69s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.1536847\ttest: 1.2138844\tbest: 0.5932184 (0)\ttotal: 186ms\tremaining: 1.66s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1031098\ttest: 1.2638998\tbest: 0.5932184 (0)\ttotal: 278ms\tremaining: 1.57s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5932184237\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: -0.3519080810165946 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9}. Best is trial 2 with value: -0.3487555733474929.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored -0.3519080810165946 in 0:00:00.376610\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}\u001b[0m\n",
      " achieve -0.3488 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 8.148018307012941e-07, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8179410\ttest: 0.5927318\tbest: 0.5927318 (0)\ttotal: 416us\tremaining: 1.25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.6331440\ttest: 0.7678841\tbest: 0.5909326 (4)\ttotal: 32.8ms\tremaining: 941ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5909326443\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.7260558\ttest: 0.9579544\tbest: 0.9579544 (0)\ttotal: 340us\tremaining: 1.02s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.5463195\ttest: 1.0809487\tbest: 0.9579046 (1)\ttotal: 25.9ms\tremaining: 742ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9579046408\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.8192173\ttest: 0.6234337\tbest: 0.6234337 (0)\ttotal: 321us\tremaining: 964ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.6323578\ttest: 0.6309452\tbest: 0.6229677 (13)\ttotal: 26.2ms\tremaining: 751ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6229676918\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.7785938\ttest: 0.7774407\tbest: 0.7774407 (0)\ttotal: 358us\tremaining: 1.07s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.6348400\ttest: 0.9051605\tbest: 0.7774081 (1)\ttotal: 28.8ms\tremaining: 828ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7774081383\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.7361543\ttest: 0.9970358\tbest: 0.9970358 (0)\ttotal: 336us\tremaining: 1.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.5734360\ttest: 1.4884421\tbest: 0.9952987 (1)\ttotal: 27.5ms\tremaining: 789ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9952987196\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.6089468373543492\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 5.57 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.6013847976207966\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.5941414021850596\u001b[0m, weights = \u001b[1m[0. 0. 1. 0.]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.5941414021850596\u001b[0m, weights = \u001b[1m[0. 0. 1. 0.]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 8.15 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 608, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.7/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-33-81a853150181>\", line 1, in <module>\n",
      "    get_ipython().run_cell_magic('time', '', \"\\n# Using a custom metric\\n# How to determine custom metric, see below\\n\\ntask = Task('binary')\\n\\n\\nclass CustomUpliftMetric(TUpliftMetric):\\n    def __call__(self, target: np.ndarray, uplift_pred: np.ndarray, treatment: np.ndarray) -> float:\\n        up_10 = calculate_uplift_at_top(target, uplift_pred, treatment, 10)\\n        up_20 = calculate_uplift_at_top(target, uplift_pred, treatment, 20)\\n\\n        return 0.5 * (up_10 + up_20)\\n\\nautouplift = AutoUplift(task,\\n                        add_dd_candidates=True,\\n                        metric=CustomUpliftMetric(), \\n                        test_size=0.2, \\n                        threshold_imbalance_treatment=0.0,\\n                        cpu_limit=10,\\n                        timeout=300)\\n\\nautouplift.fit(train, roles)\\n\")\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2359, in run_cell_magic\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"<decorator-gen-54>\", line 2, in time\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\", line 1315, in time\n",
      "    out = eval(code_2, glob, local_ns)\n",
      "  File \"<timed exec>\", line 22, in <module>\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/lightautoml/addons/uplift/base.py\", line 411, in fit\n",
      "    metalearner.fit(train_data, roles, verbose)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/lightautoml/addons/uplift/metalearners.py\", line 78, in fit\n",
      "    self.__class__.__name__,\n",
      "Message: '{} is trained, but time limit exceeded.'\n",
      "Arguments: ('RLearner',)\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #5 [__RLearner__Default__] is fitted\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 125)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 11.59 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192], 'embed_sizes': array([20,  6,  5, 19,  5,  9,  4,  7,  3,  6, 49, 13,  8, 37, 13,  8, 11,\n",
      "       11, 11,  3], dtype=int32), 'data_size': 193}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6826033413616103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.70081408908118\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7120173497967501\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7308383918743665\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7332141806253338\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7289857125731535\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7243758105471942\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7332141806253338\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 10.02 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.722038\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736004\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.7419\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.739208\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.73935\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[305]\tvalid's auc: 0.742369\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.747033\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.746804\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.739513\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[118]\tvalid's auc: 0.751686\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7516864830697806\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5639828\tbest: 0.5639828 (0)\ttotal: 5ms\tremaining: 2.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7047810\tbest: 0.7047810 (100)\ttotal: 466ms\tremaining: 1.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7110038\tbest: 0.7149380 (165)\ttotal: 944ms\tremaining: 1.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7204089\tbest: 0.7204089 (300)\ttotal: 1.41s\tremaining: 934ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\ttest: 0.7243322\tbest: 0.7253348 (392)\ttotal: 1.9s\tremaining: 469ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:499:\ttest: 0.7177716\tbest: 0.7261958 (430)\ttotal: 2.37s\tremaining: 0us\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7261957955\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 430\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 431 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7261957955077976\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left -0.02 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7448424677688291\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7534519774627012\u001b[0m, weights = \u001b[1m[0.         0.8231607  0.17683929]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7534519774627012\u001b[0m, weights = \u001b[1m[0.         0.8231607  0.17683929]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 13.78 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.82316 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.17684 * (1 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #6 [__SLearner__TabularAutoML__] is fitted\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.41 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 190}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7234935163996948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7311975591151791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7366132723112128\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7450800915331808\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.745537757437071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7456140350877192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.743020594965675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7386727688787186\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 11.27 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.719527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736156\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.741266\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.737147\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.73341\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.749428\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.726926\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.72746\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.722502\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.739512\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5727689\tbest: 0.5727689 (0)\ttotal: 2.57ms\tremaining: 1.28s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7062548\tbest: 0.7141876 (47)\ttotal: 226ms\tremaining: 893ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7240275\tbest: 0.7278413 (194)\ttotal: 434ms\tremaining: 646ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7278413425\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5815408\tbest: 0.5815408 (0)\ttotal: 2.35ms\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7398932\tbest: 0.7468345 (88)\ttotal: 217ms\tremaining: 858ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7468344775\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4952996\tbest: 0.4952996 (0)\ttotal: 2.36ms\tremaining: 1.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6314924\tbest: 0.6426165 (72)\ttotal: 226ms\tremaining: 892ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6426165296\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2e997b53-a479-47fa-96ac-fd8504781709\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5331426\tbest: 0.5331426 (0)\ttotal: 1.84ms\tremaining: 921ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7044241\tbest: 0.7244851 (58)\ttotal: 166ms\tremaining: 658ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7244851259\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7244851258581235 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7244851258581235.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7244851258581235 in 0:00:00.410186\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.36ms\tremaining: 681ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7245614\tbest: 0.7290618 (50)\ttotal: 124ms\tremaining: 489ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7488940\tbest: 0.7490465 (197)\ttotal: 249ms\tremaining: 370ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7537757\tbest: 0.7571320 (273)\ttotal: 382ms\tremaining: 252ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7571319603\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7571319603356217 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.7571319603356217.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7571319603356217 in 0:00:00.663376\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 0.7571 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 3.77ms\tremaining: 11.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7250953\tbest: 0.7370709 (13)\ttotal: 230ms\tremaining: 6.61s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7370709382\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5556064\tbest: 0.5556064 (0)\ttotal: 1.51ms\tremaining: 4.53s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650648\tbest: 0.7718535 (86)\ttotal: 333ms\tremaining: 9.56s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7718535469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 86\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 87 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5537799\tbest: 0.5537799 (0)\ttotal: 2.21ms\tremaining: 6.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6231884\tbest: 0.6231884 (100)\ttotal: 338ms\tremaining: 9.71s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6173130\tbest: 0.6308656 (110)\ttotal: 699ms\tremaining: 9.74s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6308656483\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6509597\tbest: 0.6509597 (0)\ttotal: 1.83ms\tremaining: 5.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7686643\tbest: 0.7754798 (95)\ttotal: 201ms\tremaining: 5.77s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7754798277\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5874657\tbest: 0.5874657 (0)\ttotal: 6.76ms\tremaining: 20.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6279671\tbest: 0.6520956 (66)\ttotal: 395ms\tremaining: 11.3s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6520955738\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 66\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 67 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 2.42 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 11.54 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 11.80 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203], 'embed_sizes': array([ 8, 19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49,\n",
      "       13,  8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 204}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6490524781341108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6751794124243103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6962884054720789\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7440569634447185\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7555505718771025\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.755690737833595\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7507288629737608\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.743748598340435\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 10.03 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.716865\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.718435\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.711987\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[128]\tvalid's auc: 0.726901\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751626\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.748991\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.745935\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[148]\tvalid's auc: 0.752635\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5284257\tbest: 0.5284257 (0)\ttotal: 4.05ms\tremaining: 2.02s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6480713\tbest: 0.6538181 (91)\ttotal: 388ms\tremaining: 1.53s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6696008\tbest: 0.6750953 (140)\ttotal: 784ms\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6842902\tbest: 0.6928403 (264)\ttotal: 1.17s\tremaining: 772ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6928403229\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 264\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 265 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6928403229423638\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 3.80 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7563915676160574\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7642688943709353\u001b[0m, weights = \u001b[1m[0.43055 0.56945 0.     ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7644651267100246\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7644651267100246\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 10.02 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #7 [__TLearner__TabularAutoML__] is fitted\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.38 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 190}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7234935163996948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7311975591151791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7366132723112128\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7450800915331808\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.745537757437071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7456140350877192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.743020594965675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7386727688787186\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 11.23 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.719527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736156\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.741266\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.737147\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.73341\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.749428\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.726926\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.72746\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.722502\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.739512\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5727689\tbest: 0.5727689 (0)\ttotal: 3.63ms\tremaining: 1.81s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7062548\tbest: 0.7141876 (47)\ttotal: 228ms\tremaining: 901ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7240275\tbest: 0.7278413 (194)\ttotal: 447ms\tremaining: 665ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7278413425\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5815408\tbest: 0.5815408 (0)\ttotal: 2.25ms\tremaining: 1.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7398932\tbest: 0.7468345 (88)\ttotal: 223ms\tremaining: 883ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7468344775\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4952996\tbest: 0.4952996 (0)\ttotal: 2.24ms\tremaining: 1.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6314924\tbest: 0.6426165 (72)\ttotal: 231ms\tremaining: 913ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6426165296\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-25d023cf-856c-4db5-8007-f2add6e5199a\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5331426\tbest: 0.5331426 (0)\ttotal: 1.87ms\tremaining: 934ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7044241\tbest: 0.7244851 (58)\ttotal: 179ms\tremaining: 706ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7244851259\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7244851258581235 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7244851258581235.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7244851258581235 in 0:00:00.426220\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.41ms\tremaining: 705ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7245614\tbest: 0.7290618 (50)\ttotal: 139ms\tremaining: 548ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7488940\tbest: 0.7490465 (197)\ttotal: 268ms\tremaining: 399ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7537757\tbest: 0.7571320 (273)\ttotal: 390ms\tremaining: 258ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7571319603\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7571319603356217 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.7571319603356217.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7571319603356217 in 0:00:00.621401\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 0.7571 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.82ms\tremaining: 5.46s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7250953\tbest: 0.7370709 (13)\ttotal: 140ms\tremaining: 4.01s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7370709382\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5556064\tbest: 0.5556064 (0)\ttotal: 1.44ms\tremaining: 4.32s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650648\tbest: 0.7718535 (86)\ttotal: 122ms\tremaining: 3.51s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7718535469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 86\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 87 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5537799\tbest: 0.5537799 (0)\ttotal: 1.47ms\tremaining: 4.4s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6231884\tbest: 0.6231884 (100)\ttotal: 129ms\tremaining: 3.69s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6173130\tbest: 0.6308656 (110)\ttotal: 252ms\tremaining: 3.51s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6308656483\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6509597\tbest: 0.6509597 (0)\ttotal: 1.43ms\tremaining: 4.28s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7686643\tbest: 0.7754798 (95)\ttotal: 128ms\tremaining: 3.68s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7754798277\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5874657\tbest: 0.5874657 (0)\ttotal: 1.51ms\tremaining: 4.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6279671\tbest: 0.6520956 (66)\ttotal: 128ms\tremaining: 3.68s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6520955738\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 66\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 67 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.13 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.72 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/lightautoml/addons/uplift/metalearners.py:566: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dependent_train_data[self._other_group_pred_col] = sg_oof_pred\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 125)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.11 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204], 'embed_sizes': array([ 8, 19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49,\n",
      "       13,  8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 205}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6751513792330119\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.700633550123346\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7196680870150258\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7580455259026687\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7652500560663826\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7553823727293115\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7495234357479256\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7652500560663826\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 10.57 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.73276\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.733545\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.724518\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[128]\tvalid's auc: 0.73674\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.752607\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.745206\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[99]\tvalid's auc: 0.753224\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7532238169993272\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6194915\tbest: 0.6194915 (0)\ttotal: 4.13ms\tremaining: 2.06s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6749551\tbest: 0.6749551 (100)\ttotal: 418ms\tremaining: 1.65s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6831128\tbest: 0.6884671 (177)\ttotal: 819ms\tremaining: 1.22s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6960361\tbest: 0.6973256 (285)\ttotal: 1.23s\tremaining: 812ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6973256336\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 285\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 286 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6973256335501232\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.53 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7597835837631756\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7715014577259475\u001b[0m, weights = \u001b[1m[0.41960657 0.5175336  0.06285983]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7715294909172461\u001b[0m, weights = \u001b[1m[0.6558236  0.34417638 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7715294909172461\u001b[0m, weights = \u001b[1m[0.6558236  0.34417638 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.28 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.65582 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.34418 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #8 [__TDLearner__TabularAutoML__] is fitted\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: ['FLAG_CONT_MOBILE', 'REG_REGION_NOT_LIVE_REGION', 'OBS_60_CNT_SOCIAL_CIRCLE', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_19']\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.06 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 184}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7619840507880724\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7712375695696688\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7760733479528538\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7954448030438833\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8078548628799983\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8355126810759873\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8455385073209788\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8605559905197488\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8635885372567497\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8653988542925061\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8650127005608086\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8650127005608085\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7707734765526746\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7811748284450051\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.787682758767284\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.813243301649833\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8263477296640462\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8507816956045785\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8570593507657536\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8662455583464117\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8676024104495326\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8685624807365971\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8681869550892582\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8681975831736168\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7709849742476482\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7811404815618838\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7875714751911916\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8140368052895189\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8281438442656678\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8541622327218035\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8619659756806993\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8732778558152073\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8754699981554788\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8780239503965719\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8780239503965719\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8776479518721889\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7778150229146272\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7866350260361243\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7918493451950227\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8144305395933542\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8265547184267652\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8500971920713971\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8571631266050881\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8641120049943954\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8641226464620668\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8611501298259056\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8611501298259056\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7713858028632642\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7778700038309283\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7819421387931156\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8015153449963819\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8125895656862328\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8362774727223713\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8447729110798962\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.85813859447495\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8610720923963167\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8632464989571362\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8632606875806978\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8618914854070007\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.8618914854070007\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8671189326005863\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999982.32 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.09 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203], 'embed_sizes': array([ 8, 19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49,\n",
      "       13,  8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 204}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6490524781341108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6751794124243103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6962884054720789\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7440569634447185\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7555505718771025\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.755690737833595\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7507288629737608\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.743748598340435\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 10.28 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.716865\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.718435\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.711987\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[128]\tvalid's auc: 0.726901\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751626\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.748991\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.745935\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[148]\tvalid's auc: 0.752635\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5284257\tbest: 0.5284257 (0)\ttotal: 4.86ms\tremaining: 2.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6480713\tbest: 0.6538181 (91)\ttotal: 402ms\tremaining: 1.59s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6696008\tbest: 0.6750953 (140)\ttotal: 776ms\tremaining: 1.15s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6842902\tbest: 0.6928403 (264)\ttotal: 1.16s\tremaining: 767ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6928403229\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 264\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 265 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6928403229423638\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.15 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7563915676160574\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7642688943709353\u001b[0m, weights = \u001b[1m[0.43055 0.56945 0.     ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7644651267100246\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7644651267100246\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.66 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.36 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 190}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7234935163996948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7311975591151791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7366132723112128\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7450800915331808\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.745537757437071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7456140350877192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.743020594965675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7386727688787186\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 11.07 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.719527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736156\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.741266\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.737147\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.73341\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.749428\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.726926\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.72746\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.722502\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.739512\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5727689\tbest: 0.5727689 (0)\ttotal: 2.32ms\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7062548\tbest: 0.7141876 (47)\ttotal: 218ms\tremaining: 859ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7240275\tbest: 0.7278413 (194)\ttotal: 438ms\tremaining: 652ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7278413425\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5815408\tbest: 0.5815408 (0)\ttotal: 2.33ms\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7398932\tbest: 0.7468345 (88)\ttotal: 213ms\tremaining: 843ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7468344775\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4952996\tbest: 0.4952996 (0)\ttotal: 2.24ms\tremaining: 1.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6314924\tbest: 0.6426165 (72)\ttotal: 221ms\tremaining: 874ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6426165296\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-524e6a67-bfdc-4567-b4cb-91118658799c\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5331426\tbest: 0.5331426 (0)\ttotal: 1.89ms\tremaining: 945ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7044241\tbest: 0.7244851 (58)\ttotal: 168ms\tremaining: 662ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7244851259\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7244851258581235 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7244851258581235.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7244851258581235 in 0:00:00.423269\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.36ms\tremaining: 680ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7245614\tbest: 0.7290618 (50)\ttotal: 126ms\tremaining: 499ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7488940\tbest: 0.7490465 (197)\ttotal: 245ms\tremaining: 364ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7537757\tbest: 0.7571320 (273)\ttotal: 369ms\tremaining: 244ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7571319603\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7571319603356217 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.7571319603356217.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7571319603356217 in 0:00:00.619133\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 0.7571 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.88ms\tremaining: 5.65s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7250953\tbest: 0.7370709 (13)\ttotal: 133ms\tremaining: 3.82s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7370709382\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5556064\tbest: 0.5556064 (0)\ttotal: 1.52ms\tremaining: 4.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650648\tbest: 0.7718535 (86)\ttotal: 125ms\tremaining: 3.59s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7718535469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 86\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 87 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5537799\tbest: 0.5537799 (0)\ttotal: 1.52ms\tremaining: 4.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6231884\tbest: 0.6231884 (100)\ttotal: 129ms\tremaining: 3.7s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6173130\tbest: 0.6308656 (110)\ttotal: 255ms\tremaining: 3.54s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6308656483\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6509597\tbest: 0.6509597 (0)\ttotal: 1.5ms\tremaining: 4.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7686643\tbest: 0.7754798 (95)\ttotal: 123ms\tremaining: 3.53s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7754798277\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5874657\tbest: 0.5874657 (0)\ttotal: 1.44ms\tremaining: 4.32s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6279671\tbest: 0.6520956 (66)\ttotal: 130ms\tremaining: 3.74s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6520955738\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 66\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 67 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.09 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.78 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.11 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], 'embed_sizes': array([ 6,  5,  3,  3,  9,  7,  3,  5, 49, 13,  8, 36, 13,  8],\n",
      "      dtype=int32), 'data_size': 186}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07093726938398473\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.0704291346516548\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07031142141410163\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07037027532245685\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07057521661797152\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.06212071301845505\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06166575830034786\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.06164247941905598\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06216234322604961\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06256765384868207\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0659769504165788\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 10.84 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0701653\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0703635\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0706011\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[111]\tvalid's l2: 0.0701198\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0700265\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0699663\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0702125\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[162]\tvalid's l2: 0.0698633\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.0698632892768944\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2458766\ttest: 0.2672492\tbest: 0.2672492 (0)\ttotal: 2.78ms\tremaining: 5.55s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2224887\ttest: 0.2672056\tbest: 0.2667037 (20)\ttotal: 252ms\tremaining: 4.74s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2014391\ttest: 0.2686460\tbest: 0.2667037 (20)\ttotal: 508ms\tremaining: 4.55s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1782851\ttest: 0.2697492\tbest: 0.2667037 (20)\ttotal: 781ms\tremaining: 4.41s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2667037312\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 20\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 21 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2505670\ttest: 0.2500807\tbest: 0.2500807 (0)\ttotal: 3.68ms\tremaining: 7.35s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2290464\ttest: 0.2464674\tbest: 0.2462925 (76)\ttotal: 263ms\tremaining: 4.94s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2086461\ttest: 0.2465990\tbest: 0.2460105 (109)\ttotal: 513ms\tremaining: 4.59s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1862601\ttest: 0.2472577\tbest: 0.2460105 (109)\ttotal: 773ms\tremaining: 4.36s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1669461\ttest: 0.2485226\tbest: 0.2460105 (109)\ttotal: 1.03s\tremaining: 4.13s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2460104782\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 109\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 110 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.0658260178572445\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.34 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.0654696826635753\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.06519862041132674\u001b[0m, weights = \u001b[1m[0.         0.9498603  0.05013971]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06519862041132674\u001b[0m, weights = \u001b[1m[0.         0.9498603  0.05013971]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.37 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.94986 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.05014 * (2 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.40 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([16,  6, 10,  3,  3, 11,  5,  4, 13, 11, 35,  3,  4, 47, 13,  8, 24,\n",
      "       13,  8, 11], dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07449485797186384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07423297648580518\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0742281102128536\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07548342725769143\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07662500792022853\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07697611915152407\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07627645175899474\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07609266747410862\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07657355182780512\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07721748413374047\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0751603888434811\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 11.18 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767461\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0784016\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[3]\tvalid's l2: 0.0744974\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767052\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0793602\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.0745394\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0772268\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0787542\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[41]\tvalid's l2: 0.0768315\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.07568543440913018\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2931105\ttest: 0.2730306\tbest: 0.2730306 (0)\ttotal: 1.52ms\tremaining: 3.04s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2539640\ttest: 0.2789047\tbest: 0.2730306 (0)\ttotal: 84ms\tremaining: 1.58s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2209009\ttest: 0.2840797\tbest: 0.2730306 (0)\ttotal: 174ms\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1905947\ttest: 0.2888705\tbest: 0.2730306 (0)\ttotal: 256ms\tremaining: 1.44s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730305773\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2918162\ttest: 0.2783974\tbest: 0.2783974 (0)\ttotal: 889us\tremaining: 1.78s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2541574\ttest: 0.2771797\tbest: 0.2761792 (42)\ttotal: 93ms\tremaining: 1.75s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2214694\ttest: 0.2806531\tbest: 0.2761792 (42)\ttotal: 204ms\tremaining: 1.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1907055\ttest: 0.2856095\tbest: 0.2761792 (42)\ttotal: 291ms\tremaining: 1.64s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2761791533\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2858305\ttest: 0.3014090\tbest: 0.3014090 (0)\ttotal: 911us\tremaining: 1.82s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2524039\ttest: 0.2927180\tbest: 0.2923455 (89)\ttotal: 93.4ms\tremaining: 1.76s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2186045\ttest: 0.2916859\tbest: 0.2908069 (148)\ttotal: 181ms\tremaining: 1.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1887229\ttest: 0.2944040\tbest: 0.2908069 (148)\ttotal: 265ms\tremaining: 1.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1652364\ttest: 0.2963591\tbest: 0.2908069 (148)\ttotal: 350ms\tremaining: 1.4s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2908068672\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 148\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 149 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2898185\ttest: 0.2854178\tbest: 0.2854178 (0)\ttotal: 920us\tremaining: 1.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2569051\ttest: 0.2821814\tbest: 0.2813736 (83)\ttotal: 87.2ms\tremaining: 1.64s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2260265\ttest: 0.2835825\tbest: 0.2813736 (83)\ttotal: 176ms\tremaining: 1.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1946849\ttest: 0.2851189\tbest: 0.2813736 (83)\ttotal: 278ms\tremaining: 1.57s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2813735614\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 83\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 84 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2842533\ttest: 0.3080572\tbest: 0.3080572 (0)\ttotal: 866us\tremaining: 1.73s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2494624\ttest: 0.3061037\tbest: 0.3055388 (76)\ttotal: 82.9ms\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2168374\ttest: 0.3099174\tbest: 0.3055388 (76)\ttotal: 165ms\tremaining: 1.47s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1874059\ttest: 0.3135705\tbest: 0.3055388 (76)\ttotal: 245ms\tremaining: 1.38s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.305538818\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.08157640428059512\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-f3439155-4f94-4bcc-8f33-4e2fcef20a0d\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2930198\ttest: 0.2730346\tbest: 0.2730346 (0)\ttotal: 697us\tremaining: 1.39s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2626308\ttest: 0.2786636\tbest: 0.2730346 (0)\ttotal: 61.6ms\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2405736\ttest: 0.2827328\tbest: 0.2730346 (0)\ttotal: 126ms\tremaining: 1.13s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2190736\ttest: 0.2884436\tbest: 0.2730346 (0)\ttotal: 190ms\tremaining: 1.07s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730345851\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.07454788496599066 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.07454788496599066.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.07454788496599066 in 0:00:00.300714\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934392\ttest: 0.2730211\tbest: 0.2730211 (0)\ttotal: 586us\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2762059\ttest: 0.2753635\tbest: 0.2727228 (1)\ttotal: 51.8ms\tremaining: 974ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2624159\ttest: 0.2795560\tbest: 0.2727228 (1)\ttotal: 111ms\tremaining: 997ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2485725\ttest: 0.2823829\tbest: 0.2727228 (1)\ttotal: 165ms\tremaining: 932ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2727227973\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.0743777244717666 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: -0.0743777244717666.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.0743777244717666 in 0:00:00.294915\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2932603\ttest: 0.2729836\tbest: 0.2729836 (0)\ttotal: 579us\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2739754\ttest: 0.2788363\tbest: 0.2729836 (0)\ttotal: 53.5ms\tremaining: 1.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2581291\ttest: 0.2842183\tbest: 0.2729836 (0)\ttotal: 107ms\tremaining: 961ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2441654\ttest: 0.2879016\tbest: 0.2729836 (0)\ttotal: 158ms\tremaining: 894ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.272983633\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.07452006419389333 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: -0.0743777244717666.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.07452006419389333 in 0:00:00.280864\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934392\ttest: 0.2730211\tbest: 0.2730211 (0)\ttotal: 554us\tremaining: 1.11s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2762017\ttest: 0.2753644\tbest: 0.2727228 (1)\ttotal: 48.1ms\tremaining: 904ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2624074\ttest: 0.2795581\tbest: 0.2727228 (1)\ttotal: 95ms\tremaining: 850ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2485611\ttest: 0.2823859\tbest: 0.2727228 (1)\ttotal: 145ms\tremaining: 820ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2727227842\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.07437771729254725 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 3 with value: -0.07437771729254725.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.07437771729254725 in 0:00:00.275540\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}\u001b[0m\n",
      " achieve -0.0744 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 7.71800699380605e-05, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 6, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934784\ttest: 0.2729962\tbest: 0.2729962 (0)\ttotal: 830us\tremaining: 2.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2818313\ttest: 0.2741072\tbest: 0.2728140 (1)\ttotal: 54.1ms\tremaining: 1.55s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2728139867\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2922093\ttest: 0.2783588\tbest: 0.2783588 (0)\ttotal: 682us\tremaining: 2.05s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2810740\ttest: 0.2773695\tbest: 0.2769819 (47)\ttotal: 69.8ms\tremaining: 2s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2769818792\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 47\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 48 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861366\ttest: 0.3015423\tbest: 0.3015423 (0)\ttotal: 577us\tremaining: 1.73s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2772232\ttest: 0.2969872\tbest: 0.2969685 (98)\ttotal: 49.9ms\tremaining: 1.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2709412\ttest: 0.2946235\tbest: 0.2946235 (200)\ttotal: 99.2ms\tremaining: 1.38s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2630969\ttest: 0.2944796\tbest: 0.2941172 (232)\ttotal: 149ms\tremaining: 1.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2542882\ttest: 0.2939718\tbest: 0.2939312 (398)\ttotal: 200ms\tremaining: 1.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2460489\ttest: 0.2939368\tbest: 0.2937800 (437)\ttotal: 252ms\tremaining: 1.25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2388600\ttest: 0.2943532\tbest: 0.2936933 (523)\ttotal: 304ms\tremaining: 1.21s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2936933275\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 523\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 524 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2903441\ttest: 0.2855145\tbest: 0.2855145 (0)\ttotal: 663us\tremaining: 1.99s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2795555\ttest: 0.2831808\tbest: 0.2830044 (88)\ttotal: 50.4ms\tremaining: 1.45s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2727980\ttest: 0.2829466\tbest: 0.2826695 (152)\ttotal: 100ms\tremaining: 1.4s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2826694542\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 152\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 153 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2845696\ttest: 0.3080152\tbest: 0.3080152 (0)\ttotal: 530us\tremaining: 1.59s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2734864\ttest: 0.3051470\tbest: 0.3051380 (97)\ttotal: 47.1ms\tremaining: 1.35s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2667230\ttest: 0.3047675\tbest: 0.3046527 (189)\ttotal: 98.4ms\tremaining: 1.37s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3046527142\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.08201675266808113\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.57 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.0815739155610045\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.08140332830968236\u001b[0m, weights = \u001b[1m[0.5454414  0.         0.45455867 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.08140164609517518\u001b[0m, weights = \u001b[1m[0.60477763 0.         0.39522237 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.08140164609517518\u001b[0m, weights = \u001b[1m[0.60477763 0.         0.39522237 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.21 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.60478 * (2 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.39522 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #9 [__XLearner__Propensity_Linear__Other_TabularAutoML__] is fitted\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (5600, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 11.76 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181], 'embed_sizes': array([ 8, 20,  6,  3,  3,  6,  9,  9,  7,  3,  5, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 182}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7638864778882705\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7718079434302496\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7763886477888269\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7967237158617074\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.808588200700745\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8356827304257257\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8457652397872966\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8617038236304828\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.8647859680944907\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8673402510353527\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8673402510353527\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.865267774585416\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8673402510353527\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 7.95 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.853589\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.862699\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.868265\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.871723\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.873575\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.874578\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.874061\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.873476\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[634]\tvalid's auc: 0.87473\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.874911\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.880654\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.883229\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.885128\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.886145\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.886042\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.886024\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.88561\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[644]\tvalid's auc: 0.886379\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8863786928164779\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left -7.90 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.8851812619787367\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8880685582295029\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8880685582295029\u001b[0m, weights = \u001b[1m[0.23606798 0.76393205]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 21.65 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.23607 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.76393 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.13 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203], 'embed_sizes': array([ 8, 19, 15,  6,  5, 15,  5,  3,  5,  9, 16,  9,  4,  7,  3,  6, 49,\n",
      "       13,  8, 36, 13,  8,  6,  6,  7,  9,  9,  8, 11, 11, 11, 11],\n",
      "      dtype=int32), 'data_size': 204}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6490524781341108\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6751794124243103\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6962884054720789\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7440569634447185\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7555505718771025\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.755690737833595\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7507288629737608\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.743748598340435\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.755690737833595\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 10.23 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.716865\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.718435\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.711987\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[128]\tvalid's auc: 0.726901\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751626\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.748991\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.745935\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[148]\tvalid's auc: 0.752635\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7526351199820588\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5284257\tbest: 0.5284257 (0)\ttotal: 4.21ms\tremaining: 2.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6480713\tbest: 0.6538181 (91)\ttotal: 389ms\tremaining: 1.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6696008\tbest: 0.6750953 (140)\ttotal: 792ms\tremaining: 1.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.6842902\tbest: 0.6928403 (264)\ttotal: 1.17s\tremaining: 774ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6928403229\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 264\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 265 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6928403229423638\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.05 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7563915676160574\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7642688943709353\u001b[0m, weights = \u001b[1m[0.43055 0.56945 0.     ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7644651267100246\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7644651267100246\u001b[0m, weights = \u001b[1m[0.38196602 0.618034   0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.78 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38197 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.61803 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.35 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], 'embed_sizes': array([12,  6,  3,  3, 35,  5,  4,  4, 12,  7,  3,  4, 47, 13,  8, 24, 13,\n",
      "        8,  3], dtype=int32), 'data_size': 190}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7234935163996948\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7311975591151791\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7366132723112128\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7450800915331808\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.745537757437071\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7456140350877192\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.743020594965675\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7386727688787186\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7456140350877192\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 11.02 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.719527\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736156\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.741266\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.737147\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.73341\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.749428\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.726926\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.72746\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.722502\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.739512\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.707418001525553\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5727689\tbest: 0.5727689 (0)\ttotal: 2.32ms\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7062548\tbest: 0.7141876 (47)\ttotal: 218ms\tremaining: 863ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7240275\tbest: 0.7278413 (194)\ttotal: 430ms\tremaining: 640ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7278413425\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5815408\tbest: 0.5815408 (0)\ttotal: 2.36ms\tremaining: 1.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7398932\tbest: 0.7468345 (88)\ttotal: 238ms\tremaining: 939ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7468344775\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4952996\tbest: 0.4952996 (0)\ttotal: 2.34ms\tremaining: 1.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6314924\tbest: 0.6426165 (72)\ttotal: 220ms\tremaining: 867ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6426165296\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 2\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6841092727972298\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-04e815a5-786f-42cf-a423-bfccef5d4f9d\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5331426\tbest: 0.5331426 (0)\ttotal: 1.82ms\tremaining: 909ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7044241\tbest: 0.7244851 (58)\ttotal: 188ms\tremaining: 745ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7244851259\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 58\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 59 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.7244851258581235 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.7244851258581235.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.7244851258581235 in 0:00:00.466891\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.49ms\tremaining: 746ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7245614\tbest: 0.7290618 (50)\ttotal: 129ms\tremaining: 508ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.7488940\tbest: 0.7490465 (197)\ttotal: 259ms\tremaining: 385ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\ttest: 0.7537757\tbest: 0.7571320 (273)\ttotal: 383ms\tremaining: 254ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7571319603\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 273\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 274 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.7571319603356217 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.7571319603356217.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.7571319603356217 in 0:00:00.625264\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}\u001b[0m\n",
      " achieve 0.7571 auc\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.002570603566117598, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 15, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5509153\tbest: 0.5509153 (0)\ttotal: 1.37ms\tremaining: 4.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7250953\tbest: 0.7370709 (13)\ttotal: 135ms\tremaining: 3.87s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7370709382\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 13\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 14 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5556064\tbest: 0.5556064 (0)\ttotal: 1.34ms\tremaining: 4.03s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7650648\tbest: 0.7718535 (86)\ttotal: 126ms\tremaining: 3.62s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7718535469\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 86\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 87 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5537799\tbest: 0.5537799 (0)\ttotal: 1.44ms\tremaining: 4.33s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6231884\tbest: 0.6231884 (100)\ttotal: 130ms\tremaining: 3.72s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6173130\tbest: 0.6308656 (110)\ttotal: 257ms\tremaining: 3.58s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6308656483\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6509597\tbest: 0.6509597 (0)\ttotal: 1.51ms\tremaining: 4.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7686643\tbest: 0.7754798 (95)\ttotal: 146ms\tremaining: 4.2s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7754798277\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5874657\tbest: 0.5874657 (0)\ttotal: 1.39ms\tremaining: 4.17s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6279671\tbest: 0.6520956 (66)\ttotal: 123ms\tremaining: 3.54s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6520955738\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 66\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 67 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.6426784468728202\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 3.92 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7011609703169805\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7005130589785321\u001b[0m, weights = \u001b[1m[0.38284618 0.6171538  0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7061303572812525\u001b[0m, weights = \u001b[1m[0.72890556 0.27109444 0.         0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.95 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.72891 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.27109 * (2 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (3688, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.13 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], 'embed_sizes': array([ 6,  5,  3,  3,  9,  7,  3,  5, 49, 13,  8, 36, 13,  8],\n",
      "      dtype=int32), 'data_size': 186}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07093726938398473\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.0704291346516548\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07031142141410163\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07037027532245685\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07057521661797152\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.06212071301845505\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.06166575830034786\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.06164247941905598\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.06216234322604961\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.06256765384868207\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0659769504165788\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 10.88 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0701653\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0703635\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0706011\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[111]\tvalid's l2: 0.0701198\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0700265\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0699663\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0702125\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[162]\tvalid's l2: 0.0698633\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.0698632892768944\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2458766\ttest: 0.2672492\tbest: 0.2672492 (0)\ttotal: 2.76ms\tremaining: 5.52s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2224887\ttest: 0.2672056\tbest: 0.2667037 (20)\ttotal: 258ms\tremaining: 4.86s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2014391\ttest: 0.2686460\tbest: 0.2667037 (20)\ttotal: 513ms\tremaining: 4.59s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1782851\ttest: 0.2697492\tbest: 0.2667037 (20)\ttotal: 779ms\tremaining: 4.39s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2667037312\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 20\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 21 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2505670\ttest: 0.2500807\tbest: 0.2500807 (0)\ttotal: 2.72ms\tremaining: 5.44s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2290464\ttest: 0.2464674\tbest: 0.2462925 (76)\ttotal: 258ms\tremaining: 4.86s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2086461\ttest: 0.2465990\tbest: 0.2460105 (109)\ttotal: 511ms\tremaining: 4.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1862601\ttest: 0.2472577\tbest: 0.2460105 (109)\ttotal: 769ms\tremaining: 4.34s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1669461\ttest: 0.2485226\tbest: 0.2460105 (109)\ttotal: 1.03s\tremaining: 4.12s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2460104782\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 109\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 110 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.0658260178572445\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.45 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.0654696826635753\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.06519862041132674\u001b[0m, weights = \u001b[1m[0.         0.9498603  0.05013971]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06519862041132674\u001b[0m, weights = \u001b[1m[0.         0.9498603  0.05013971]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.26 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.94986 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.05014 * (2 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 13.64 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (1912, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 12.37 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'embed_sizes': array([16,  6, 10,  3,  3, 11,  5,  4, 13, 11, 35,  3,  4, 47, 13,  8, 24,\n",
      "       13,  8, 11], dtype=int32), 'data_size': 212}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07449485797186384\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07423297648580518\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.0742281102128536\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07548342725769143\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07662500792022853\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.07697611915152407\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07627645175899474\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07609266747410862\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07657355182780512\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07721748413374047\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.0751603888434811\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 11.14 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767461\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0784016\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[3]\tvalid's l2: 0.0744974\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0767052\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0793602\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1]\tvalid's l2: 0.0745394\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0772268\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0787542\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[41]\tvalid's l2: 0.0768315\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 1\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.07568543440913018\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2931105\ttest: 0.2730306\tbest: 0.2730306 (0)\ttotal: 924us\tremaining: 1.85s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2539640\ttest: 0.2789047\tbest: 0.2730306 (0)\ttotal: 94.2ms\tremaining: 1.77s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2209009\ttest: 0.2840797\tbest: 0.2730306 (0)\ttotal: 191ms\tremaining: 1.71s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1905947\ttest: 0.2888705\tbest: 0.2730306 (0)\ttotal: 278ms\tremaining: 1.57s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730305773\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2918162\ttest: 0.2783974\tbest: 0.2783974 (0)\ttotal: 5.53ms\tremaining: 11.1s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2541574\ttest: 0.2771797\tbest: 0.2761792 (42)\ttotal: 89ms\tremaining: 1.67s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2214694\ttest: 0.2806531\tbest: 0.2761792 (42)\ttotal: 180ms\tremaining: 1.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1907055\ttest: 0.2856095\tbest: 0.2761792 (42)\ttotal: 280ms\tremaining: 1.58s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2761791533\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2858305\ttest: 0.3014090\tbest: 0.3014090 (0)\ttotal: 1.15ms\tremaining: 2.31s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2524039\ttest: 0.2927180\tbest: 0.2923455 (89)\ttotal: 83ms\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2186045\ttest: 0.2916859\tbest: 0.2908069 (148)\ttotal: 180ms\tremaining: 1.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1887229\ttest: 0.2944040\tbest: 0.2908069 (148)\ttotal: 265ms\tremaining: 1.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.1652364\ttest: 0.2963591\tbest: 0.2908069 (148)\ttotal: 378ms\tremaining: 1.51s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2908068672\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 148\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 149 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2898185\ttest: 0.2854178\tbest: 0.2854178 (0)\ttotal: 1.07ms\tremaining: 2.15s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2569051\ttest: 0.2821814\tbest: 0.2813736 (83)\ttotal: 89.6ms\tremaining: 1.69s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2260265\ttest: 0.2835825\tbest: 0.2813736 (83)\ttotal: 175ms\tremaining: 1.57s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1946849\ttest: 0.2851189\tbest: 0.2813736 (83)\ttotal: 264ms\tremaining: 1.49s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2813735614\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 83\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 84 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 3\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.07863586185253599\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 1.00 secs\n",
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-eaa204a8-37e9-4268-a065-b20ecac44af5\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2930198\ttest: 0.2730346\tbest: 0.2730346 (0)\ttotal: 788us\tremaining: 1.58s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2626308\ttest: 0.2786636\tbest: 0.2730346 (0)\ttotal: 69ms\tremaining: 1.3s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2405736\ttest: 0.2827328\tbest: 0.2730346 (0)\ttotal: 139ms\tremaining: 1.24s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2190736\ttest: 0.2884436\tbest: 0.2730346 (0)\ttotal: 205ms\tremaining: 1.16s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2730345851\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 0 finished with value: -0.07454788496599066 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: -0.07454788496599066.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored -0.07454788496599066 in 0:00:00.340392\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934392\ttest: 0.2730211\tbest: 0.2730211 (0)\ttotal: 624us\tremaining: 1.25s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2762059\ttest: 0.2753635\tbest: 0.2727228 (1)\ttotal: 53.5ms\tremaining: 1.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2624159\ttest: 0.2795560\tbest: 0.2727228 (1)\ttotal: 111ms\tremaining: 994ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2485725\ttest: 0.2823829\tbest: 0.2727228 (1)\ttotal: 162ms\tremaining: 917ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2727227973\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: -0.0743777244717666 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 1 with value: -0.0743777244717666.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored -0.0743777244717666 in 0:00:00.283233\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2932603\ttest: 0.2729836\tbest: 0.2729836 (0)\ttotal: 604us\tremaining: 1.21s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2739754\ttest: 0.2788363\tbest: 0.2729836 (0)\ttotal: 61.5ms\tremaining: 1.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2581291\ttest: 0.2842183\tbest: 0.2729836 (0)\ttotal: 112ms\tremaining: 1.01s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2441654\ttest: 0.2879016\tbest: 0.2729836 (0)\ttotal: 169ms\tremaining: 953ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.272983633\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: -0.07452006419389333 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: -0.0743777244717666.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored -0.07452006419389333 in 0:00:00.288893\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934392\ttest: 0.2730211\tbest: 0.2730211 (0)\ttotal: 595us\tremaining: 1.19s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2762017\ttest: 0.2753644\tbest: 0.2727228 (1)\ttotal: 52.1ms\tremaining: 979ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2624074\ttest: 0.2795581\tbest: 0.2727228 (1)\ttotal: 109ms\tremaining: 979ms\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2485611\ttest: 0.2823859\tbest: 0.2727228 (1)\ttotal: 156ms\tremaining: 883ms\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2727227842\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: -0.07437771729254725 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 3 with value: -0.07437771729254725.\n",
      "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored -0.07437771729254725 in 0:00:00.303814\n",
      "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}\u001b[0m\n",
      " achieve -0.0744 mse\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 7.71800699380605e-05, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 6, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2934784\ttest: 0.2729962\tbest: 0.2729962 (0)\ttotal: 727us\tremaining: 2.18s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2818313\ttest: 0.2741072\tbest: 0.2728140 (1)\ttotal: 73.5ms\tremaining: 2.11s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2728139867\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2922093\ttest: 0.2783588\tbest: 0.2783588 (0)\ttotal: 571us\tremaining: 1.71s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2810740\ttest: 0.2773695\tbest: 0.2769819 (47)\ttotal: 54.2ms\tremaining: 1.55s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2769818792\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 47\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 48 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2861366\ttest: 0.3015423\tbest: 0.3015423 (0)\ttotal: 614us\tremaining: 1.84s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2772232\ttest: 0.2969872\tbest: 0.2969685 (98)\ttotal: 59.9ms\tremaining: 1.72s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2709412\ttest: 0.2946235\tbest: 0.2946235 (200)\ttotal: 111ms\tremaining: 1.54s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.2630969\ttest: 0.2944796\tbest: 0.2941172 (232)\ttotal: 167ms\tremaining: 1.5s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:400:\tlearn: 0.2542882\ttest: 0.2939718\tbest: 0.2939312 (398)\ttotal: 221ms\tremaining: 1.43s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:500:\tlearn: 0.2460489\ttest: 0.2939368\tbest: 0.2937800 (437)\ttotal: 299ms\tremaining: 1.49s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:600:\tlearn: 0.2388600\ttest: 0.2943532\tbest: 0.2936933 (523)\ttotal: 358ms\tremaining: 1.43s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2936933275\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 523\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 524 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2903441\ttest: 0.2855145\tbest: 0.2855145 (0)\ttotal: 707us\tremaining: 2.12s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2795555\ttest: 0.2831808\tbest: 0.2830044 (88)\ttotal: 56.5ms\tremaining: 1.62s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2727980\ttest: 0.2829466\tbest: 0.2826695 (152)\ttotal: 107ms\tremaining: 1.48s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2826694542\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 152\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 153 iterations.\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2845696\ttest: 0.3080152\tbest: 0.3080152 (0)\ttotal: 521us\tremaining: 1.56s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2734864\ttest: 0.3051470\tbest: 0.3051380 (97)\ttotal: 56.1ms\tremaining: 1.61s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2667230\ttest: 0.3047675\tbest: 0.3046527 (189)\ttotal: 108ms\tremaining: 1.5s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.3046527142\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m-0.08201675266808113\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 4.70 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.08154555383349474\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.07842880752374629\u001b[0m, weights = \u001b[1m[0.46698883 0.         0.5330112  0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.07841747120589734\u001b[0m, weights = \u001b[1m[0.6047776  0.         0.39522243 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.07841747120589734\u001b[0m, weights = \u001b[1m[0.6047776  0.         0.39522243 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.08 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.60478 * (2 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.39522 * (4 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n",
      "INFO:lightautoml.addons.uplift.base:Uplift candidate #10 [__XLearner__TabularAutoML__] is fitted\n",
      "WARNING:lightautoml.addons.uplift.base:Time of training exceeds 'timeout': 345.2980740070343 > 300.\n",
      "WARNING:lightautoml.addons.uplift.base:There is fitted 11/13 candidates\n",
      "WARNING:lightautoml.addons.uplift.base:Try to increase 'timeout' or set 'None'(eq. infinity)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 31s, sys: 15 s, total: 7min 46s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using a custom metric\n",
    "# How to determine custom metric, see below\n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "\n",
    "class CustomUpliftMetric(TUpliftMetric):\n",
    "    def __call__(self, target: np.ndarray, uplift_pred: np.ndarray, treatment: np.ndarray) -> float:\n",
    "        up_10 = calculate_uplift_at_top(target, uplift_pred, treatment, 10)\n",
    "        up_20 = calculate_uplift_at_top(target, uplift_pred, treatment, 20)\n",
    "\n",
    "        return 0.5 * (up_10 + up_20)\n",
    "\n",
    "autouplift = AutoUplift(task,\n",
    "                        add_dd_candidates=True,\n",
    "                        metric=CustomUpliftMetric(),\n",
    "                        test_size=0.2,\n",
    "                        threshold_imbalance_treatment=0.0,\n",
    "                        cpu_limit=10,\n",
    "                        timeout=300)\n",
    "\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtM2Rcn-0jG9"
   },
   "source": [
    "### Show rating of uplift methods (meta-learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "l7YZjNHd0jG9",
    "outputId": "bcf8d2fa-8b52-4c71-eb54-242cffcc47e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.45 ms, sys: 14 µs, total: 4.46 ms\n",
      "Wall time: 4.58 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-44351e3c-99c0-453b-a0f9-583bd693231a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MetaLearner</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Metrics</th>\n",
       "      <th>WorkTime</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__SLearner__TabularAutoML__</td>\n",
       "      <td>{'timeout': None, 'learner': BaseLearnerWrappe...</td>\n",
       "      <td>0.091882</td>\n",
       "      <td>13.824842</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__TDLearner__TabularAutoML__</td>\n",
       "      <td>{'timeout': None, 'treatment_learner': BaseLea...</td>\n",
       "      <td>0.071742</td>\n",
       "      <td>19.531887</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__TLearner__TabularAutoML__</td>\n",
       "      <td>{'timeout': None, 'treatment_learner': BaseLea...</td>\n",
       "      <td>0.054898</td>\n",
       "      <td>21.660593</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__XLearner__Default__</td>\n",
       "      <td>{'base_task': &lt;lightautoml.tasks.base.Task obj...</td>\n",
       "      <td>0.052193</td>\n",
       "      <td>41.096292</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__RLearner__Linear__</td>\n",
       "      <td>{'timeout': None, 'propensity_learner': BaseLe...</td>\n",
       "      <td>0.049947</td>\n",
       "      <td>38.253768</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__XLearner__Propensity_Linear__Other_TabularAu...</td>\n",
       "      <td>{'timeout': None, 'outcome_learners': [BaseLea...</td>\n",
       "      <td>0.044471</td>\n",
       "      <td>56.870918</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__RLearner__Default__</td>\n",
       "      <td>{'base_task': &lt;lightautoml.tasks.base.Task obj...</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>46.593131</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__XLearner__TabularAutoML__</td>\n",
       "      <td>{'timeout': None, 'outcome_learners': [BaseLea...</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>60.958136</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__TLearner__Default__</td>\n",
       "      <td>{'base_task': &lt;lightautoml.tasks.base.Task obj...</td>\n",
       "      <td>0.029899</td>\n",
       "      <td>14.176472</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__TDLearner__Default__</td>\n",
       "      <td>{'base_task': &lt;lightautoml.tasks.base.Task obj...</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>14.241730</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>__SLearner__Default__</td>\n",
       "      <td>{'base_task': &lt;lightautoml.tasks.base.Task obj...</td>\n",
       "      <td>-0.035616</td>\n",
       "      <td>9.984988</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XLearner__Propensity_Linear__Control_Preset__T...</td>\n",
       "      <td>{'timeout': None, 'outcome_learners': [BaseLea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XLearner__Control_Preset__Treatment_Linear</td>\n",
       "      <td>{'timeout': None, 'outcome_learners': [BaseLea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44351e3c-99c0-453b-a0f9-583bd693231a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-44351e3c-99c0-453b-a0f9-583bd693231a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-44351e3c-99c0-453b-a0f9-583bd693231a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                          MetaLearner  \\\n",
       "0                         __SLearner__TabularAutoML__   \n",
       "1                        __TDLearner__TabularAutoML__   \n",
       "2                         __TLearner__TabularAutoML__   \n",
       "3                               __XLearner__Default__   \n",
       "4                                __RLearner__Linear__   \n",
       "5   __XLearner__Propensity_Linear__Other_TabularAu...   \n",
       "6                               __RLearner__Default__   \n",
       "7                         __XLearner__TabularAutoML__   \n",
       "8                               __TLearner__Default__   \n",
       "9                              __TDLearner__Default__   \n",
       "10                              __SLearner__Default__   \n",
       "11  XLearner__Propensity_Linear__Control_Preset__T...   \n",
       "12         XLearner__Control_Preset__Treatment_Linear   \n",
       "\n",
       "                                           Parameters   Metrics   WorkTime  \\\n",
       "0   {'timeout': None, 'learner': BaseLearnerWrappe...  0.091882  13.824842   \n",
       "1   {'timeout': None, 'treatment_learner': BaseLea...  0.071742  19.531887   \n",
       "2   {'timeout': None, 'treatment_learner': BaseLea...  0.054898  21.660593   \n",
       "3   {'base_task': <lightautoml.tasks.base.Task obj...  0.052193  41.096292   \n",
       "4   {'timeout': None, 'propensity_learner': BaseLe...  0.049947  38.253768   \n",
       "5   {'timeout': None, 'outcome_learners': [BaseLea...  0.044471  56.870918   \n",
       "6   {'base_task': <lightautoml.tasks.base.Task obj...  0.038690  46.593131   \n",
       "7   {'timeout': None, 'outcome_learners': [BaseLea...  0.034382  60.958136   \n",
       "8   {'base_task': <lightautoml.tasks.base.Task obj...  0.029899  14.176472   \n",
       "9   {'base_task': <lightautoml.tasks.base.Task obj...  0.026395  14.241730   \n",
       "10  {'base_task': <lightautoml.tasks.base.Task obj... -0.035616   9.984988   \n",
       "11  {'timeout': None, 'outcome_learners': [BaseLea...       NaN        NaN   \n",
       "12  {'timeout': None, 'outcome_learners': [BaseLea...       NaN        NaN   \n",
       "\n",
       "    Rank  \n",
       "0    1.0  \n",
       "1    2.0  \n",
       "2    3.0  \n",
       "3    4.0  \n",
       "4    5.0  \n",
       "5    6.0  \n",
       "6    7.0  \n",
       "7    8.0  \n",
       "8    9.0  \n",
       "9   10.0  \n",
       "10  11.0  \n",
       "11   NaN  \n",
       "12   NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rating_table = autouplift.get_metalearners_rating()\n",
    "rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaPz2Jd30jG9"
   },
   "source": [
    "## MetaLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlH8CwC00jG9"
   },
   "source": [
    "### TLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSfm-eJC0jG9"
   },
   "source": [
    "#### Fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZ8ykYXX0jG-",
    "outputId": "9042e465-ab2f-455d-cfe4-04872db7b3b0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (2390, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.65 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'embed_sizes': array([ 8, 18,  4, 11, 11,  4,  7,  3,  3,  6,  6,  5,  5, 13, 10, 47, 13,\n",
      "        8, 26, 13,  8, 11], dtype=int32), 'data_size': 202}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.729669887278583\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7392814009661836\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7506038647342995\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7763184380032206\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7823570853462157\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7888989533011272\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7862318840579711\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7684681964573269\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6308930246334601\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6470849582860246\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6606111467640815\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6966974379226933\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7091375820703955\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7147652663276892\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7096312385841931\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6794688255911537\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6481216369649998\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6609073406723601\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.670632373994175\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.697635385298909\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7092363133731548\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.718467690181172\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7178753023646147\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7121982524559411\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.634546082835563\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6484671965246581\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6567112603050798\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6656958088561978\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.6660413684158561\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6625857728192723\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6598212963420051\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6423458557535667\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.659870661993385\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6751740139211135\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7328824603840647\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7507528261835416\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7629461420743446\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7605765908081157\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7567754356518733\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7304580340294625\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999994.01 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (4610, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 9999999998.12 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'embed_sizes': array([30, 18,  6,  5,  3, 19, 17, 17,  9,  4,  3, 49, 13,  8, 37, 13,  8,\n",
      "       11, 11,  7,  7,  8,  7, 11, 11], dtype=int32), 'data_size': 202}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6245758908536038\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6469347455345121\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6660802441432546\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7161116596355803\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7307961583340813\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.754241091463962\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7591419082667623\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7667354815546181\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7653531998922898\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7596804595637734\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6449869850103221\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6655237411363433\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6828471411901984\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7180324925949195\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7215869311551925\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7051970200161566\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6928103401849027\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6263710618436407\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6482182927923884\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6700475720312361\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7315321784399964\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7494300332106634\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7668611435239207\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7684049905753524\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7606139484785925\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7540256709451576\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6267659994614487\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6423121802351673\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.652293330939772\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.6759895880082578\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.683565209586213\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.6937079256799211\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.6928103401849026\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.6817879903060767\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6751817610627412\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7022529395924962\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7212817520868863\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7533973610986446\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7611345480657032\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7711695539000091\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7698770307871825\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.750345570415582\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7442218831343684\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 9999999986.17 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 898 ms, total: 20.5 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "# Default setting\n",
    "tlearner = metalearners.TLearner(base_task=Task('binary'), cpu_limit=5)\n",
    "tlearner.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWvZBs730jG-"
   },
   "source": [
    "#### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJlIflC60jG-",
    "outputId": "e2b02247-53d3-4038-94ac-2bef6292abb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check scores ---\n",
      "OOF scores \"ROC_AUC\":\n",
      "\tTreatment = 0.68472\n",
      "\tControl   = 0.73299\n",
      "Uplift score of test group (default=\"adj_qini\"):\n",
      "\tBaseline      = 0.01340\n",
      "\tAlgo (Normed) = 0.01670 (0.04069)\n",
      "\tPerfect       = 0.09438\n",
      "CPU times: user 1.12 s, sys: 10.6 ms, total: 1.13 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "uplift_pred, treatment_pred, control_pred = tlearner.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "print('--- Check scores ---')\n",
    "print('OOF scores \"ROC_AUC\":')\n",
    "print('\\tTreatment = {:.5f}'.format(roc_auc_treatment))\n",
    "print('\\tControl   = {:.5f}'.format(roc_auc_control))\n",
    "print('Uplift score of test group (default=\"adj_qini\"):')\n",
    "print('\\tBaseline      = {:.5f}'.format(auc_base))\n",
    "print('\\tAlgo (Normed) = {:.5f} ({:.5f})'.format(uplift_auc_algo, uplift_auc_algo_normed))\n",
    "print('\\tPerfect       = {:.5f}'.format(auc_perfect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K_4Fd890jG-"
   },
   "source": [
    "### XLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqGRp8t_0jG-"
   },
   "source": [
    "#### Fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQnBGN5J0jG-",
    "outputId": "7771648d-a489-4c9e-b522-81eaff9597c2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 10.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (7000, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 7.79 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181], 'embed_sizes': array([35, 20,  6,  3,  9,  9,  7,  3,  6, 49, 13,  8, 38, 13,  8],\n",
      "      dtype=int32), 'data_size': 182}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7632625091895914\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7712358979478848\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7764410640866227\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7992244438595377\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8109281260494288\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8344285208615072\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8423361076067127\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.8552922970802059\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.857720164459652\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.8593436589549734\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.8593436589549734\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.8582488495992884\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8593436589549734\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 3.41 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847253\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.856556\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.860906\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.864448\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.865911\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.866674\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.866864\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.86701\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.867028\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.867611\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.868353\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.868487\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.868115\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1172]\tvalid's auc: 0.868634\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 32, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.5, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.856113\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.865426\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.871123\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.873808\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.875371\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.876723\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.877191\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.877184\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.87737\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.877699\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.877953\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.878321\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.878191\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's auc: 0.878137\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1500]\tvalid's auc: 0.878064\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[1600]\tvalid's auc: 0.878346\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[1430]\tvalid's auc: 0.878464\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8784636818268453\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left -41.91 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.8751418146833789\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8786792401455812\u001b[0m, weights = \u001b[1m[0.09852592 0.90147406]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8786792401455812\u001b[0m, weights = \u001b[1m[0.09852592 0.90147406]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 52.00 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.09853 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.90147 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 10.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (4610, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 8.25 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], 'embed_sizes': array([30, 18,  6,  5,  3, 19, 17, 17,  9,  4,  3, 49, 13,  8, 37, 13,  8,\n",
      "       11, 11,  7,  7,  8,  7, 11, 11], dtype=int32), 'data_size': 192}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6278879813302218\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6539269365407054\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6711605780450588\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.7155731083385692\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7295395386410556\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.752930616641235\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7581545642222421\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7656763306704963\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.7625886365676331\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.7537922987164527\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7656763306704963\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 5.44 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.751566\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.753954\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.755605\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.754385\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.753128\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[306]\tvalid's auc: 0.757365\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.776645\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.775191\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.770757\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[190]\tvalid's auc: 0.77862\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7786195135086618\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left -0.88 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7776860245938425\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.780253119109595\u001b[0m, weights = \u001b[1m[0.09016994 0.90983003]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.780253119109595\u001b[0m, weights = \u001b[1m[0.09016994 0.90983003]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 10.96 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.09017 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.90983 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: binary\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 10.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (2390, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 8.69 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], 'embed_sizes': array([ 8, 18,  4, 11, 11,  4,  7,  3,  3,  6,  6,  5,  5, 13, 10, 47, 13,\n",
      "        8, 26, 13,  8, 11], dtype=int32), 'data_size': 192}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7417975040257649\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7500503220611917\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7560889694041868\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.772493961352657\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.7786332528180354\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.7810990338164252\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.7767713365539453\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.7556863929146538\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7810990338164252\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 7.56 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.757448\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.773651\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.782105\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.782659\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.785578\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.787993\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.788446\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[546]\tvalid's auc: 0.789553\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.772645\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.778281\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.785427\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.786383\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.789201\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.788547\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[492]\tvalid's auc: 0.790006\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.790006038647343\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 0.85 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m0.7972020933977456\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7982085346215781\u001b[0m, weights = \u001b[1m[0.34520444 0.6547956 ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7982085346215781\u001b[0m, weights = \u001b[1m[0.34520444 0.6547956 ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 9.22 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.34520 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.65480 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 10.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (4610, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 8.17 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187], 'embed_sizes': array([ 6,  3,  5,  9,  4,  3,  3,  6, 49, 13,  8, 37, 13,  8],\n",
      "      dtype=int32), 'data_size': 188}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.070796646159767\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.07053951752606476\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.07052010936673676\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.07094496436909396\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.07141356309534819\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.07052010936673676\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 7.20 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0702975\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0702148\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0705006\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[137]\tvalid's l2: 0.0701572\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0701407\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0702952\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.0707701\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[116]\tvalid's l2: 0.0700329\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.07003284996143398\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2456203\ttest: 0.2666256\tbest: 0.2666256 (0)\ttotal: 2.97ms\tremaining: 5.93s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2277573\ttest: 0.2664001\tbest: 0.2659334 (32)\ttotal: 275ms\tremaining: 5.16s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2108182\ttest: 0.2681001\tbest: 0.2659334 (32)\ttotal: 730ms\tremaining: 6.53s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1914203\ttest: 0.2695821\tbest: 0.2659334 (32)\ttotal: 1.08s\tremaining: 6.12s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2659333936\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 32\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 33 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.07072056972976445\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 1.43 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.07018577383509919\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.07001074592330009\u001b[0m, weights = \u001b[1m[0.0539058  0.94609416 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.06997678848411243\u001b[0m, weights = \u001b[1m[0.24312113 0.75687885 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m-0.06997678848411243\u001b[0m, weights = \u001b[1m[0.24312113 0.75687885 0.        ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 8.71 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.24312 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.75688 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Stdout logging level is ERROR.\n",
      "INFO:lightautoml.automl.presets.base:Task: reg\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n",
      "INFO:lightautoml.automl.presets.base:- time: 10.00 seconds\n",
      "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n",
      "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
      "\n",
      "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (2390, 124)\u001b[0m\n",
      "\n",
      "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n",
      "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 8.42 secs\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205], 'embed_sizes': array([ 8, 18, 14,  6,  4,  5,  5,  3,  3,  5,  5,  8, 13,  8,  4,  7, 19,\n",
      "        6, 47, 13,  8, 26, 13,  8,  6,  3, 11], dtype=int32), 'data_size': 206}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = -0.09030792187357785\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = -0.08953794426601187\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = -0.08931296562210757\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = -0.08962611070809186\n",
      "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = -0.09023809555443973\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.08931296562210757\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 7.29 secs\n",
      "\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0894462\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0896381\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.09\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[165]\tvalid's l2: 0.0893287\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's l2: 0.0895329\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's l2: 0.0897793\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's l2: 0.090354\n",
      "DEBUG:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
      "[126]\tvalid's l2: 0.0893865\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.08938645716380864\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 2000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 300, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False}\n",
      "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "INFO3:lightautoml.ml_algo.boost_cb:0:\tlearn: 0.2872807\ttest: 0.3014299\tbest: 0.3014299 (0)\ttotal: 2.29ms\tremaining: 4.58s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:100:\tlearn: 0.2555142\ttest: 0.2985476\tbest: 0.2974633 (45)\ttotal: 230ms\tremaining: 4.32s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:200:\tlearn: 0.2251131\ttest: 0.3004958\tbest: 0.2974633 (45)\ttotal: 449ms\tremaining: 4.02s\n",
      "DEBUG:lightautoml.ml_algo.boost_cb:300:\tlearn: 0.1951394\ttest: 0.3009585\tbest: 0.2974633 (45)\ttotal: 668ms\tremaining: 3.77s\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (300 iterations wait)\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.2974633248\n",
      "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 45\n",
      "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 46 iterations.\n",
      "INFO:lightautoml.ml_algo.base:Time limit exceeded after calculating fold 0\n",
      "\n",
      "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m-0.08848442987283325\u001b[0m\n",
      "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "INFO:lightautoml.automl.base:Time left 1.15 secs\n",
      "\n",
      "INFO:lightautoml.automl.base:Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights and score \u001b[1m-0.08872377744721839\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.08847314785835803\u001b[0m, weights = \u001b[1m[0.10386859 0.         0.8961314 ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.08847314785835803\u001b[0m, weights = \u001b[1m[0.10386859 0.         0.8961314 ]\u001b[0m\n",
      "INFO:lightautoml.automl.blend:Blending: no score update. Terminated\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 8.90 seconds\u001b[0m\n",
      "\n",
      "INFO:lightautoml.automl.presets.base:Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.10387 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.89613 * (1 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 1.5 s, total: 2min 24s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "# Custom base algorithm\n",
    "xlearner = metalearners.XLearner(\n",
    "    propensity_learner=TabularAutoML(task=Task('binary'), timeout=10),\n",
    "    outcome_learners=[\n",
    "        TabularAutoML(task=Task('binary'), timeout=10),\n",
    "        TabularAutoML(task=Task('binary'), timeout=10)\n",
    "    ],\n",
    "    effect_learners=[\n",
    "        TabularAutoML(task=Task('reg'), timeout=10),\n",
    "        TabularAutoML(task=Task('reg'), timeout=10)\n",
    "    ]\n",
    ")\n",
    "xlearner.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyvNPez00jG-"
   },
   "source": [
    "#### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJc9xQDc0jG-",
    "outputId": "b630abc7-745b-42e0-ce63-e6592def80e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check scores ---\n",
      "OOF scores \"ROC_AUC\":\n",
      "\tTreatment = 0.67084\n",
      "\tControl   = 0.74275\n",
      "Uplift score of test group (default=\"adj_qini\"):\n",
      "\tBaseline      = 0.01340\n",
      "\tAlgo (Normed) = 0.02536 (0.14772)\n",
      "\tPerfect       = 0.09438\n"
     ]
    }
   ],
   "source": [
    "uplift_pred, treatment_pred, control_pred = xlearner.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "print('--- Check scores ---')\n",
    "print('OOF scores \"ROC_AUC\":')\n",
    "print('\\tTreatment = {:.5f}'.format(roc_auc_treatment))\n",
    "print('\\tControl   = {:.5f}'.format(roc_auc_control))\n",
    "print('Uplift score of test group (default=\"adj_qini\"):')\n",
    "print('\\tBaseline      = {:.5f}'.format(auc_base))\n",
    "print('\\tAlgo (Normed) = {:.5f} ({:.5f})'.format(uplift_auc_algo, uplift_auc_algo_normed))\n",
    "print('\\tPerfect       = {:.5f}'.format(auc_perfect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjchR_S70jG-"
   },
   "source": [
    "## Uplift metrics and graphics (using xlearner predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJAqm0vH0jG-",
    "outputId": "6e67947a-124d-444c-f300-ac9982aa87ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All available uplift metrics: ('qini', 'cum_gain', 'adj_qini')\n"
     ]
    }
   ],
   "source": [
    "UPLIFT_METRIC = 'adj_qini'\n",
    "\n",
    "print(\"All available uplift metrics: {}\".format(_available_uplift_modes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV3_L6Cy0jG-"
   },
   "source": [
    "### Algorithm uplift curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuysnxGb0jG-"
   },
   "outputs": [],
   "source": [
    "# Algorithm curve\n",
    "xs_xlearner, ys_xlearner = calculate_graphic_uplift_curve(\n",
    "    test_target, uplift_pred, test_treatment, mode=UPLIFT_METRIC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMwoTj4P0jG-"
   },
   "source": [
    "### Baseline, perfect curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPMh-TX50jG-"
   },
   "outputs": [],
   "source": [
    "# Baseline curve\n",
    "xs_base, ys_base = xs_xlearner, xs_xlearner * ys_xlearner[-1]\n",
    "\n",
    "# Perfect curver\n",
    "perfect_uplift = perfect_uplift_curve(test_target, test_treatment)\n",
    "xs_perfect, ys_perfect = calculate_graphic_uplift_curve(\n",
    "    test_target, perfect_uplift, test_treatment, mode=UPLIFT_METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "EtWYwr1b0jG-",
    "outputId": "2e54c6b4-f31e-4bca-97bd-127f5434596d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(xs_base, ys_base, 'black')\n",
    "plt.plot(xs_xlearner, ys_xlearner, 'red')\n",
    "plt.plot(xs_perfect, ys_perfect, 'green')\n",
    "\n",
    "plt.fill_between(xs_xlearner, ys_base, ys_xlearner, alpha=0.5, color='orange')\n",
    "\n",
    "plt.xlabel('Cumulative percentage of people in T/C groups')\n",
    "plt.ylabel('Uplift metric (%s)'.format(UPLIFT_METRIC))\n",
    "plt.legend(['Baseline', 'XLearner', 'Perfect']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yurpo7z0jG-"
   },
   "source": [
    "### Uplift TOP-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "zPhdtyVL0jG-",
    "outputId": "aac5e650-fc01-4714-ba86-9066dfcbb105"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tops = np.arange(0, 101, 5)\n",
    "\n",
    "uplift_at_tops = []\n",
    "for top in tops:\n",
    "    uat = calculate_uplift_at_top(test_target, uplift_pred, test_treatment, top=top)\n",
    "    uplift_at_tops.append(uat)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(tops, uplift_at_tops, marker='.')\n",
    "\n",
    "plt.legend(['Uplift_At_K'])\n",
    "plt.xticks(np.arange(0, 101, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDNLk_eg0jG-"
   },
   "source": [
    "### Custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mN9tf-9K0jG-",
    "outputId": "44d462aa-46aa-46fa-e731-42741a45ff5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric = 0.07204058125110756\n"
     ]
    }
   ],
   "source": [
    "# Custom metric can be used in AutoUplift\n",
    "# There msut be a function's signature:\n",
    "# def custom_metric(target, uplift_pred, treatment) -> float:\n",
    "\n",
    "\n",
    "class CustomUpliftMetric(TUpliftMetric):\n",
    "    def __call__(self, target: np.ndarray, uplift_pred: np.ndarray, treatment: np.ndarray) -> float:\n",
    "        up_10 = calculate_uplift_at_top(target, uplift_pred, treatment, 10)\n",
    "        up_20 = calculate_uplift_at_top(target, uplift_pred, treatment, 20)\n",
    "\n",
    "        return 0.5 * (up_10 + up_20)\n",
    "\n",
    "\n",
    "metric = CustomUpliftMetric()\n",
    "metric_value = metric(test_target, uplift_pred, test_treatment)\n",
    "\n",
    "print(\"Metric = {}\".format(metric_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUkYzGzMp1pv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "bf9424b8e3052bddf6726e3cb8e5d28a2d26679b29382f5380215b73dc612d6f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
